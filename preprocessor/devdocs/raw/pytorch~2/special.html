<h1 id="torch-special">torch.special</h1> <p>The torch.special module, modeled after SciPy’s <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/special.html">special</a> module.</p>  <h2 id="functions">Functions</h2> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.airy_ai">
<code>torch.special.airy_ai(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Airy function <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Ai</mtext><mrow><mo fence="true">(</mo><mtext>input</mtext><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{Ai}\left(\text{input}\right)</annotation></semantics></math></span></span></span>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.bessel_j0">
<code>torch.special.bessel_j0(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Bessel function of the first kind of order <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span></span>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.bessel_j1">
<code>torch.special.bessel_j1(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Bessel function of the first kind of order <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span></span>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.digamma">
<code>torch.special.digamma(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the logarithmic derivative of the gamma function on <code>input</code>.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">ϝ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mi>d</mi><mrow><mi>d</mi><mi>x</mi></mrow></mfrac><mi>ln</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi mathvariant="normal">Γ</mi><mrow><mo fence="true">(</mo><mi>x</mi><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mo>=</mo><mfrac><mrow><msup><mi mathvariant="normal">Γ</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\digamma(x) = \frac{d}{dx} \ln\left(\Gamma\left(x\right)\right) = \frac{\Gamma'(x)}{\Gamma(x)} </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the tensor to compute the digamma function on</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This function is similar to SciPy’s <code>scipy.special.digamma</code>.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>From PyTorch 1.8 onwards, the digamma function returns <code>-Inf</code> for <code>0</code>. Previously it returned <code>NaN</code> for <code>0</code>.</p> </div> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; a = torch.tensor([1, 0.5])
&gt;&gt;&gt; torch.special.digamma(a)
tensor([-0.5772, -1.9635])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.entr">
<code>torch.special.entr(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the entropy on <code>input</code> (as defined below), elementwise.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mtext>entr(x)</mtext><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mi>x</mi><mo>∗</mo><mi>ln</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>x</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>x</mi><mo>=</mo><mn>0.0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>x</mi><mo>&lt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align} \text{entr(x)} = \begin{cases} -x * \ln(x) &amp; x &gt; 0 \\ 0 &amp; x = 0.0 \\ -\infty &amp; x &lt; 0 \end{cases} \end{align} </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; a = torch.arange(-0.5, 1, 0.5)
&gt;&gt;&gt; a
tensor([-0.5000,  0.0000,  0.5000])
&gt;&gt;&gt; torch.special.entr(a)
tensor([  -inf, 0.0000, 0.3466])
</pre> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.erf">
<code>torch.special.erf(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the error function of <code>input</code>. The error function is defined as follows:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">f</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>2</mn><msqrt><mi>π</mi></msqrt></mfrac><msubsup><mo>∫</mo><mn>0</mn><mi>x</mi></msubsup><msup><mi>e</mi><mrow><mo>−</mo><msup><mi>t</mi><mn>2</mn></msup></mrow></msup><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\mathrm{erf}(x) = \frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-t^2} dt </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; torch.special.erf(torch.tensor([0, -1., 10.]))
tensor([ 0.0000, -0.8427,  1.0000])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.erfc">
<code>torch.special.erfc(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the complementary error function of <code>input</code>. The complementary error function is defined as follows:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">f</mi><mi mathvariant="normal">c</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mn>2</mn><msqrt><mi>π</mi></msqrt></mfrac><msubsup><mo>∫</mo><mn>0</mn><mi>x</mi></msubsup><msup><mi>e</mi><mrow><mo>−</mo><msup><mi>t</mi><mn>2</mn></msup></mrow></msup><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\mathrm{erfc}(x) = 1 - \frac{2}{\sqrt{\pi}} \int_{0}^{x} e^{-t^2} dt </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; torch.special.erfc(torch.tensor([0, -1., 10.]))
tensor([ 1.0000, 1.8427,  0.0000])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.erfcx">
<code>torch.special.erfcx(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the scaled complementary error function for each element of <code>input</code>. The scaled complementary error function is defined as follows:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">f</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">x</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>e</mi><msup><mi>x</mi><mn>2</mn></msup></msup><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">f</mi><mi mathvariant="normal">c</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{erfcx}(x) = e^{x^2} \mathrm{erfc}(x) </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; torch.special.erfcx(torch.tensor([0, -1., 10.]))
tensor([ 1.0000, 5.0090, 0.0561])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.erfinv">
<code>torch.special.erfinv(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the inverse error function of <code>input</code>. The inverse error function is defined in the range <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(-1, 1)</annotation></semantics></math></span></span></span> as:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">f</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">v</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">f</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">\mathrm{erfinv}(\mathrm{erf}(x)) = x </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; torch.special.erfinv(torch.tensor([0, 0.5, -1.]))
tensor([ 0.0000,  0.4769,    -inf])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.exp2">
<code>torch.special.exp2(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the base two exponential function of <code>input</code>.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><msup><mn>2</mn><msub><mi>x</mi><mi>i</mi></msub></msup></mrow><annotation encoding="application/x-tex">y_{i} = 2^{x_{i}} </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; torch.special.exp2(torch.tensor([0, math.log2(2.), 3, 4]))
tensor([ 1.,  2.,  8., 16.])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.expit">
<code>torch.special.expit(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the expit (also known as the logistic sigmoid function) of the elements of <code>input</code>.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><msub><mtext>input</mtext><mi>i</mi></msub></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{out}_{i} = \frac{1}{1 + e^{-\text{input}_{i}}} </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; t = torch.randn(4)
&gt;&gt;&gt; t
tensor([ 0.9213,  1.0887, -0.8858, -1.7683])
&gt;&gt;&gt; torch.special.expit(t)
tensor([ 0.7153,  0.7481,  0.2920,  0.1458])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.expm1">
<code>torch.special.expm1(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the exponential of the elements minus 1 of <code>input</code>.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><msup><mi>e</mi><msub><mi>x</mi><mi>i</mi></msub></msup><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">y_{i} = e^{x_{i}} - 1 </annotation></semantics></math></span></span></span>
</div>
<div class="admonition note"> <p class="admonition-title">Note</p> <p>This function provides greater precision than exp(x) - 1 for small values of x.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; torch.special.expm1(torch.tensor([0, math.log(2.)]))
tensor([ 0.,  1.])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.gammainc">
<code>torch.special.gammainc(input, other, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the regularized lower incomplete gamma function:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><msub><mtext>input</mtext><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><msubsup><mo>∫</mo><mn>0</mn><msub><mtext>other</mtext><mi>i</mi></msub></msubsup><msup><mi>t</mi><mrow><msub><mtext>input</mtext><mi>i</mi></msub><mo>−</mo><mn>1</mn></mrow></msup><msup><mi>e</mi><mrow><mo>−</mo><mi>t</mi></mrow></msup><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\text{out}_{i} = \frac{1}{\Gamma(\text{input}_i)} \int_0^{\text{other}_i} t^{\text{input}_i-1} e^{-t} dt </annotation></semantics></math></span></span></span>
</div>
<p>where both <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>input</mtext><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{input}_i</annotation></semantics></math></span></span></span> and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>other</mtext><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{other}_i</annotation></semantics></math></span></span></span> are weakly positive and at least one is strictly positive. If both are zero or either is negative then <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><mtext>nan</mtext></mrow><annotation encoding="application/x-tex">\text{out}_i=\text{nan}</annotation></semantics></math></span></span></span>. <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma(\cdot)</annotation></semantics></math></span></span></span> in the equation above is the gamma function,</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><msub><mtext>input</mtext><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∫</mo><mn>0</mn><mi mathvariant="normal">∞</mi></msubsup><msup><mi>t</mi><mrow><mo stretchy="false">(</mo><msub><mtext>input</mtext><mi>i</mi></msub><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><msup><mi>e</mi><mrow><mo>−</mo><mi>t</mi></mrow></msup><mi>d</mi><mi>t</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\Gamma(\text{input}_i) = \int_0^\infty t^{(\text{input}_i-1)} e^{-t} dt. </annotation></semantics></math></span></span></span>
</div>
<p>See <a class="reference internal" href="#torch.special.gammaincc" title="torch.special.gammaincc"><code>torch.special.gammaincc()</code></a> and <a class="reference internal" href="#torch.special.gammaln" title="torch.special.gammaln"><code>torch.special.gammaln()</code></a> for related functions.</p> <p>Supports <a class="reference internal" href="https://pytorch.org/docs/2.1/notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcasting to a common shape</span></a> and float inputs.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The backward pass with respect to <code>input</code> is not yet supported. Please open an issue on PyTorch’s Github to request it.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the first non-negative input tensor</li> <li>
<strong>other</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the second non-negative input tensor</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; a1 = torch.tensor([4.0])
&gt;&gt;&gt; a2 = torch.tensor([3.0, 4.0, 5.0])
&gt;&gt;&gt; a = torch.special.gammaincc(a1, a2)
tensor([0.3528, 0.5665, 0.7350])
tensor([0.3528, 0.5665, 0.7350])
&gt;&gt;&gt; b = torch.special.gammainc(a1, a2) + torch.special.gammaincc(a1, a2)
tensor([1., 1., 1.])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.gammaincc">
<code>torch.special.gammaincc(input, other, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the regularized upper incomplete gamma function:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><msub><mtext>input</mtext><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><msubsup><mo>∫</mo><msub><mtext>other</mtext><mi>i</mi></msub><mi mathvariant="normal">∞</mi></msubsup><msup><mi>t</mi><mrow><msub><mtext>input</mtext><mi>i</mi></msub><mo>−</mo><mn>1</mn></mrow></msup><msup><mi>e</mi><mrow><mo>−</mo><mi>t</mi></mrow></msup><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\text{out}_{i} = \frac{1}{\Gamma(\text{input}_i)} \int_{\text{other}_i}^{\infty} t^{\text{input}_i-1} e^{-t} dt </annotation></semantics></math></span></span></span>
</div>
<p>where both <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>input</mtext><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{input}_i</annotation></semantics></math></span></span></span> and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>other</mtext><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{other}_i</annotation></semantics></math></span></span></span> are weakly positive and at least one is strictly positive. If both are zero or either is negative then <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><mtext>nan</mtext></mrow><annotation encoding="application/x-tex">\text{out}_i=\text{nan}</annotation></semantics></math></span></span></span>. <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma(\cdot)</annotation></semantics></math></span></span></span> in the equation above is the gamma function,</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><msub><mtext>input</mtext><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∫</mo><mn>0</mn><mi mathvariant="normal">∞</mi></msubsup><msup><mi>t</mi><mrow><mo stretchy="false">(</mo><msub><mtext>input</mtext><mi>i</mi></msub><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><msup><mi>e</mi><mrow><mo>−</mo><mi>t</mi></mrow></msup><mi>d</mi><mi>t</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\Gamma(\text{input}_i) = \int_0^\infty t^{(\text{input}_i-1)} e^{-t} dt. </annotation></semantics></math></span></span></span>
</div>
<p>See <a class="reference internal" href="#torch.special.gammainc" title="torch.special.gammainc"><code>torch.special.gammainc()</code></a> and <a class="reference internal" href="#torch.special.gammaln" title="torch.special.gammaln"><code>torch.special.gammaln()</code></a> for related functions.</p> <p>Supports <a class="reference internal" href="https://pytorch.org/docs/2.1/notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcasting to a common shape</span></a> and float inputs.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The backward pass with respect to <code>input</code> is not yet supported. Please open an issue on PyTorch’s Github to request it.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the first non-negative input tensor</li> <li>
<strong>other</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the second non-negative input tensor</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; a1 = torch.tensor([4.0])
&gt;&gt;&gt; a2 = torch.tensor([3.0, 4.0, 5.0])
&gt;&gt;&gt; a = torch.special.gammaincc(a1, a2)
tensor([0.6472, 0.4335, 0.2650])
&gt;&gt;&gt; b = torch.special.gammainc(a1, a2) + torch.special.gammaincc(a1, a2)
tensor([1., 1., 1.])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.gammaln">
<code>torch.special.gammaln(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the natural logarithm of the absolute value of the gamma function on <code>input</code>.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><mi>ln</mi><mo>⁡</mo><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><mi mathvariant="normal">∣</mi><msub><mtext>input</mtext><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{out}_{i} = \ln \Gamma(|\text{input}_{i}|) </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; a = torch.arange(0.5, 2, 0.5)
&gt;&gt;&gt; torch.special.gammaln(a)
tensor([ 0.5724,  0.0000, -0.1208])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.i0">
<code>torch.special.i0(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the zeroth order modified Bessel function of the first kind for each element of <code>input</code>.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><msub><mi>I</mi><mn>0</mn></msub><mo stretchy="false">(</mo><msub><mtext>input</mtext><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mfrac><mrow><mo stretchy="false">(</mo><msubsup><mtext>input</mtext><mi>i</mi><mn>2</mn></msubsup><mi mathvariant="normal">/</mi><mn>4</mn><msup><mo stretchy="false">)</mo><mi>k</mi></msup></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">!</mo><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{out}_{i} = I_0(\text{input}_{i}) = \sum_{k=0}^{\infty} \frac{(\text{input}_{i}^2/4)^k}{(k!)^2} </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; torch.i0(torch.arange(5, dtype=torch.float32))
tensor([ 1.0000,  1.2661,  2.2796,  4.8808, 11.3019])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.i0e">
<code>torch.special.i0e(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below) for each element of <code>input</code>.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mi mathvariant="normal">∣</mi><mi>x</mi><mi mathvariant="normal">∣</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>i</mi><mn>0</mn><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mi mathvariant="normal">∣</mi><mi>x</mi><mi mathvariant="normal">∣</mi><mo stretchy="false">)</mo><mo>∗</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mfrac><mrow><mo stretchy="false">(</mo><msubsup><mtext>input</mtext><mi>i</mi><mn>2</mn></msubsup><mi mathvariant="normal">/</mi><mn>4</mn><msup><mo stretchy="false">)</mo><mi>k</mi></msup></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">!</mo><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{out}_{i} = \exp(-|x|) * i0(x) = \exp(-|x|) * \sum_{k=0}^{\infty} \frac{(\text{input}_{i}^2/4)^k}{(k!)^2} </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; torch.special.i0e(torch.arange(5, dtype=torch.float32))
tensor([1.0000, 0.4658, 0.3085, 0.2430, 0.2070])
</pre> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.i1">
<code>torch.special.i1(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the first order modified Bessel function of the first kind (as defined below) for each element of <code>input</code>.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mo stretchy="false">(</mo><msub><mtext>input</mtext><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mn>2</mn></mfrac><mo>∗</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mfrac><mrow><mo stretchy="false">(</mo><msubsup><mtext>input</mtext><mi>i</mi><mn>2</mn></msubsup><mi mathvariant="normal">/</mi><mn>4</mn><msup><mo stretchy="false">)</mo><mi>k</mi></msup></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">!</mo><mo stretchy="false">)</mo><mo>∗</mo><mo stretchy="false">(</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">!</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{out}_{i} = \frac{(\text{input}_{i})}{2} * \sum_{k=0}^{\infty} \frac{(\text{input}_{i}^2/4)^k}{(k!) * (k+1)!} </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; torch.special.i1(torch.arange(5, dtype=torch.float32))
tensor([0.0000, 0.5652, 1.5906, 3.9534, 9.7595])
</pre> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.i1e">
<code>torch.special.i1e(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the exponentially scaled first order modified Bessel function of the first kind (as defined below) for each element of <code>input</code>.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mi mathvariant="normal">∣</mi><mi>x</mi><mi mathvariant="normal">∣</mi><mo stretchy="false">)</mo><mo>∗</mo><mi>i</mi><mn>1</mn><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>−</mo><mi mathvariant="normal">∣</mi><mi>x</mi><mi mathvariant="normal">∣</mi><mo stretchy="false">)</mo><mo>∗</mo><mfrac><mrow><mo stretchy="false">(</mo><msub><mtext>input</mtext><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mn>2</mn></mfrac><mo>∗</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mfrac><mrow><mo stretchy="false">(</mo><msubsup><mtext>input</mtext><mi>i</mi><mn>2</mn></msubsup><mi mathvariant="normal">/</mi><mn>4</mn><msup><mo stretchy="false">)</mo><mi>k</mi></msup></mrow><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">!</mo><mo stretchy="false">)</mo><mo>∗</mo><mo stretchy="false">(</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo stretchy="false">!</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{out}_{i} = \exp(-|x|) * i1(x) = \exp(-|x|) * \frac{(\text{input}_{i})}{2} * \sum_{k=0}^{\infty} \frac{(\text{input}_{i}^2/4)^k}{(k!) * (k+1)!} </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; torch.special.i1e(torch.arange(5, dtype=torch.float32))
tensor([0.0000, 0.2079, 0.2153, 0.1968, 0.1788])
</pre> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.log1p">
<code>torch.special.log1p(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Alias for <a class="reference internal" href="generated/torch.log1p#torch.log1p" title="torch.log1p"><code>torch.log1p()</code></a>.</p> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.log_ndtr">
<code>torch.special.log_ndtr(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the log of the area under the standard Gaussian probability density function, integrated from minus infinity to <code>input</code>, elementwise.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>log_ndtr</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mn>1</mn><msqrt><mrow><mn>2</mn><mi>π</mi></mrow></msqrt></mfrac><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mi>x</mi></msubsup><msup><mi>e</mi><mrow><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msup><mi>t</mi><mn>2</mn></msup></mrow></msup><mi>d</mi><mi>t</mi><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{log\_ndtr}(x) = \log\left(\frac{1}{\sqrt{2 \pi}}\int_{-\infty}^{x} e^{-\frac{1}{2}t^2} dt \right) </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; torch.special.log_ndtr(torch.tensor([-3., -2, -1, 0, 1, 2, 3]))
tensor([-6.6077 -3.7832 -1.841  -0.6931 -0.1728 -0.023  -0.0014])
</pre> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.log_softmax">
<code>torch.special.log_softmax(input, dim, *, dtype=None) → Tensor</code> </dt> <dd>
<p>Computes softmax followed by a logarithm.</p> <p>While mathematically equivalent to log(softmax(x)), doing these two operations separately is slower and numerically unstable. This function is computed as:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>log_softmax</mtext><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><munder><mo>∑</mo><mi>j</mi></munder><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\text{log\_softmax}(x_{i}) = \log\left(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} \right) </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – input</li> <li>
<strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>) – A dimension along which log_softmax will be computed.</li> <li>
<strong>dtype</strong> (<a class="reference internal" href="tensor_attributes#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a>, optional) – the desired data type of returned tensor. If specified, the input tensor is cast to <code>dtype</code> before the operation is performed. This is useful for preventing data type overflows. Default: None.</li> </ul> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; t = torch.ones(2, 2)
&gt;&gt;&gt; torch.special.log_softmax(t, 0)
tensor([[-0.6931, -0.6931],
        [-0.6931, -0.6931]])
</pre> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.logit">
<code>torch.special.logit(input, eps=None, *, out=None) → Tensor</code> </dt> <dd>
<p>Returns a new tensor with the logit of the elements of <code>input</code>. <code>input</code> is clamped to [eps, 1 - eps] when eps is not None. When eps is None and <code>input</code> &lt; 0 or <code>input</code> &gt; 1, the function will yields NaN.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>y</mi><mi>i</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo>=</mo><mi>ln</mi><mo>⁡</mo><mo stretchy="false">(</mo><mfrac><msub><mi>z</mi><mi>i</mi></msub><mrow><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>i</mi></msub></mrow></mfrac><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>z</mi><mi>i</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mi>i</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>if eps is None</mtext></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>eps</mtext></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mi>x</mi><mi>i</mi></msub><mo>&lt;</mo><mtext>eps</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mi>i</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if eps</mtext><mo>≤</mo><msub><mi>x</mi><mi>i</mi></msub><mo>≤</mo><mn>1</mn><mo>−</mo><mtext>eps</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mo>−</mo><mtext>eps</mtext></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mi>x</mi><mi>i</mi></msub><mo>&gt;</mo><mn>1</mn><mo>−</mo><mtext>eps</mtext></mrow></mstyle></mtd></mtr></mtable></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align} y_{i} &amp;= \ln(\frac{z_{i}}{1 - z_{i}}) \\ z_{i} &amp;= \begin{cases} x_{i} &amp; \text{if eps is None} \\ \text{eps} &amp; \text{if } x_{i} &lt; \text{eps} \\ x_{i} &amp; \text{if } \text{eps} \leq x_{i} \leq 1 - \text{eps} \\ 1 - \text{eps} &amp; \text{if } x_{i} &gt; 1 - \text{eps} \end{cases} \end{align} </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</li> <li>
<strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em>, </em><em>optional</em>) – the epsilon for input clamp bound. Default: <code>None</code>
</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; a = torch.rand(5)
&gt;&gt;&gt; a
tensor([0.2796, 0.9331, 0.6486, 0.1523, 0.6516])
&gt;&gt;&gt; torch.special.logit(a, eps=1e-6)
tensor([-0.9466,  2.6352,  0.6131, -1.7169,  0.6261])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.logsumexp">
<code>torch.special.logsumexp(input, dim, keepdim=False, *, out=None)</code> </dt> <dd>
<p>Alias for <a class="reference internal" href="generated/torch.logsumexp#torch.logsumexp" title="torch.logsumexp"><code>torch.logsumexp()</code></a>.</p> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.multigammaln">
<code>torch.special.multigammaln(input, p, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the <a class="reference external" href="https://en.wikipedia.org/wiki/Multivariate_gamma_function">multivariate log-gamma function</a> with dimension <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span></span></span> element-wise, given by</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="normal">Γ</mi><mi>p</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mi>C</mi><mo>+</mo><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi mathvariant="normal">Γ</mi><mrow><mo fence="true">(</mo><mi>a</mi><mo>−</mo><mfrac><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow><mn>2</mn></mfrac><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mstyle></mrow><annotation encoding="application/x-tex">\log(\Gamma_{p}(a)) = C + \displaystyle \sum_{i=1}^{p} \log\left(\Gamma\left(a - \frac{i - 1}{2}\right)\right) </annotation></semantics></math></span></span></span>
</div>
<p>where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>π</mi><mo stretchy="false">)</mo><mo>⋅</mo><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>p</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mn>4</mn></mfrac></mrow><annotation encoding="application/x-tex">C = \log(\pi) \cdot \frac{p (p - 1)}{4}</annotation></semantics></math></span></span></span> and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><mo>−</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma(-)</annotation></semantics></math></span></span></span> is the Gamma function.</p> <p>All elements must be greater than <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>p</mi><mo>−</mo><mn>1</mn></mrow><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{p - 1}{2}</annotation></semantics></math></span></span></span>, otherwise the behavior is undefiend.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the tensor to compute the multivariate log-gamma function</li> <li>
<strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>) – the number of dimensions</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; a = torch.empty(2, 3).uniform_(1, 2)
&gt;&gt;&gt; a
tensor([[1.6835, 1.8474, 1.1929],
        [1.0475, 1.7162, 1.4180]])
&gt;&gt;&gt; torch.special.multigammaln(a, 2)
tensor([[0.3928, 0.4007, 0.7586],
        [1.0311, 0.3901, 0.5049]])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.ndtr">
<code>torch.special.ndtr(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the area under the standard Gaussian probability density function, integrated from minus infinity to <code>input</code>, elementwise.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>ndtr</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><msqrt><mrow><mn>2</mn><mi>π</mi></mrow></msqrt></mfrac><msubsup><mo>∫</mo><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><mi>x</mi></msubsup><msup><mi>e</mi><mrow><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msup><mi>t</mi><mn>2</mn></msup></mrow></msup><mi>d</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\text{ndtr}(x) = \frac{1}{\sqrt{2 \pi}}\int_{-\infty}^{x} e^{-\frac{1}{2}t^2} dt </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; torch.special.ndtr(torch.tensor([-3., -2, -1, 0, 1, 2, 3]))
tensor([0.0013, 0.0228, 0.1587, 0.5000, 0.8413, 0.9772, 0.9987])
</pre> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.ndtri">
<code>torch.special.ndtri(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the argument, x, for which the area under the Gaussian probability density function (integrated from minus infinity to x) is equal to <code>input</code>, elementwise.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>ndtri</mtext><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>=</mo><msqrt><mn>2</mn></msqrt><msup><mtext>erf</mtext><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mn>2</mn><mi>p</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{ndtri}(p) = \sqrt{2}\text{erf}^{-1}(2p - 1) </annotation></semantics></math></span></span></span>
</div>
<div class="admonition note"> <p class="admonition-title">Note</p> <p>Also known as quantile function for Normal Distribution.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; torch.special.ndtri(torch.tensor([0, 0.25, 0.5, 0.75, 1]))
tensor([   -inf, -0.6745,  0.0000,  0.6745,     inf])
</pre> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.polygamma">
<code>torch.special.polygamma(n, input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>n</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding="application/x-tex">n^{th}</annotation></semantics></math></span></span></span> derivative of the digamma function on <code>input</code>. <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">n \geq 0</annotation></semantics></math></span></span></span> is called the order of the polygamma function.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>ψ</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><msup><mi>d</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msup><mrow><mi>d</mi><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msup></mrow></mfrac><mi>ψ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\psi^{(n)}(x) = \frac{d^{(n)}}{dx^{(n)}} \psi(x) </annotation></semantics></math></span></span></span>
</div>
<div class="admonition note"> <p class="admonition-title">Note</p> <p>This function is implemented only for nonnegative integers <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≥</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">n \geq 0</annotation></semantics></math></span></span></span>.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>n</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>) – the order of the polygamma function</li> <li>
<strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; a = torch.tensor([1, 0.5])
&gt;&gt;&gt; torch.special.polygamma(1, a)
tensor([1.64493, 4.9348])
&gt;&gt;&gt; torch.special.polygamma(2, a)
tensor([ -2.4041, -16.8288])
&gt;&gt;&gt; torch.special.polygamma(3, a)
tensor([ 6.4939, 97.4091])
&gt;&gt;&gt; torch.special.polygamma(4, a)
tensor([ -24.8863, -771.4742])
</pre> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.psi">
<code>torch.special.psi(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Alias for <a class="reference internal" href="#torch.special.digamma" title="torch.special.digamma"><code>torch.special.digamma()</code></a>.</p> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.round">
<code>torch.special.round(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Alias for <a class="reference internal" href="generated/torch.round#torch.round" title="torch.round"><code>torch.round()</code></a>.</p> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.scaled_modified_bessel_k0">
<code>torch.special.scaled_modified_bessel_k0(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Scaled modified Bessel function of the second kind of order <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span></span>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.scaled_modified_bessel_k1">
<code>torch.special.scaled_modified_bessel_k1(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Scaled modified Bessel function of the second kind of order <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span></span>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.sinc">
<code>torch.special.sinc(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the normalized sinc of <code>input.</code></p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mn>1</mn><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mtext>input</mtext><mi>i</mi></msub><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>π</mi><msub><mtext>input</mtext><mi>i</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mi>π</mi><msub><mtext>input</mtext><mi>i</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\text{out}_{i} = \begin{cases} 1, &amp; \text{if}\ \text{input}_{i}=0 \\ \sin(\pi \text{input}_{i}) / (\pi \text{input}_{i}), &amp; \text{otherwise} \end{cases} </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; t = torch.randn(4)
&gt;&gt;&gt; t
tensor([ 0.2252, -0.2948,  1.0267, -1.1566])
&gt;&gt;&gt; torch.special.sinc(t)
tensor([ 0.9186,  0.8631, -0.0259, -0.1300])
</pre> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.softmax">
<code>torch.special.softmax(input, dim, *, dtype=None) → Tensor</code> </dt> <dd>
<p>Computes the softmax function.</p> <p>Softmax is defined as:</p> <p><span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Softmax</mtext><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><msub><mo>∑</mo><mi>j</mi></msub><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}</annotation></semantics></math></span></span></span></p> <p>It is applied to all slices along dim, and will re-scale them so that the elements lie in the range <code>[0, 1]</code> and sum to 1.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – input</li> <li>
<strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>) – A dimension along which softmax will be computed.</li> <li>
<strong>dtype</strong> (<a class="reference internal" href="tensor_attributes#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a>, optional) – the desired data type of returned tensor. If specified, the input tensor is cast to <code>dtype</code> before the operation is performed. This is useful for preventing data type overflows. Default: None.</li> </ul> </dd> </dl> <dl> <dt>Examples::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; t = torch.ones(2, 2)
&gt;&gt;&gt; torch.special.softmax(t, 0)
tensor([[0.5000, 0.5000],
        [0.5000, 0.5000]])
</pre> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.spherical_bessel_j0">
<code>torch.special.spherical_bessel_j0(input, *, out=None) → Tensor</code> </dt> <dd>
<p>Spherical Bessel function of the first kind of order <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span></span>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.xlog1py">
<code>torch.special.xlog1py(input, other, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes <code>input * log1p(other)</code> with the following cases.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>NaN</mtext></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mtext>other</mtext><mi>i</mi></msub><mo>=</mo><mtext>NaN</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mtext>input</mtext><mi>i</mi></msub><mo>=</mo><mn>0.0</mn><mtext> and </mtext><msub><mtext>other</mtext><mi>i</mi></msub><mo stretchy="false">!</mo><mo>=</mo><mtext>NaN</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mtext>input</mtext><mi>i</mi></msub><mo>∗</mo><mtext>log1p</mtext><mo stretchy="false">(</mo><msub><mtext>other</mtext><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\text{out}_{i} = \begin{cases} \text{NaN} &amp; \text{if } \text{other}_{i} = \text{NaN} \\ 0 &amp; \text{if } \text{input}_{i} = 0.0 \text{ and } \text{other}_{i} != \text{NaN} \\ \text{input}_{i} * \text{log1p}(\text{other}_{i})&amp; \text{otherwise} \end{cases} </annotation></semantics></math></span></span></span>
</div>
<p>Similar to SciPy’s <code>scipy.special.xlog1py</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<em>Number</em><em> or </em><a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – Multiplier</li> <li>
<strong>other</strong> (<em>Number</em><em> or </em><a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – Argument</li> </ul> </dd> </dl> <div class="admonition note"> <p class="admonition-title">Note</p> <p>At least one of <code>input</code> or <code>other</code> must be a tensor.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Keyword Arguments</dt> <dd class="field-odd">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; x = torch.zeros(5,)
&gt;&gt;&gt; y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])
&gt;&gt;&gt; torch.special.xlog1py(x, y)
tensor([0., 0., 0., 0., nan])
&gt;&gt;&gt; x = torch.tensor([1, 2, 3])
&gt;&gt;&gt; y = torch.tensor([3, 2, 1])
&gt;&gt;&gt; torch.special.xlog1py(x, y)
tensor([1.3863, 2.1972, 2.0794])
&gt;&gt;&gt; torch.special.xlog1py(x, 4)
tensor([1.6094, 3.2189, 4.8283])
&gt;&gt;&gt; torch.special.xlog1py(2, y)
tensor([2.7726, 2.1972, 1.3863])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.xlogy">
<code>torch.special.xlogy(input, other, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes <code>input * log(other)</code> with the following cases.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>NaN</mtext></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mtext>other</mtext><mi>i</mi></msub><mo>=</mo><mtext>NaN</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>0</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><msub><mtext>input</mtext><mi>i</mi></msub><mo>=</mo><mn>0.0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mtext>input</mtext><mi>i</mi></msub><mo>∗</mo><mi>log</mi><mo>⁡</mo><mrow><mo stretchy="false">(</mo><msub><mtext>other</mtext><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>otherwise</mtext></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\text{out}_{i} = \begin{cases} \text{NaN} &amp; \text{if } \text{other}_{i} = \text{NaN} \\ 0 &amp; \text{if } \text{input}_{i} = 0.0 \\ \text{input}_{i} * \log{(\text{other}_{i})} &amp; \text{otherwise} \end{cases} </annotation></semantics></math></span></span></span>
</div>
<p>Similar to SciPy’s <code>scipy.special.xlogy</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<em>Number</em><em> or </em><a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – Multiplier</li> <li>
<strong>other</strong> (<em>Number</em><em> or </em><a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – Argument</li> </ul> </dd> </dl> <div class="admonition note"> <p class="admonition-title">Note</p> <p>At least one of <code>input</code> or <code>other</code> must be a tensor.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Keyword Arguments</dt> <dd class="field-odd">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; x = torch.zeros(5,)
&gt;&gt;&gt; y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])
&gt;&gt;&gt; torch.special.xlogy(x, y)
tensor([0., 0., 0., 0., nan])
&gt;&gt;&gt; x = torch.tensor([1, 2, 3])
&gt;&gt;&gt; y = torch.tensor([3, 2, 1])
&gt;&gt;&gt; torch.special.xlogy(x, y)
tensor([1.0986, 1.3863, 0.0000])
&gt;&gt;&gt; torch.special.xlogy(x, 4)
tensor([1.3863, 2.7726, 4.1589])
&gt;&gt;&gt; torch.special.xlogy(2, y)
tensor([2.1972, 1.3863, 0.0000])
</pre> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.special.zeta">
<code>torch.special.zeta(input, other, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the Hurwitz zeta function, elementwise.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>ζ</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><mfrac><mn>1</mn><mrow><mo stretchy="false">(</mo><mi>k</mi><mo>+</mo><mi>q</mi><msup><mo stretchy="false">)</mo><mi>x</mi></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\zeta(x, q) = \sum_{k=0}^{\infty} \frac{1}{(k + q)^x} </annotation></semantics></math></span></span></span>
</div>
<dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor corresponding to <code>x</code>.</li> <li>
<strong>other</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor corresponding to <code>q</code>.</li> </ul> </dd> </dl> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The Riemann zeta function corresponds to the case when <code>q = 1</code></p> </div> <dl class="field-list simple"> <dt class="field-odd">Keyword Arguments</dt> <dd class="field-odd">
<p><strong>out</strong> (<a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; x = torch.tensor([2., 4.])
&gt;&gt;&gt; torch.special.zeta(x, 1)
tensor([1.6449, 1.0823])
&gt;&gt;&gt; torch.special.zeta(x, torch.tensor([1., 2.]))
tensor([1.6449, 0.0823])
&gt;&gt;&gt; torch.special.zeta(2, torch.tensor([1., 2.]))
tensor([1.6449, 0.6449])
</pre> </dd> </dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/special.html" class="_attribution-link">https://pytorch.org/docs/2.1/special.html</a>
  </p>
</div>
