<h1 id="externalstream">ExternalStream</h1> <dl class="py class"> <dt class="sig sig-object py" id="torch.cuda.ExternalStream">
<code>class torch.cuda.ExternalStream(stream_ptr, device=None, **kwargs)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/cuda/streams.html#ExternalStream"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Wrapper around an externally allocated CUDA stream.</p> <p>This class is used to wrap streams allocated in other libraries in order to facilitate data exchange and multi-library interactions.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This class doesn’t manage the stream life-cycle, it is the user responsibility to keep the referenced stream alive while this class is being used.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>stream_ptr</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>) – Integer representation of the <code>cudaStream_t</code> value. allocated externally.</li> <li>
<strong>device</strong> (<a class="reference internal" href="../tensor_attributes#torch.device" title="torch.device">torch.device</a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><em>optional</em>) – the device where the stream was originally allocated. if device is specified incorrectly, subsequent launches using this stream may fail.</li> </ul> </dd> </dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.cuda.ExternalStream.query">
<code>query()</code> </dt> <dd>
<p>Checks if all the work submitted has been completed.</p> <dl class="field-list simple"> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<p>A boolean indicating if all kernels in this stream are completed.</p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.cuda.ExternalStream.record_event">
<code>record_event(event=None)</code> </dt> <dd>
<p>Records an event.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>event</strong> (<a class="reference internal" href="torch.cuda.event#torch.cuda.Event" title="torch.cuda.Event">torch.cuda.Event</a><em>, </em><em>optional</em>) – event to record. If not given, a new one will be allocated.</p> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<p>Recorded event.</p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.cuda.ExternalStream.synchronize">
<code>synchronize()</code> </dt> <dd>
<p>Wait for all the kernels in this stream to complete.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This is a wrapper around <code>cudaStreamSynchronize()</code>: see <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html">CUDA Stream documentation</a> for more info.</p> </div> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.cuda.ExternalStream.wait_event">
<code>wait_event(event)</code> </dt> <dd>
<p>Makes all future work submitted to the stream wait for an event.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>event</strong> (<a class="reference internal" href="torch.cuda.event#torch.cuda.Event" title="torch.cuda.Event">torch.cuda.Event</a>) – an event to wait for.</p> </dd> </dl> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This is a wrapper around <code>cudaStreamWaitEvent()</code>: see <a class="reference external" href="https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html">CUDA Stream documentation</a> for more info.</p> <p>This function returns without waiting for <code>event</code>: only future operations are affected.</p> </div> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.cuda.ExternalStream.wait_stream">
<code>wait_stream(stream)</code> </dt> <dd>
<p>Synchronizes with another stream.</p> <p>All future work submitted to this stream will wait until all kernels submitted to a given stream at the time of call complete.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>stream</strong> (<a class="reference internal" href="torch.cuda.stream#torch.cuda.Stream" title="torch.cuda.Stream">Stream</a>) – a stream to synchronize.</p> </dd> </dl> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This function returns without waiting for currently enqueued kernels in <a class="reference internal" href="torch.cuda.stream#torch.cuda.stream" title="torch.cuda.stream"><code>stream</code></a>: only future operations are affected.</p> </div> </dd>
</dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.cuda.ExternalStream.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.cuda.ExternalStream.html</a>
  </p>
</div>
