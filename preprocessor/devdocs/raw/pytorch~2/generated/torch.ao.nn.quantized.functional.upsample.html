<h1 id="upsample">upsample</h1> <dl class="py class"> <dt class="sig sig-object py" id="torch.ao.nn.quantized.functional.upsample">
<code>class torch.ao.nn.quantized.functional.upsample(input, size=None, scale_factor=None, mode='nearest', align_corners=None)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/nn/quantized/functional.html#upsample"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Upsamples the input to either the given <code>size</code> or the given <code>scale_factor</code></p> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>This function is deprecated in favor of <a class="reference internal" href="torch.ao.nn.quantized.functional.interpolate#torch.ao.nn.quantized.functional.interpolate" title="torch.ao.nn.quantized.functional.interpolate"><code>torch.ao.nn.quantized.functional.interpolate()</code></a>. This is equivalent with <code>nn.quantized.functional.interpolate(...)</code>.</p> </div> <p>See <a class="reference internal" href="torch.nn.functional.interpolate#torch.nn.functional.interpolate" title="torch.nn.functional.interpolate"><code>torch.nn.functional.interpolate()</code></a> for implementation details.</p> <p>The input dimensions are interpreted in the form: <code>mini-batch x channels x [optional depth] x [optional height] x width</code>.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The input quantization parameters propagate to the output.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Only 2D input is supported for quantized inputs</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Only the following modes are supported for the quantized inputs:</p> <ul class="simple"> <li><code>bilinear</code></li> <li><code>nearest</code></li> </ul> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – quantized input tensor</li> <li>
<strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em> or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>] or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>] or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>]</em>) – output spatial size.</li> <li>
<strong>scale_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em> or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em>]</em>) – multiplier for spatial size. Has to be an integer.</li> <li>
<strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>) – algorithm used for upsampling: <code>'nearest'</code> | <code>'bilinear'</code>
</li> <li>
<strong>align_corners</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – Geometrically, we consider the pixels of the input and output as squares rather than points. If set to <code>True</code>, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels. If set to <code>False</code>, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation <em>independent</em> of input size when <code>scale_factor</code> is kept the same. This only has an effect when <code>mode</code> is <code>'bilinear'</code>. Default: <code>False</code>
</li> </ul> </dd> </dl> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>With <code>align_corners = True</code>, the linearly interpolating modes (<code>bilinear</code>) don’t proportionally align the output and input pixels, and thus the output values can depend on the input size. This was the default behavior for these modes up to version 0.3.1. Since then, the default behavior is <code>align_corners = False</code>. See <a class="reference internal" href="torch.nn.upsample#torch.nn.Upsample" title="torch.nn.Upsample"><code>Upsample</code></a> for concrete examples on how this affects the outputs.</p> </div> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.ao.nn.quantized.functional.upsample.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.ao.nn.quantized.functional.upsample.html</a>
  </p>
</div>
