<h1 id="torch-nn-utils-parametrizations-orthogonal">torch.nn.utils.parametrizations.orthogonal</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.nn.utils.parametrizations.orthogonal">
<code>torch.nn.utils.parametrizations.orthogonal(module, name='weight', orthogonal_map=None, *, use_trivialization=True)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/nn/utils/parametrizations.html#orthogonal"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Applies an orthogonal or unitary parametrization to a matrix or a batch of matrices.</p> <p>Letting <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">K</mi></mrow><annotation encoding="application/x-tex">\mathbb{K}</annotation></semantics></math></span></span></span> be <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\mathbb{R}</annotation></semantics></math></span></span></span> or <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">C</mi></mrow><annotation encoding="application/x-tex">\mathbb{C}</annotation></semantics></math></span></span></span>, the parametrized matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>∈</mo><msup><mi mathvariant="double-struck">K</mi><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">Q \in \mathbb{K}^{m \times n}</annotation></semantics></math></span></span></span> is <strong>orthogonal</strong> as</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msup><mi>Q</mi><mtext>H</mtext></msup><mi>Q</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo>=</mo><msub><mi mathvariant="normal">I</mi><mi>n</mi></msub><mpadded width="0px"><mrow><mspace width="2em"></mspace><mtext>if </mtext><mi>m</mi><mo>≥</mo><mi>n</mi></mrow></mpadded></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>Q</mi><msup><mi>Q</mi><mtext>H</mtext></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo>=</mo><msub><mi mathvariant="normal">I</mi><mi>m</mi></msub><mpadded width="0px"><mrow><mspace width="2em"></mspace><mtext>if </mtext><mi>m</mi><mo>&lt;</mo><mi>n</mi></mrow></mpadded></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{align*} Q^{\text{H}}Q &amp;= \mathrm{I}_n \mathrlap{\qquad \text{if }m \geq n}\\ QQ^{\text{H}} &amp;= \mathrm{I}_m \mathrlap{\qquad \text{if }m &lt; n} \end{align*}</annotation></semantics></math></span></span></span>
</div>
<p>where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>Q</mi><mtext>H</mtext></msup></mrow><annotation encoding="application/x-tex">Q^{\text{H}}</annotation></semantics></math></span></span></span> is the conjugate transpose when <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span></span></span> is complex and the transpose when <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span></span></span> is real-valued, and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">I</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\mathrm{I}_n</annotation></semantics></math></span></span></span> is the <code>n</code>-dimensional identity matrix. In plain words, <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span></span></span> will have orthonormal columns whenever <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>≥</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \geq n</annotation></semantics></math></span></span></span> and orthonormal rows otherwise.</p> <p>If the tensor has more than two dimensions, we consider it as a batch of matrices of shape <code>(…, m, n)</code>.</p> <p>The matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span></span></span> may be parametrized via three different <code>orthogonal_map</code> in terms of the original tensor:</p> <ul class="simple"> <li>
<code>"matrix_exp"</code>/<code>"cayley"</code>: the <a class="reference internal" href="torch.matrix_exp#torch.matrix_exp" title="torch.matrix_exp"><code>matrix_exp()</code></a> <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>=</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q = \exp(A)</annotation></semantics></math></span></span></span> and the <a class="reference external" href="https://en.wikipedia.org/wiki/Cayley_transform#Matrix_map">Cayley map</a> <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi mathvariant="normal">I</mi><mi>n</mi></msub><mo>+</mo><mi>A</mi><mi mathvariant="normal">/</mi><mn>2</mn><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi mathvariant="normal">I</mi><mi>n</mi></msub><mo>−</mo><mi>A</mi><mi mathvariant="normal">/</mi><mn>2</mn><msup><mo stretchy="false">)</mo><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">Q = (\mathrm{I}_n + A/2)(\mathrm{I}_n - A/2)^{-1}</annotation></semantics></math></span></span></span> are applied to a skew-symmetric <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span></span> to give an orthogonal matrix.</li> <li>
<code>"householder"</code>: computes a product of Householder reflectors (<a class="reference internal" href="torch.linalg.householder_product#torch.linalg.householder_product" title="torch.linalg.householder_product"><code>householder_product()</code></a>).</li> </ul> <p><code>"matrix_exp"</code>/<code>"cayley"</code> often make the parametrized weight converge faster than <code>"householder"</code>, but they are slower to compute for very thin or very wide matrices.</p> <p>If <code>use_trivialization=True</code> (default), the parametrization implements the “Dynamic Trivialization Framework”, where an extra matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>∈</mo><msup><mi mathvariant="double-struck">K</mi><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">B \in \mathbb{K}^{n \times n}</annotation></semantics></math></span></span></span> is stored under <code>module.parametrizations.weight[0].base</code>. This helps the convergence of the parametrized layer at the expense of some extra memory use. See <a class="reference external" href="https://arxiv.org/abs/1909.09501">Trivializations for Gradient-Based Optimization on Manifolds</a> .</p> <p>Initial value of <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span></span></span>: If the original tensor is not parametrized and <code>use_trivialization=True</code> (default), the initial value of <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span></span></span> is that of the original tensor if it is orthogonal (or unitary in the complex case) and it is orthogonalized via the QR decomposition otherwise (see <a class="reference internal" href="torch.linalg.qr#torch.linalg.qr" title="torch.linalg.qr"><code>torch.linalg.qr()</code></a>). Same happens when it is not parametrized and <code>orthogonal_map="householder"</code> even when <code>use_trivialization=False</code>. Otherwise, the initial value is the result of the composition of all the registered parametrizations applied to the original tensor.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This function is implemented using the parametrization functionality in <a class="reference internal" href="torch.nn.utils.parametrize.register_parametrization#torch.nn.utils.parametrize.register_parametrization" title="torch.nn.utils.parametrize.register_parametrization"><code>register_parametrization()</code></a>.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>module</strong> (<a class="reference internal" href="torch.nn.module#torch.nn.Module" title="torch.nn.Module">nn.Module</a>) – module on which to register the parametrization.</li> <li>
<strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a><em>, </em><em>optional</em>) – name of the tensor to make orthogonal. Default: <code>"weight"</code>.</li> <li>
<strong>orthogonal_map</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a><em>, </em><em>optional</em>) – One of the following: <code>"matrix_exp"</code>, <code>"cayley"</code>, <code>"householder"</code>. Default: <code>"matrix_exp"</code> if the matrix is square or complex, <code>"householder"</code> otherwise.</li> <li>
<strong>use_trivialization</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – whether to use the dynamic trivialization framework. Default: <code>True</code>.</li> </ul> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<p>The original module with an orthogonal parametrization registered to the specified weight</p> </dd> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="torch.nn.module#torch.nn.Module" title="torch.nn.modules.module.Module">Module</a></p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; orth_linear = orthogonal(nn.Linear(20, 40))
&gt;&gt;&gt; orth_linear
ParametrizedLinear(
in_features=20, out_features=40, bias=True
(parametrizations): ModuleDict(
    (weight): ParametrizationList(
    (0): _Orthogonal()
    )
)
)
&gt;&gt;&gt; Q = orth_linear.weight
&gt;&gt;&gt; torch.dist(Q.T @ Q, torch.eye(20))
tensor(4.9332e-07)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.nn.utils.parametrizations.orthogonal.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.nn.utils.parametrizations.orthogonal.html</a>
  </p>
</div>
