<h1 id="torch-nn-utils-prune-l1-unstructured">torch.nn.utils.prune.l1_unstructured</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.nn.utils.prune.l1_unstructured">
<code>torch.nn.utils.prune.l1_unstructured(module, name, amount, importance_scores=None)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/nn/utils/prune.html#l1_unstructured"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Prunes tensor corresponding to parameter called <code>name</code> in <code>module</code> by removing the specified <code>amount</code> of (currently unpruned) units with the lowest L1-norm. Modifies module in place (and also return the modified module) by:</p> <ol class="arabic simple"> <li>adding a named buffer called <code>name+'_mask'</code> corresponding to the binary mask applied to the parameter <code>name</code> by the pruning method.</li> <li>replacing the parameter <code>name</code> by its pruned version, while the original (unpruned) parameter is stored in a new parameter named <code>name+'_orig'</code>.</li> </ol> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>module</strong> (<a class="reference internal" href="torch.nn.module#torch.nn.Module" title="torch.nn.Module">nn.Module</a>) – module containing the tensor to prune</li> <li>
<strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>) – parameter name within <code>module</code> on which pruning will act.</li> <li>
<strong>amount</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a>) – quantity of parameters to prune. If <code>float</code>, should be between 0.0 and 1.0 and represent the fraction of parameters to prune. If <code>int</code>, it represents the absolute number of parameters to prune.</li> <li>
<strong>importance_scores</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">torch.Tensor</a>) – tensor of importance scores (of same shape as module parameter) used to compute mask for pruning. The values in this tensor indicate the importance of the corresponding elements in the parameter being pruned. If unspecified or None, the module parameter will be used in its place.</li> </ul> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<p>modified (i.e. pruned) version of the input module</p> </dd> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p>module (<a class="reference internal" href="torch.nn.module#torch.nn.Module" title="torch.nn.Module">nn.Module</a>)</p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; m = prune.l1_unstructured(nn.Linear(2, 3), 'weight', amount=0.2)
&gt;&gt;&gt; m.state_dict().keys()
odict_keys(['bias', 'weight_orig', 'weight_mask'])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.nn.utils.prune.l1_unstructured.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.nn.utils.prune.l1_unstructured.html</a>
  </p>
</div>
