<h1 id="torch-linalg-vander">torch.linalg.vander</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.linalg.vander">
<code>torch.linalg.vander(x, N=None) → Tensor</code> </dt> <dd>
<p>Generates a Vandermonde matrix.</p> <p>Returns the Vandermonde matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span></span></span></p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>V</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>1</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>x</mi><mn>1</mn><mn>2</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">…</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>x</mi><mn>1</mn><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></msubsup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>2</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>x</mi><mn>2</mn><mn>2</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">…</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>x</mi><mn>2</mn><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></msubsup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mn>3</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>x</mi><mn>3</mn><mn>2</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">…</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>x</mi><mn>3</mn><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></msubsup></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mi><mi mathvariant="normal">⋮</mi><mpadded height="0em" voffset="0em"><mspace mathbackground="black" width="0em" height="1.5em"></mspace></mpadded></mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mi><mi mathvariant="normal">⋮</mi><mpadded height="0em" voffset="0em"><mspace mathbackground="black" width="0em" height="1.5em"></mspace></mpadded></mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mi><mi mathvariant="normal">⋮</mi><mpadded height="0em" voffset="0em"><mspace mathbackground="black" width="0em" height="1.5em"></mspace></mpadded></mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">⋱</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mi><mi mathvariant="normal">⋮</mi><mpadded height="0em" voffset="0em"><mspace mathbackground="black" width="0em" height="1.5em"></mspace></mpadded></mi></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>x</mi><mi>n</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>x</mi><mi>n</mi><mn>2</mn></msubsup></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mo lspace="0em" rspace="0em">…</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msubsup><mi>x</mi><mi>n</mi><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></msubsup></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">V = \begin{pmatrix} 1 &amp; x_1 &amp; x_1^2 &amp; \dots &amp; x_1^{N-1}\\ 1 &amp; x_2 &amp; x_2^2 &amp; \dots &amp; x_2^{N-1}\\ 1 &amp; x_3 &amp; x_3^2 &amp; \dots &amp; x_3^{N-1}\\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp;\vdots \\ 1 &amp; x_n &amp; x_n^2 &amp; \dots &amp; x_n^{N-1} \end{pmatrix}.</annotation></semantics></math></span></span></span>
</div>
<p>for <code>N &gt; 1</code>. If <code>N</code><code>= None</code>, then <code>N = x.size(-1)</code> so that the output is a square matrix.</p> <p>Supports inputs of float, double, cfloat, cdouble, and integral dtypes. Also supports batches of vectors, and if <code>x</code> is a batch of vectors then the output has the same batch dimensions.</p> <p>Differences with <code>numpy.vander</code>:</p> <ul class="simple"> <li>Unlike <code>numpy.vander</code>, this function returns the powers of <code>x</code> in ascending order. To get them in the reverse order call <code>linalg.vander(x, N).flip(-1)</code>.</li> </ul> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>x</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – tensor of shape <code>(*, n)</code> where <code>*</code> is zero or more batch dimensions consisting of vectors.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>N</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><em>optional</em>) – Number of columns in the output. Default: <code>x.size(-1)</code></p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; x = torch.tensor([1, 2, 3, 5])
&gt;&gt;&gt; linalg.vander(x)
tensor([[  1,   1,   1,   1],
        [  1,   2,   4,   8],
        [  1,   3,   9,  27],
        [  1,   5,  25, 125]])
&gt;&gt;&gt; linalg.vander(x, N=3)
tensor([[ 1,  1,  1],
        [ 1,  2,  4],
        [ 1,  3,  9],
        [ 1,  5, 25]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.linalg.vander.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.linalg.vander.html</a>
  </p>
</div>
