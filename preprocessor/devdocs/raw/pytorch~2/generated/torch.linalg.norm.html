<h1 id="torch-linalg-norm">torch.linalg.norm</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.linalg.norm">
<code>torch.linalg.norm(A, ord=None, dim=None, keepdim=False, *, out=None, dtype=None) → Tensor</code> </dt> <dd>
<p>Computes a vector or matrix norm.</p> <p>Supports input of float, double, cfloat and cdouble dtypes.</p> <p>Whether this function computes a vector or matrix norm is determined as follows:</p> <ul class="simple"> <li>If <code>dim</code> is an <code>int</code>, the vector norm will be computed.</li> <li>If <code>dim</code> is a <code>2</code>-<code>tuple</code>, the matrix norm will be computed.</li> <li>If <code>dim</code><code>= None</code> and <code>ord</code><code>= None</code>, <code>A</code> will be flattened to 1D and the <code>2</code>-norm of the resulting vector will be computed.</li> <li>If <code>dim</code><code>= None</code> and <code>ord</code> <code>!= None</code>, <code>A</code> must be 1D or 2D.</li> </ul> <p><code>ord</code> defines the norm that is computed. The following norms are supported:</p> <table class="docutils colwidths-auto align-default"> <thead> <tr>
<th class="head"><p><code>ord</code></p></th> <th class="head"><p>norm for matrices</p></th> <th class="head"><p>norm for vectors</p></th> </tr> </thead>  <tr>
<td><p><code>None</code> (default)</p></td> <td><p>Frobenius norm</p></td> <td><p><code>2</code>-norm (see below)</p></td> </tr> <tr>
<td><p><code>‘fro’</code></p></td> <td><p>Frobenius norm</p></td> <td><p>– not supported –</p></td> </tr> <tr>
<td><p><code>‘nuc’</code></p></td> <td><p>nuclear norm</p></td> <td><p>– not supported –</p></td> </tr> <tr>
<td><p><code>inf</code></p></td> <td><p><code>max(sum(abs(x), dim=1))</code></p></td> <td><p><code>max(abs(x))</code></p></td> </tr> <tr>
<td><p><code>-inf</code></p></td> <td><p><code>min(sum(abs(x), dim=1))</code></p></td> <td><p><code>min(abs(x))</code></p></td> </tr> <tr>
<td><p><code>0</code></p></td> <td><p>– not supported –</p></td> <td><p><code>sum(x != 0)</code></p></td> </tr> <tr>
<td><p><code>1</code></p></td> <td><p><code>max(sum(abs(x), dim=0))</code></p></td> <td><p>as below</p></td> </tr> <tr>
<td><p><code>-1</code></p></td> <td><p><code>min(sum(abs(x), dim=0))</code></p></td> <td><p>as below</p></td> </tr> <tr>
<td><p><code>2</code></p></td> <td><p>largest singular value</p></td> <td><p>as below</p></td> </tr> <tr>
<td><p><code>-2</code></p></td> <td><p>smallest singular value</p></td> <td><p>as below</p></td> </tr> <tr>
<td><p>other <code>int</code> or <code>float</code></p></td> <td><p>– not supported –</p></td> <td><p><code>sum(abs(x)^{ord})^{(1 / ord)}</code></p></td> </tr>  </table> <p>where <code>inf</code> refers to <code>float(‘inf’)</code>, NumPy’s <code>inf</code> object, or any equivalent object.</p> <div class="admonition seealso"> <p class="admonition-title">See also</p> <p><a class="reference internal" href="torch.linalg.vector_norm#torch.linalg.vector_norm" title="torch.linalg.vector_norm"><code>torch.linalg.vector_norm()</code></a> computes a vector norm.</p> <p><a class="reference internal" href="torch.linalg.matrix_norm#torch.linalg.matrix_norm" title="torch.linalg.matrix_norm"><code>torch.linalg.matrix_norm()</code></a> computes a matrix norm.</p> <p>The above functions are often clearer and more flexible than using <a class="reference internal" href="#torch.linalg.norm" title="torch.linalg.norm"><code>torch.linalg.norm()</code></a>. For example, <code>torch.linalg.norm(A, ord=1, dim=(0, 1))</code> always computes a matrix norm, but with <code>torch.linalg.vector_norm(A, ord=1, dim=(0, 1))</code> it is possible to compute a vector norm over the two dimensions.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>A</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – tensor of shape <code>(*, n)</code> or <code>(*, m, n)</code> where <code>*</code> is zero or more batch dimensions</li> <li>
<strong>ord</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em>, </em><em>inf</em><em>, </em><em>-inf</em><em>, </em><em>'fro'</em><em>, </em><em>'nuc'</em><em>, </em><em>optional</em>) – order of norm. Default: <code>None</code>
</li> <li>
<strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>]</em><em>, </em><em>optional</em>) – dimensions over which to compute the vector or matrix norm. See above for the behavior when <code>dim</code><code>= None</code>. Default: <code>None</code>
</li> <li>
<strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – If set to <code>True</code>, the reduced dimensions are retained in the result as dimensions with size one. Default: <code>False</code>
</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<ul class="simple"> <li>
<strong>out</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – output tensor. Ignored if <code>None</code>. Default: <code>None</code>.</li> <li>
<strong>dtype</strong> (<a class="reference internal" href="../tensor_attributes#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a>, optional) – If specified, the input tensor is cast to <code>dtype</code> before performing the operation, and the returned tensor’s type will be <code>dtype</code>. Default: <code>None</code>
</li> </ul> </dd> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<p>A real-valued tensor, even when <code>A</code> is complex.</p> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; from torch import linalg as LA
&gt;&gt;&gt; a = torch.arange(9, dtype=torch.float) - 4
&gt;&gt;&gt; a
tensor([-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.])
&gt;&gt;&gt; B = a.reshape((3, 3))
&gt;&gt;&gt; B
tensor([[-4., -3., -2.],
        [-1.,  0.,  1.],
        [ 2.,  3.,  4.]])

&gt;&gt;&gt; LA.norm(a)
tensor(7.7460)
&gt;&gt;&gt; LA.norm(B)
tensor(7.7460)
&gt;&gt;&gt; LA.norm(B, 'fro')
tensor(7.7460)
&gt;&gt;&gt; LA.norm(a, float('inf'))
tensor(4.)
&gt;&gt;&gt; LA.norm(B, float('inf'))
tensor(9.)
&gt;&gt;&gt; LA.norm(a, -float('inf'))
tensor(0.)
&gt;&gt;&gt; LA.norm(B, -float('inf'))
tensor(2.)

&gt;&gt;&gt; LA.norm(a, 1)
tensor(20.)
&gt;&gt;&gt; LA.norm(B, 1)
tensor(7.)
&gt;&gt;&gt; LA.norm(a, -1)
tensor(0.)
&gt;&gt;&gt; LA.norm(B, -1)
tensor(6.)
&gt;&gt;&gt; LA.norm(a, 2)
tensor(7.7460)
&gt;&gt;&gt; LA.norm(B, 2)
tensor(7.3485)

&gt;&gt;&gt; LA.norm(a, -2)
tensor(0.)
&gt;&gt;&gt; LA.norm(B.double(), -2)
tensor(1.8570e-16, dtype=torch.float64)
&gt;&gt;&gt; LA.norm(a, 3)
tensor(5.8480)
&gt;&gt;&gt; LA.norm(a, -3)
tensor(0.)
</pre> <p>Using the <code>dim</code> argument to compute vector norms:</p> <pre data-language="python">&gt;&gt;&gt; c = torch.tensor([[1., 2., 3.],
...                   [-1, 1, 4]])
&gt;&gt;&gt; LA.norm(c, dim=0)
tensor([1.4142, 2.2361, 5.0000])
&gt;&gt;&gt; LA.norm(c, dim=1)
tensor([3.7417, 4.2426])
&gt;&gt;&gt; LA.norm(c, ord=1, dim=1)
tensor([6., 6.])
</pre> <p>Using the <code>dim</code> argument to compute matrix norms:</p> <pre data-language="python">&gt;&gt;&gt; A = torch.arange(8, dtype=torch.float).reshape(2, 2, 2)
&gt;&gt;&gt; LA.norm(A, dim=(1,2))
tensor([ 3.7417, 11.2250])
&gt;&gt;&gt; LA.norm(A[0, :, :]), LA.norm(A[1, :, :])
(tensor(3.7417), tensor(11.2250))
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.linalg.norm.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.linalg.norm.html</a>
  </p>
</div>
