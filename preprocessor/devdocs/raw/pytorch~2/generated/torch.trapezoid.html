<h1 id="torch-trapezoid">torch.trapezoid</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.trapezoid">
<code>torch.trapezoid(y, x=None, *, dx=None, dim=-1) → Tensor</code> </dt> <dd>
<p>Computes the <a class="reference external" href="https://en.wikipedia.org/wiki/Trapezoidal_rule">trapezoidal rule</a> along <code>dim</code>. By default the spacing between elements is assumed to be 1, but <code>dx</code> can be used to specify a different constant spacing, and <code>x</code> can be used to specify arbitrary spacing along <code>dim</code>.</p> <p>Assuming <code>y</code> is a one-dimensional tensor with elements <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">{y_0, y_1, ..., y_n}</annotation></semantics></math></span></span></span>, the default computation is</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></munderover><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} \sum_{i = 1}^{n-1} \frac{1}{2} (y_i + y_{i-1}) \end{aligned} </annotation></semantics></math></span></span></span>
</div>
<p>When <code>dx</code> is specified the computation becomes</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></munderover><mfrac><mrow><mi mathvariant="normal">Δ</mi><mi>x</mi></mrow><mn>2</mn></mfrac><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} \sum_{i = 1}^{n-1} \frac{\Delta x}{2} (y_i + y_{i-1}) \end{aligned} </annotation></semantics></math></span></span></span>
</div>
<p>effectively multiplying the result by <code>dx</code>. When <code>x</code> is specified, assuming <code>x</code> is also a one-dimensional tensor with elements <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">{x_0, x_1, ..., x_n}</annotation></semantics></math></span></span></span>, the computation becomes</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></munderover><mfrac><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>x</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><mn>2</mn></mfrac><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>+</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} \sum_{i = 1}^{n-1} \frac{(x_i - x_{i-1})}{2} (y_i + y_{i-1}) \end{aligned} </annotation></semantics></math></span></span></span>
</div>
<p>When <code>x</code> and <code>y</code> have the same size, the computation is as described above and no broadcasting is needed. The broadcasting behavior of this function is as follows when their sizes are different. For both <code>x</code> and <code>y</code>, the function computes the difference between consecutive elements along dimension <code>dim</code>. This effectively creates two tensors, <code>x_diff</code> and <code>y_diff</code>, that have the same shape as the original tensors except their lengths along the dimension <code>dim</code> is reduced by 1. After that, those two tensors are broadcast together to compute final output as part of the trapezoidal rule. See the examples below for details.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The trapezoidal rule is a technique for approximating the definite integral of a function by averaging its left and right Riemann sums. The approximation becomes more accurate as the resolution of the partition increases.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>y</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – Values to use when computing the trapezoidal rule.</li> <li>
<strong>x</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – If specified, defines spacing between values as specified above.</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<ul class="simple"> <li>
<strong>dx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a>) – constant spacing between values. If neither <code>x</code> or <code>dx</code> are specified then this defaults to 1. Effectively multiplies the result by its value.</li> <li>
<strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>) – The dimension along which to compute the trapezoidal rule. The last (inner-most) dimension by default.</li> </ul> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; # Computes the trapezoidal rule in 1D, spacing is implicitly 1
&gt;&gt;&gt; y = torch.tensor([1, 5, 10])
&gt;&gt;&gt; torch.trapezoid(y)
tensor(10.5)

&gt;&gt;&gt; # Computes the same trapezoidal rule directly to verify
&gt;&gt;&gt; (1 + 10 + 10) / 2
10.5

&gt;&gt;&gt; # Computes the trapezoidal rule in 1D with constant spacing of 2
&gt;&gt;&gt; # NOTE: the result is the same as before, but multiplied by 2
&gt;&gt;&gt; torch.trapezoid(y, dx=2)
21.0

&gt;&gt;&gt; # Computes the trapezoidal rule in 1D with arbitrary spacing
&gt;&gt;&gt; x = torch.tensor([1, 3, 6])
&gt;&gt;&gt; torch.trapezoid(y, x)
28.5

&gt;&gt;&gt; # Computes the same trapezoidal rule directly to verify
&gt;&gt;&gt; ((3 - 1) * (1 + 5) + (6 - 3) * (5 + 10)) / 2
28.5

&gt;&gt;&gt; # Computes the trapezoidal rule for each row of a 3x3 matrix
&gt;&gt;&gt; y = torch.arange(9).reshape(3, 3)
tensor([[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]])
&gt;&gt;&gt; torch.trapezoid(y)
tensor([ 2., 8., 14.])

&gt;&gt;&gt; # Computes the trapezoidal rule for each column of the matrix
&gt;&gt;&gt; torch.trapezoid(y, dim=0)
tensor([ 6., 8., 10.])

&gt;&gt;&gt; # Computes the trapezoidal rule for each row of a 3x3 ones matrix
&gt;&gt;&gt; #   with the same arbitrary spacing
&gt;&gt;&gt; y = torch.ones(3, 3)
&gt;&gt;&gt; x = torch.tensor([1, 3, 6])
&gt;&gt;&gt; torch.trapezoid(y, x)
array([5., 5., 5.])

&gt;&gt;&gt; # Computes the trapezoidal rule for each row of a 3x3 ones matrix
&gt;&gt;&gt; #   with different arbitrary spacing per row
&gt;&gt;&gt; y = torch.ones(3, 3)
&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [1, 3, 5], [1, 4, 7]])
&gt;&gt;&gt; torch.trapezoid(y, x)
array([2., 4., 6.])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.trapezoid.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.trapezoid.html</a>
  </p>
</div>
