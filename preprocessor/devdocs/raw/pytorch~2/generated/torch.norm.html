<h1 id="torch-norm">torch.norm</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.norm">
<code>torch.norm(input, p='fro', dim=None, keepdim=False, out=None, dtype=None)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/functional.html#norm"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the matrix norm or vector norm of a given tensor.</p> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>torch.norm is deprecated and may be removed in a future PyTorch release. Its documentation and behavior may be incorrect, and it is no longer actively maintained.</p> <p>Use <a class="reference internal" href="torch.linalg.vector_norm#torch.linalg.vector_norm" title="torch.linalg.vector_norm"><code>torch.linalg.vector_norm()</code></a> when computing vector norms and <a class="reference internal" href="torch.linalg.matrix_norm#torch.linalg.matrix_norm" title="torch.linalg.matrix_norm"><code>torch.linalg.matrix_norm()</code></a> when computing matrix norms. For a function with a similar behavior as this one see <a class="reference internal" href="torch.linalg.norm#torch.linalg.norm" title="torch.linalg.norm"><code>torch.linalg.norm()</code></a>. Note, however, the signature for these functions is slightly different than the signature for <code>torch.norm</code>.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – The input tensor. Its data type must be either a floating point or complex type. For complex inputs, the norm is calculated using the absolute value of each element. If the input is complex and neither <a class="reference internal" href="../tensor_attributes#torch.dtype" title="torch.dtype"><code>dtype</code></a> nor <code>out</code> is specified, the result’s data type will be the corresponding floating point type (e.g. float if <code>input</code> is complexfloat).</li> <li>
<p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em>, </em><em>inf</em><em>, </em><em>-inf</em><em>, </em><em>'fro'</em><em>, </em><em>'nuc'</em><em>, </em><em>optional</em>) – </p>
<p>the order of norm. Default: <code>'fro'</code> The following norms can be calculated:</p> <table class="docutils colwidths-auto align-default"> <thead> <tr>
<th class="head"><p>ord</p></th> <th class="head"><p>matrix norm</p></th> <th class="head"><p>vector norm</p></th> </tr> </thead>  <tr>
<td><p>’fro’</p></td> <td><p>Frobenius norm</p></td> <td><p>–</p></td> </tr> <tr>
<td><p>‘nuc’</p></td> <td><p>nuclear norm</p></td> <td><p>–</p></td> </tr> <tr>
<td><p>Number</p></td> <td><p>–</p></td> <td><p>sum(abs(x)**ord)**(1./ord)</p></td> </tr>  </table> <p>The vector norm can be calculated across any number of dimensions. The corresponding dimensions of <code>input</code> are flattened into one dimension, and the norm is calculated on the flattened dimension.</p> <p>Frobenius norm produces the same result as <code>p=2</code> in all cases except when <code>dim</code> is a list of three or more dims, in which case Frobenius norm throws an error.</p> <p>Nuclear norm can only be calculated across exactly two dimensions.</p> </li> <li>
<strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a><em> of </em><em>ints</em><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)">list</a><em> of </em><em>ints</em><em>, </em><em>optional</em>) – Specifies which dimension or dimensions of <code>input</code> to calculate the norm across. If <code>dim</code> is <code>None</code>, the norm will be calculated across all dimensions of <code>input</code>. If the norm type indicated by <code>p</code> does not support the specified number of dimensions, an error will occur.</li> <li>
<strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – whether the output tensors have <code>dim</code> retained or not. Ignored if <code>dim</code> = <code>None</code> and <code>out</code> = <code>None</code>. Default: <code>False</code>
</li> <li>
<strong>out</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor. Ignored if <code>dim</code> = <code>None</code> and <code>out</code> = <code>None</code>.</li> <li>
<strong>dtype</strong> (<a class="reference internal" href="../tensor_attributes#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a>, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to <a class="reference internal" href="../tensor_attributes#torch.dtype" title="torch.dtype"><code>dtype</code></a> while performing the operation. Default: None.</li> </ul> </dd> </dl> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Even though <code>p='fro'</code> supports any number of dimensions, the true mathematical definition of Frobenius norm only applies to tensors with exactly two dimensions. <a class="reference internal" href="torch.linalg.matrix_norm#torch.linalg.matrix_norm" title="torch.linalg.matrix_norm"><code>torch.linalg.matrix_norm()</code></a> with <code>ord='fro'</code> aligns with the mathematical definition, since it can only be applied across exactly two dimensions.</p> </div> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; import torch
&gt;&gt;&gt; a = torch.arange(9, dtype= torch.float) - 4
&gt;&gt;&gt; b = a.reshape((3, 3))
&gt;&gt;&gt; torch.norm(a)
tensor(7.7460)
&gt;&gt;&gt; torch.norm(b)
tensor(7.7460)
&gt;&gt;&gt; torch.norm(a, float('inf'))
tensor(4.)
&gt;&gt;&gt; torch.norm(b, float('inf'))
tensor(4.)
&gt;&gt;&gt; c = torch.tensor([[ 1, 2, 3], [-1, 1, 4]] , dtype=torch.float)
&gt;&gt;&gt; torch.norm(c, dim=0)
tensor([1.4142, 2.2361, 5.0000])
&gt;&gt;&gt; torch.norm(c, dim=1)
tensor([3.7417, 4.2426])
&gt;&gt;&gt; torch.norm(c, p=1, dim=1)
tensor([6., 6.])
&gt;&gt;&gt; d = torch.arange(8, dtype=torch.float).reshape(2, 2, 2)
&gt;&gt;&gt; torch.norm(d, dim=(1, 2))
tensor([ 3.7417, 11.2250])
&gt;&gt;&gt; torch.norm(d[0, :, :]), torch.norm(d[1, :, :])
(tensor(3.7417), tensor(11.2250))
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.norm.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.norm.html</a>
  </p>
</div>
