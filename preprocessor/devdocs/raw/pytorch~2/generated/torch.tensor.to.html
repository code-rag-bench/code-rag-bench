<h1 id="torch-tensor-to">torch.Tensor.to</h1> <dl class="py method"> <dt class="sig sig-object py" id="torch.Tensor.to">
<code>Tensor.to(*args, **kwargs) → Tensor</code> </dt> <dd>
<p>Performs Tensor dtype and/or device conversion. A <a class="reference internal" href="../tensor_attributes#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a> and <a class="reference internal" href="../tensor_attributes#torch.device" title="torch.device"><code>torch.device</code></a> are inferred from the arguments of <code>self.to(*args, **kwargs)</code>.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>If the <code>self</code> Tensor already has the correct <a class="reference internal" href="../tensor_attributes#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a> and <a class="reference internal" href="../tensor_attributes#torch.device" title="torch.device"><code>torch.device</code></a>, then <code>self</code> is returned. Otherwise, the returned tensor is a copy of <code>self</code> with the desired <a class="reference internal" href="../tensor_attributes#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a> and <a class="reference internal" href="../tensor_attributes#torch.device" title="torch.device"><code>torch.device</code></a>.</p> </div> <p>Here are the ways to call <code>to</code>:</p> <dl class="py method"> <dt class="sig sig-object py"> <span class="sig-name descname">to</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">dtype</span></em>, <em class="sig-param"><span class="n">non_blocking</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">copy</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">memory_format</span><span class="o">=</span><span class="default_value">torch.preserve_format</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a></span></span>
</dt> <dd> <p>Returns a Tensor with the specified <a class="reference internal" href="../tensor_attributes#torch.dtype" title="torch.dtype"><code>dtype</code></a></p> <dl class="simple"> <dt>Args:</dt>
<dd>
<p>memory_format (<a class="reference internal" href="../tensor_attributes#torch.memory_format" title="torch.memory_format"><code>torch.memory_format</code></a>, optional): the desired memory format of returned Tensor. Default: <code>torch.preserve_format</code>.</p> </dd> </dl>  </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py"> <span class="sig-prename descclassname">torch.</span><span class="sig-name descname">to</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">device</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">dtype</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">non_blocking</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">copy</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">memory_format</span><span class="o">=</span><span class="default_value">torch.preserve_format</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a></span></span>
</dt> <dd> <p>Returns a Tensor with the specified <a class="reference internal" href="../tensor_attributes#torch.device" title="torch.device"><code>device</code></a> and (optional) <a class="reference internal" href="../tensor_attributes#torch.dtype" title="torch.dtype"><code>dtype</code></a>. If <a class="reference internal" href="../tensor_attributes#torch.dtype" title="torch.dtype"><code>dtype</code></a> is <code>None</code> it is inferred to be <code>self.dtype</code>. When <code>non_blocking</code>, tries to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor. When <code>copy</code> is set, a new Tensor is created even when the Tensor already matches the desired conversion.</p> <dl class="simple"> <dt>Args:</dt>
<dd>
<p>memory_format (<a class="reference internal" href="../tensor_attributes#torch.memory_format" title="torch.memory_format"><code>torch.memory_format</code></a>, optional): the desired memory format of returned Tensor. Default: <code>torch.preserve_format</code>.</p> </dd> </dl>  </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py"> <span class="sig-prename descclassname">torch.</span><span class="sig-name descname">to</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">other</span></em>, <em class="sig-param"><span class="n">non_blocking</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">copy</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a></span></span>
</dt> <dd> <p>Returns a Tensor with same <a class="reference internal" href="../tensor_attributes#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a> and <a class="reference internal" href="../tensor_attributes#torch.device" title="torch.device"><code>torch.device</code></a> as the Tensor <code>other</code>. When <code>non_blocking</code>, tries to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor. When <code>copy</code> is set, a new Tensor is created even when the Tensor already matches the desired conversion.</p>  </dd>
</dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; tensor = torch.randn(2, 2)  # Initially dtype=float32, device=cpu
&gt;&gt;&gt; tensor.to(torch.float64)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], dtype=torch.float64)

&gt;&gt;&gt; cuda0 = torch.device('cuda:0')
&gt;&gt;&gt; tensor.to(cuda0)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], device='cuda:0')

&gt;&gt;&gt; tensor.to(cuda0, dtype=torch.float64)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')

&gt;&gt;&gt; other = torch.randn((), dtype=torch.float64, device=cuda0)
&gt;&gt;&gt; tensor.to(other, non_blocking=True)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.Tensor.to.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.Tensor.to.html</a>
  </p>
</div>
