<h1 id="torch-linalg-ldl-factor-ex">torch.linalg.ldl_factor_ex</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.linalg.ldl_factor_ex">
<code>torch.linalg.ldl_factor_ex(A, *, hermitian=False, check_errors=False, out=None)</code> </dt> <dd>
<p>This is a version of <a class="reference internal" href="torch.linalg.ldl_factor#torch.linalg.ldl_factor" title="torch.linalg.ldl_factor"><code>ldl_factor()</code></a> that does not perform error checks unless <code>check_errors</code><code>= True</code>. It also returns the <code>info</code> tensor returned by <a class="reference external" href="https://www.netlib.org/lapack/explore-html/d3/db6/group__double_s_ycomputational_gad91bde1212277b3e909eb6af7f64858a.html">LAPACK’s sytrf</a>. <code>info</code> stores integer error codes from the backend library. A positive integer indicates the diagonal element of <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span></span></span> that is zero. Division by 0 will occur if the result is used for solving a system of linear equations. <code>info</code> filled with zeros indicates that the factorization was successful. If <code>check_errors=True</code> and <code>info</code> contains positive integers, then a <code>RuntimeError</code> is thrown.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>When the inputs are on a CUDA device, this function synchronizes only when <code>check_errors</code><code>= True</code>.</p> </div> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>This function is “experimental” and it may change in a future PyTorch release.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>A</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – tensor of shape <code>(*, n, n)</code> where <code>*</code> is zero or more batch dimensions consisting of symmetric or Hermitian matrices.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<ul class="simple"> <li>
<strong>hermitian</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – whether to consider the input to be Hermitian or symmetric. For real-valued matrices, this switch has no effect. Default: <code>False</code>.</li> <li>
<strong>check_errors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – controls whether to check the content of <code>info</code> and raise an error if it is non-zero. Default: <code>False</code>.</li> <li>
<strong>out</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a><em>, </em><em>optional</em>) – tuple of three tensors to write the output to. Ignored if <code>None</code>. Default: <code>None</code>.</li> </ul> </dd> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<p>A named tuple <code>(LD, pivots, info)</code>.</p> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; A = torch.randn(3, 3)
&gt;&gt;&gt; A = A @ A.mT # make symmetric
&gt;&gt;&gt; A
tensor([[7.2079, 4.2414, 1.9428],
        [4.2414, 3.4554, 0.3264],
        [1.9428, 0.3264, 1.3823]])
&gt;&gt;&gt; LD, pivots, info = torch.linalg.ldl_factor_ex(A)
&gt;&gt;&gt; LD
tensor([[ 7.2079,  0.0000,  0.0000],
        [ 0.5884,  0.9595,  0.0000],
        [ 0.2695, -0.8513,  0.1633]])
&gt;&gt;&gt; pivots
tensor([1, 2, 3], dtype=torch.int32)
&gt;&gt;&gt; info
tensor(0, dtype=torch.int32)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.linalg.ldl_factor_ex.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.linalg.ldl_factor_ex.html</a>
  </p>
</div>
