<h1 id="torch-logsumexp">torch.logsumexp</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.logsumexp">
<code>torch.logsumexp(input, dim, keepdim=False, *, out=None)</code> </dt> <dd>
<p>Returns the log of summed exponentials of each row of the <code>input</code> tensor in the given dimension <code>dim</code>. The computation is numerically stabilized.</p> <p>For summation index <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span></span></span> given by <code>dim</code> and other indices <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span></span></span>, the result is</p>  <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>logsumexp</mtext><mo stretchy="false">(</mo><mi>x</mi><msub><mo stretchy="false">)</mo><mi>i</mi></msub><mo>=</mo><mi>log</mi><mo>⁡</mo><munder><mo>∑</mo><mi>j</mi></munder><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{logsumexp}(x)_{i} = \log \sum_j \exp(x_{ij}) </annotation></semantics></math></span></span></span>
</div> <p>If <code>keepdim</code> is <code>True</code>, the output tensor is of the same size as <code>input</code> except in the dimension(s) <code>dim</code> where it is of size 1. Otherwise, <code>dim</code> is squeezed (see <a class="reference internal" href="torch.squeeze#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a>), resulting in the output tensor having 1 (or <code>len(dim)</code>) fewer dimension(s).</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</li> <li>
<strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a><em> of </em><em>ints</em><em>, </em><em>optional</em>) – the dimension or dimensions to reduce. If <code>None</code>, all dimensions are reduced.</li> <li>
<strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a>) – whether the output tensor has <code>dim</code> retained or not.</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; a = torch.randn(3, 3)
&gt;&gt;&gt; torch.logsumexp(a, 1)
tensor([1.4907, 1.0593, 1.5696])
&gt;&gt;&gt; torch.dist(torch.logsumexp(a, 1), torch.log(torch.sum(torch.exp(a), 1)))
tensor(1.6859e-07)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.logsumexp.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.logsumexp.html</a>
  </p>
</div>
