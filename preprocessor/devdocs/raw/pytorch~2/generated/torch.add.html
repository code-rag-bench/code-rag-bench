<h1 id="torch-add">torch.add</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.add">
<code>torch.add(input, other, *, alpha=1, out=None) → Tensor</code> </dt> <dd>
<p>Adds <code>other</code>, scaled by <code>alpha</code>, to <code>input</code>.</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext>out</mtext><mi>i</mi></msub><mo>=</mo><msub><mtext>input</mtext><mi>i</mi></msub><mo>+</mo><mtext>alpha</mtext><mo>×</mo><msub><mtext>other</mtext><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{{out}}_i = \text{{input}}_i + \text{{alpha}} \times \text{{other}}_i </annotation></semantics></math></span></span></span>
</div>
<p>Supports <a class="reference internal" href="https://pytorch.org/docs/2.1/notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcasting to a common shape</span></a>, <a class="reference internal" href="../tensor_attributes#type-promotion-doc"><span class="std std-ref">type promotion</span></a>, and integer, float, and complex inputs.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</li> <li>
<strong>other</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em> or </em><em>Number</em>) – the tensor or number to add to <code>input</code>.</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<ul class="simple"> <li>
<strong>alpha</strong> (<em>Number</em>) – the multiplier for <code>other</code>.</li> <li>
<strong>out</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</li> </ul> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; a = torch.randn(4)
&gt;&gt;&gt; a
tensor([ 0.0202,  1.0985,  1.3506, -0.6056])
&gt;&gt;&gt; torch.add(a, 20)
tensor([ 20.0202,  21.0985,  21.3506,  19.3944])

&gt;&gt;&gt; b = torch.randn(4)
&gt;&gt;&gt; b
tensor([-0.9732, -0.3497,  0.6245,  0.4022])
&gt;&gt;&gt; c = torch.randn(4, 1)
&gt;&gt;&gt; c
tensor([[ 0.3743],
        [-1.7724],
        [-0.5811],
        [-0.8017]])
&gt;&gt;&gt; torch.add(b, c, alpha=10)
tensor([[  2.7695,   3.3930,   4.3672,   4.1450],
        [-18.6971, -18.0736, -17.0994, -17.3216],
        [ -6.7845,  -6.1610,  -5.1868,  -5.4090],
        [ -8.9902,  -8.3667,  -7.3925,  -7.6147]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.add.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.add.html</a>
  </p>
</div>
