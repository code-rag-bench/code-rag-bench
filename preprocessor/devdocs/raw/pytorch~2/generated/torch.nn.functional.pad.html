<h1 id="torch-nn-functional-pad">torch.nn.functional.pad</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.nn.functional.pad">
<code>torch.nn.functional.pad(input, pad, mode='constant', value=None) → Tensor</code> </dt> <dd>
<p>Pads tensor.</p> <dl class="simple"> <dt>Padding size:</dt>
<dd>
<p>The padding size by which to pad some dimensions of <code>input</code> are described starting from the last dimension and moving forward. <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">⌊</mo><mfrac><mtext>len(pad)</mtext><mn>2</mn></mfrac><mo fence="true">⌋</mo></mrow><annotation encoding="application/x-tex">\left\lfloor\frac{\text{len(pad)}}{2}\right\rfloor</annotation></semantics></math></span></span></span> dimensions of <code>input</code> will be padded. For example, to pad only the last dimension of the input tensor, then <a class="reference internal" href="#torch.nn.functional.pad" title="torch.nn.functional.pad"><code>pad</code></a> has the form <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mtext>padding_left</mtext><mo separator="true">,</mo><mtext>padding_right</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\text{padding\_left}, \text{padding\_right})</annotation></semantics></math></span></span></span>; to pad the last 2 dimensions of the input tensor, then use <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mtext>padding_left</mtext><mo separator="true">,</mo><mtext>padding_right</mtext><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">(\text{padding\_left}, \text{padding\_right},</annotation></semantics></math></span></span></span> <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>padding_top</mtext><mo separator="true">,</mo><mtext>padding_bottom</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{padding\_top}, \text{padding\_bottom})</annotation></semantics></math></span></span></span>; to pad the last 3 dimensions, use <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mtext>padding_left</mtext><mo separator="true">,</mo><mtext>padding_right</mtext><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">(\text{padding\_left}, \text{padding\_right},</annotation></semantics></math></span></span></span> <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>padding_top</mtext><mo separator="true">,</mo><mtext>padding_bottom</mtext></mrow><annotation encoding="application/x-tex">\text{padding\_top}, \text{padding\_bottom}</annotation></semantics></math></span></span></span> <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>padding_front</mtext><mo separator="true">,</mo><mtext>padding_back</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{padding\_front}, \text{padding\_back})</annotation></semantics></math></span></span></span>.</p> </dd> <dt>Padding mode:</dt>
<dd>
<p>See <code>torch.nn.CircularPad2d</code>, <a class="reference internal" href="torch.nn.constantpad2d#torch.nn.ConstantPad2d" title="torch.nn.ConstantPad2d"><code>torch.nn.ConstantPad2d</code></a>, <a class="reference internal" href="torch.nn.reflectionpad2d#torch.nn.ReflectionPad2d" title="torch.nn.ReflectionPad2d"><code>torch.nn.ReflectionPad2d</code></a>, and <a class="reference internal" href="torch.nn.replicationpad2d#torch.nn.ReplicationPad2d" title="torch.nn.ReplicationPad2d"><code>torch.nn.ReplicationPad2d</code></a> for concrete examples on how each of the padding modes works. Constant padding is implemented for arbitrary dimensions. Circular, replicate and reflection padding are implemented for padding the last 3 dimensions of a 4D or 5D input tensor, the last 2 dimensions of a 3D or 4D input tensor, or the last dimension of a 2D or 3D input tensor.</p> </dd> </dl> <div class="admonition note"> <p class="admonition-title">Note</p> <p>When using the CUDA backend, this operation may induce nondeterministic behaviour in its backward pass that is not easily switched off. Please see the notes on <a class="reference internal" href="https://pytorch.org/docs/2.1/notes/randomness.html"><span class="doc">Reproducibility</span></a> for background.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – N-dimensional tensor</li> <li>
<strong>pad</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a>) – m-elements tuple, where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>m</mi><mn>2</mn></mfrac><mo>≤</mo></mrow><annotation encoding="application/x-tex">\frac{m}{2} \leq</annotation></semantics></math></span></span></span> input dimensions and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span></span> is even.</li> <li>
<strong>mode</strong> – <code>'constant'</code>, <code>'reflect'</code>, <code>'replicate'</code> or <code>'circular'</code>. Default: <code>'constant'</code>
</li> <li>
<strong>value</strong> – fill value for <code>'constant'</code> padding. Default: <code>0</code>
</li> </ul> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; t4d = torch.empty(3, 3, 4, 2)
&gt;&gt;&gt; p1d = (1, 1) # pad last dim by 1 on each side
&gt;&gt;&gt; out = F.pad(t4d, p1d, "constant", 0)  # effectively zero padding
&gt;&gt;&gt; print(out.size())
torch.Size([3, 3, 4, 4])
&gt;&gt;&gt; p2d = (1, 1, 2, 2) # pad last dim by (1, 1) and 2nd to last by (2, 2)
&gt;&gt;&gt; out = F.pad(t4d, p2d, "constant", 0)
&gt;&gt;&gt; print(out.size())
torch.Size([3, 3, 8, 4])
&gt;&gt;&gt; t4d = torch.empty(3, 3, 4, 2)
&gt;&gt;&gt; p3d = (0, 1, 2, 1, 3, 3) # pad by (0, 1), (2, 1), and (3, 3)
&gt;&gt;&gt; out = F.pad(t4d, p3d, "constant", 0)
&gt;&gt;&gt; print(out.size())
torch.Size([3, 9, 7, 3])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.nn.functional.pad.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.nn.functional.pad.html</a>
  </p>
</div>
