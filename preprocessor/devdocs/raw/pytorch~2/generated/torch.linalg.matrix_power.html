<h1 id="torch-linalg-matrix-power">torch.linalg.matrix_power</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.linalg.matrix_power">
<code>torch.linalg.matrix_power(A, n, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the <code>n</code>-th power of a square matrix for an integer <code>n</code>.</p> <p>Supports input of float, double, cfloat and cdouble dtypes. Also supports batches of matrices, and if <code>A</code> is a batch of matrices then the output has the same batch dimensions.</p> <p>If <code>n</code><code>= 0</code>, it returns the identity matrix (or batch) of the same shape as <code>A</code>. If <code>n</code> is negative, it returns the inverse of each matrix (if invertible) raised to the power of <code>abs(n)</code>.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Consider using <a class="reference internal" href="torch.linalg.solve#torch.linalg.solve" title="torch.linalg.solve"><code>torch.linalg.solve()</code></a> if possible for multiplying a matrix on the left by a negative power as, if <code>n</code><code>&gt; 0</code>:</p> <pre data-language="python">matrix_power(torch.linalg.solve(A, B), n) == matrix_power(A, -n)  @ B
</pre> <p>It is always preferred to use <a class="reference internal" href="torch.linalg.solve#torch.linalg.solve" title="torch.linalg.solve"><code>solve()</code></a> when possible, as it is faster and more numerically stable than computing <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">A^{-n}</annotation></semantics></math></span></span></span> explicitly.</p> </div> <div class="admonition seealso"> <p class="admonition-title">See also</p> <p><a class="reference internal" href="torch.linalg.solve#torch.linalg.solve" title="torch.linalg.solve"><code>torch.linalg.solve()</code></a> computes <code>A</code><code>.inverse() @ </code><code>B</code> with a numerically stable algorithm.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>A</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – tensor of shape <code>(*, m, m)</code> where <code>*</code> is zero or more batch dimensions.</li> <li>
<strong>n</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>) – the exponent.</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – output tensor. Ignored if <code>None</code>. Default: <code>None</code>.</p> </dd> <dt class="field-odd">Raises</dt> <dd class="field-odd">
<p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(in Python v3.12)"><strong>RuntimeError</strong></a> – if <code>n</code><code>&lt; 0</code> and the matrix <code>A</code> or any matrix in the batch of matrices <code>A</code> is not invertible.</p> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; A = torch.randn(3, 3)
&gt;&gt;&gt; torch.linalg.matrix_power(A, 0)
tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]])
&gt;&gt;&gt; torch.linalg.matrix_power(A, 3)
tensor([[ 1.0756,  0.4980,  0.0100],
        [-1.6617,  1.4994, -1.9980],
        [-0.4509,  0.2731,  0.8001]])
&gt;&gt;&gt; torch.linalg.matrix_power(A.expand(2, -1, -1), -2)
tensor([[[ 0.2640,  0.4571, -0.5511],
        [-1.0163,  0.3491, -1.5292],
        [-0.4899,  0.0822,  0.2773]],
        [[ 0.2640,  0.4571, -0.5511],
        [-1.0163,  0.3491, -1.5292],
        [-0.4899,  0.0822,  0.2773]]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.linalg.matrix_power.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.linalg.matrix_power.html</a>
  </p>
</div>
