<h1 id="torch-nn-functional-embedding-bag">torch.nn.functional.embedding_bag</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.nn.functional.embedding_bag">
<code>torch.nn.functional.embedding_bag(input, weight, offsets=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, mode='mean', sparse=False, per_sample_weights=None, include_last_offset=False, padding_idx=None)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/nn/functional.html#embedding_bag"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Computes sums, means or maxes of <code>bags</code> of embeddings, without instantiating the intermediate embeddings.</p> <p>See <a class="reference internal" href="torch.nn.embeddingbag#torch.nn.EmbeddingBag" title="torch.nn.EmbeddingBag"><code>torch.nn.EmbeddingBag</code></a> for more details.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This operation may produce nondeterministic gradients when given tensors on a CUDA device. See <a class="reference internal" href="https://pytorch.org/docs/2.1/notes/randomness.html"><span class="doc">Reproducibility</span></a> for more information.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<em>LongTensor</em>) – Tensor containing bags of indices into the embedding matrix</li> <li>
<strong>weight</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – The embedding matrix with number of rows equal to the maximum possible index + 1, and number of columns equal to the embedding size</li> <li>
<strong>offsets</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) – Only used when <code>input</code> is 1D. <code>offsets</code> determines the starting index position of each bag (sequence) in <code>input</code>.</li> <li>
<strong>max_norm</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em>, </em><em>optional</em>) – If given, each embedding vector with norm larger than <code>max_norm</code> is renormalized to have norm <code>max_norm</code>. Note: this will modify <code>weight</code> in-place.</li> <li>
<strong>norm_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em>, </em><em>optional</em>) – The <code>p</code> in the <code>p</code>-norm to compute for the <code>max_norm</code> option. Default <code>2</code>.</li> <li>
<strong>scale_grad_by_freq</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – if given, this will scale gradients by the inverse of frequency of the words in the mini-batch. Default <code>False</code>. Note: this option is not supported when <code>mode="max"</code>.</li> <li>
<strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a><em>, </em><em>optional</em>) – <code>"sum"</code>, <code>"mean"</code> or <code>"max"</code>. Specifies the way to reduce the bag. Default: <code>"mean"</code>
</li> <li>
<strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – if <code>True</code>, gradient w.r.t. <code>weight</code> will be a sparse tensor. See Notes under <a class="reference internal" href="torch.nn.embedding#torch.nn.Embedding" title="torch.nn.Embedding"><code>torch.nn.Embedding</code></a> for more details regarding sparse gradients. Note: this option is not supported when <code>mode="max"</code>.</li> <li>
<strong>per_sample_weights</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – a tensor of float / double weights, or None to indicate all weights should be taken to be 1. If specified, <code>per_sample_weights</code> must have exactly the same shape as input and is treated as having the same <code>offsets</code>, if those are not None.</li> <li>
<strong>include_last_offset</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – if <code>True</code>, the size of offsets is equal to the number of bags + 1. The last element is the size of the input, or the ending index position of the last bag (sequence).</li> <li>
<strong>padding_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><em>optional</em>) – If specified, the entries at <code>padding_idx</code> do not contribute to the gradient; therefore, the embedding vector at <code>padding_idx</code> is not updated during training, i.e. it remains as a fixed “pad”. Note that the embedding vector at <code>padding_idx</code> is excluded from the reduction.</li> </ul> </dd> <dt class="field-even">Return type</dt> <dd class="field-even">
<p><a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a></p> </dd> </dl> <dl class="simple"> <dt>Shape:</dt>
<dd>
<ul class="simple"> <li>
<p><code>input</code> (LongTensor) and <code>offsets</code> (LongTensor, optional)</p> <ul> <li>If <code>input</code> is 2D of shape <code>(B, N)</code>, it will be treated as <code>B</code> bags (sequences) each of fixed length <code>N</code>, and this will return <code>B</code> values aggregated in a way depending on the <code>mode</code>. <code>offsets</code> is ignored and required to be <code>None</code> in this case.</li> <li>If <code>input</code> is 1D of shape <code>(N)</code>, it will be treated as a concatenation of multiple bags (sequences). <code>offsets</code> is required to be a 1D tensor containing the starting index positions of each bag in <code>input</code>. Therefore, for <code>offsets</code> of shape <code>(B)</code>, <code>input</code> will be viewed as having <code>B</code> bags. Empty bags (i.e., having 0-length) will have returned vectors filled by zeros.</li> </ul> </li> <li>
<code>weight</code> (Tensor): the learnable weights of the module of shape <code>(num_embeddings, embedding_dim)</code>
</li> <li>
<code>per_sample_weights</code> (Tensor, optional). Has the same shape as <code>input</code>.</li> <li>
<code>output</code>: aggregated embedding values of shape <code>(B, embedding_dim)</code>
</li> </ul> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; # an Embedding module containing 10 tensors of size 3
&gt;&gt;&gt; embedding_matrix = torch.rand(10, 3)
&gt;&gt;&gt; # a batch of 2 samples of 4 indices each
&gt;&gt;&gt; input = torch.tensor([1, 2, 4, 5, 4, 3, 2, 9])
&gt;&gt;&gt; offsets = torch.tensor([0, 4])
&gt;&gt;&gt; F.embedding_bag(input, embedding_matrix, offsets)
tensor([[ 0.3397,  0.3552,  0.5545],
        [ 0.5893,  0.4386,  0.5882]])

&gt;&gt;&gt; # example with padding_idx
&gt;&gt;&gt; embedding_matrix = torch.rand(10, 3)
&gt;&gt;&gt; input = torch.tensor([2, 2, 2, 2, 4, 3, 2, 9])
&gt;&gt;&gt; offsets = torch.tensor([0, 4])
&gt;&gt;&gt; F.embedding_bag(input, embedding_matrix, offsets, padding_idx=2, mode='sum')
tensor([[ 0.0000,  0.0000,  0.0000],
        [-0.7082,  3.2145, -2.6251]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.nn.functional.embedding_bag.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.nn.functional.embedding_bag.html</a>
  </p>
</div>
