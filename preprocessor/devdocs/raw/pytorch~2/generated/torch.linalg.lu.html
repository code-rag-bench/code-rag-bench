<h1 id="torch-linalg-lu">torch.linalg.lu</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.linalg.lu">
<code>torch.linalg.lu(A, *, pivot=True, out=None)</code> </dt> <dd>
<p>Computes the LU decomposition with partial pivoting of a matrix.</p> <p>Letting <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">K</mi></mrow><annotation encoding="application/x-tex">\mathbb{K}</annotation></semantics></math></span></span></span> be <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\mathbb{R}</annotation></semantics></math></span></span></span> or <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">C</mi></mrow><annotation encoding="application/x-tex">\mathbb{C}</annotation></semantics></math></span></span></span>, the <strong>LU decomposition with partial pivoting</strong> of a matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∈</mo><msup><mi mathvariant="double-struck">K</mi><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">A \in \mathbb{K}^{m \times n}</annotation></semantics></math></span></span></span> is defined as</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mi>P</mi><mi>L</mi><mi>U</mi><mpadded width="0px"><mrow><mspace width="2em"></mspace><mi>P</mi><mo>∈</mo><msup><mi mathvariant="double-struck">K</mi><mrow><mi>m</mi><mo>×</mo><mi>m</mi></mrow></msup><mo separator="true">,</mo><mi>L</mi><mo>∈</mo><msup><mi mathvariant="double-struck">K</mi><mrow><mi>m</mi><mo>×</mo><mi>k</mi></mrow></msup><mo separator="true">,</mo><mi>U</mi><mo>∈</mo><msup><mi mathvariant="double-struck">K</mi><mrow><mi>k</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow></mpadded></mrow><annotation encoding="application/x-tex">A = PLU\mathrlap{\qquad P \in \mathbb{K}^{m \times m}, L \in \mathbb{K}^{m \times k}, U \in \mathbb{K}^{k \times n}}</annotation></semantics></math></span></span></span>
</div>
<p>where <code>k = min(m,n)</code>, <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span></span></span> is a <a class="reference external" href="https://en.wikipedia.org/wiki/Permutation_matrix">permutation matrix</a>, <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span></span></span> is lower triangular with ones on the diagonal and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span></span></span> is upper triangular.</p> <p>If <code>pivot</code><code>= False</code> and <code>A</code> is on GPU, then the <strong>LU decomposition without pivoting</strong> is computed</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mi>L</mi><mi>U</mi><mpadded width="0px"><mrow><mspace width="2em"></mspace><mi>L</mi><mo>∈</mo><msup><mi mathvariant="double-struck">K</mi><mrow><mi>m</mi><mo>×</mo><mi>k</mi></mrow></msup><mo separator="true">,</mo><mi>U</mi><mo>∈</mo><msup><mi mathvariant="double-struck">K</mi><mrow><mi>k</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow></mpadded></mrow><annotation encoding="application/x-tex">A = LU\mathrlap{\qquad L \in \mathbb{K}^{m \times k}, U \in \mathbb{K}^{k \times n}}</annotation></semantics></math></span></span></span>
</div>
<p>When <code>pivot</code><code>= False</code>, the returned matrix <code>P</code> will be empty. The LU decomposition without pivoting <a class="reference external" href="https://en.wikipedia.org/wiki/LU_decomposition#Definitions">may not exist</a> if any of the principal minors of <code>A</code> is singular. In this case, the output matrix may contain <code>inf</code> or <code>NaN</code>.</p> <p>Supports input of float, double, cfloat and cdouble dtypes. Also supports batches of matrices, and if <code>A</code> is a batch of matrices then the output has the same batch dimensions.</p> <div class="admonition seealso"> <p class="admonition-title">See also</p> <p><a class="reference internal" href="torch.linalg.solve#torch.linalg.solve" title="torch.linalg.solve"><code>torch.linalg.solve()</code></a> solves a system of linear equations using the LU decomposition with partial pivoting.</p> </div> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>The LU decomposition is almost never unique, as often there are different permutation matrices that can yield different LU decompositions. As such, different platforms, like SciPy, or inputs on different devices, may produce different valid decompositions.</p> </div> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>Gradient computations are only supported if the input matrix is full-rank. If this condition is not met, no error will be thrown, but the gradient may not be finite. This is because the LU decomposition with pivoting is not differentiable at these points.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>A</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – tensor of shape <code>(*, m, n)</code> where <code>*</code> is zero or more batch dimensions.</li> <li>
<strong>pivot</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – Controls whether to compute the LU decomposition with partial pivoting or no pivoting. Default: <code>True</code>.</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a><em>, </em><em>optional</em>) – output tuple of three tensors. Ignored if <code>None</code>. Default: <code>None</code>.</p> </dd> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<p>A named tuple <code>(P, L, U)</code>.</p> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; A = torch.randn(3, 2)
&gt;&gt;&gt; P, L, U = torch.linalg.lu(A)
&gt;&gt;&gt; P
tensor([[0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.]])
&gt;&gt;&gt; L
tensor([[1.0000, 0.0000],
        [0.5007, 1.0000],
        [0.0633, 0.9755]])
&gt;&gt;&gt; U
tensor([[0.3771, 0.0489],
        [0.0000, 0.9644]])
&gt;&gt;&gt; torch.dist(A, P @ L @ U)
tensor(5.9605e-08)

&gt;&gt;&gt; A = torch.randn(2, 5, 7, device="cuda")
&gt;&gt;&gt; P, L, U = torch.linalg.lu(A, pivot=False)
&gt;&gt;&gt; P
tensor([], device='cuda:0')
&gt;&gt;&gt; torch.dist(A, L @ U)
tensor(1.0376e-06, device='cuda:0')
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.linalg.lu.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.linalg.lu.html</a>
  </p>
</div>
