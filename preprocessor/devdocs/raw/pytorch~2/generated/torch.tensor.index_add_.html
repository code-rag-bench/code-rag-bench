<h1 id="torch-tensor-index-add">torch.Tensor.index_add_</h1> <dl class="py method"> <dt class="sig sig-object py" id="torch.Tensor.index_add_">
<code>Tensor.index_add_(dim, index, source, *, alpha=1) → Tensor</code> </dt> <dd>
<p>Accumulate the elements of <code>alpha</code> times <code>source</code> into the <code>self</code> tensor by adding to the indices in the order given in <code>index</code>. For example, if <code>dim == 0</code>, <code>index[i] == j</code>, and <code>alpha=-1</code>, then the <code>i</code>th row of <code>source</code> is subtracted from the <code>j</code>th row of <code>self</code>.</p> <p>The <a class="reference internal" href="torch.tensor.dim#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim</code></a>th dimension of <code>source</code> must have the same size as the length of <code>index</code> (which must be a vector), and all other dimensions must match <code>self</code>, or an error will be raised.</p> <p>For a 3-D tensor the output is given as:</p> <pre data-language="python">self[index[i], :, :] += alpha * src[i, :, :]  # if dim == 0
self[:, index[i], :] += alpha * src[:, i, :]  # if dim == 1
self[:, :, index[i]] += alpha * src[:, :, i]  # if dim == 2
</pre> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This operation may behave nondeterministically when given tensors on a CUDA device. See <a class="reference internal" href="https://pytorch.org/docs/2.1/notes/randomness.html"><span class="doc">Reproducibility</span></a> for more information.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a>) – dimension along which to index</li> <li>
<strong>index</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – indices of <code>source</code> to select from, should have dtype either <code>torch.int64</code> or <code>torch.int32</code>
</li> <li>
<strong>source</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the tensor containing values to add</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>alpha</strong> (<em>Number</em>) – the scalar multiplier for <code>source</code></p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; x = torch.ones(5, 3)
&gt;&gt;&gt; t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)
&gt;&gt;&gt; index = torch.tensor([0, 4, 2])
&gt;&gt;&gt; x.index_add_(0, index, t)
tensor([[  2.,   3.,   4.],
        [  1.,   1.,   1.],
        [  8.,   9.,  10.],
        [  1.,   1.,   1.],
        [  5.,   6.,   7.]])
&gt;&gt;&gt; x.index_add_(0, index, t, alpha=-1)
tensor([[  1.,   1.,   1.],
        [  1.,   1.,   1.],
        [  1.,   1.,   1.],
        [  1.,   1.,   1.],
        [  1.,   1.,   1.]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.Tensor.index_add_.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.Tensor.index_add_.html</a>
  </p>
</div>
