<h1 id="torch-linalg-inv">torch.linalg.inv</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.linalg.inv">
<code>torch.linalg.inv(A, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the inverse of a square matrix if it exists. Throws a <code>RuntimeError</code> if the matrix is not invertible.</p> <p>Letting <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">K</mi></mrow><annotation encoding="application/x-tex">\mathbb{K}</annotation></semantics></math></span></span></span> be <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">R</mi></mrow><annotation encoding="application/x-tex">\mathbb{R}</annotation></semantics></math></span></span></span> or <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">C</mi></mrow><annotation encoding="application/x-tex">\mathbb{C}</annotation></semantics></math></span></span></span>, for a matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∈</mo><msup><mi mathvariant="double-struck">K</mi><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">A \in \mathbb{K}^{n \times n}</annotation></semantics></math></span></span></span>, its <strong>inverse matrix</strong> <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>∈</mo><msup><mi mathvariant="double-struck">K</mi><mrow><mi>n</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">A^{-1} \in \mathbb{K}^{n \times n}</annotation></semantics></math></span></span></span> (if it exists) is defined as</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>A</mi><mo>=</mo><mi>A</mi><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">I</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">A^{-1}A = AA^{-1} = \mathrm{I}_n</annotation></semantics></math></span></span></span>
</div>
<p>where <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">I</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\mathrm{I}_n</annotation></semantics></math></span></span></span> is the <code>n</code>-dimensional identity matrix.</p> <p>The inverse matrix exists if and only if <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span></span> is <a class="reference external" href="https://en.wikipedia.org/wiki/Invertible_matrix#The_invertible_matrix_theorem">invertible</a>. In this case, the inverse is unique.</p> <p>Supports input of float, double, cfloat and cdouble dtypes. Also supports batches of matrices, and if <code>A</code> is a batch of matrices then the output has the same batch dimensions.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>When inputs are on a CUDA device, this function synchronizes that device with the CPU.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Consider using <a class="reference internal" href="torch.linalg.solve#torch.linalg.solve" title="torch.linalg.solve"><code>torch.linalg.solve()</code></a> if possible for multiplying a matrix on the left by the inverse, as:</p> <pre data-language="python">linalg.solve(A, B) == linalg.inv(A) @ B  # When B is a matrix
</pre> <p>It is always preferred to use <a class="reference internal" href="torch.linalg.solve#torch.linalg.solve" title="torch.linalg.solve"><code>solve()</code></a> when possible, as it is faster and more numerically stable than computing the inverse explicitly.</p> </div> <div class="admonition seealso"> <p class="admonition-title">See also</p> <p><a class="reference internal" href="torch.linalg.pinv#torch.linalg.pinv" title="torch.linalg.pinv"><code>torch.linalg.pinv()</code></a> computes the pseudoinverse (Moore-Penrose inverse) of matrices of any shape.</p> <p><a class="reference internal" href="torch.linalg.solve#torch.linalg.solve" title="torch.linalg.solve"><code>torch.linalg.solve()</code></a> computes <code>A</code><code>.inv() @ </code><code>B</code> with a numerically stable algorithm.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>A</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – tensor of shape <code>(*, n, n)</code> where <code>*</code> is zero or more batch dimensions consisting of invertible matrices.</p> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – output tensor. Ignored if <code>None</code>. Default: <code>None</code>.</p> </dd> <dt class="field-odd">Raises</dt> <dd class="field-odd">
<p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(in Python v3.12)"><strong>RuntimeError</strong></a> – if the matrix <code>A</code> or any matrix in the batch of matrices <code>A</code> is not invertible.</p> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; A = torch.randn(4, 4)
&gt;&gt;&gt; Ainv = torch.linalg.inv(A)
&gt;&gt;&gt; torch.dist(A @ Ainv, torch.eye(4))
tensor(1.1921e-07)

&gt;&gt;&gt; A = torch.randn(2, 3, 4, 4)  # Batch of matrices
&gt;&gt;&gt; Ainv = torch.linalg.inv(A)
&gt;&gt;&gt; torch.dist(A @ Ainv, torch.eye(4))
tensor(1.9073e-06)

&gt;&gt;&gt; A = torch.randn(4, 4, dtype=torch.complex128)  # Complex matrix
&gt;&gt;&gt; Ainv = torch.linalg.inv(A)
&gt;&gt;&gt; torch.dist(A @ Ainv, torch.eye(4))
tensor(7.5107e-16, dtype=torch.float64)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.linalg.inv.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.linalg.inv.html</a>
  </p>
</div>
