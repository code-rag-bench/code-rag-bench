<h1 id="torch-tensor-requires-grad">torch.Tensor.requires_grad_</h1> <dl class="py method"> <dt class="sig sig-object py" id="torch.Tensor.requires_grad_">
<code>Tensor.requires_grad_(requires_grad=True) → Tensor</code> </dt> <dd>
<p>Change if autograd should record operations on this tensor: sets this tensor’s <a class="reference internal" href="torch.tensor.requires_grad#torch.Tensor.requires_grad" title="torch.Tensor.requires_grad"><code>requires_grad</code></a> attribute in-place. Returns this tensor.</p> <p><a class="reference internal" href="#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>requires_grad_()</code></a>’s main use case is to tell autograd to begin recording operations on a Tensor <code>tensor</code>. If <code>tensor</code> has <code>requires_grad=False</code> (because it was obtained through a DataLoader, or required preprocessing or initialization), <code>tensor.requires_grad_()</code> makes it so that autograd will begin to record operations on <code>tensor</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<p><strong>requires_grad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a>) – If autograd should record operations on this tensor. Default: <code>True</code>.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; # Let's say we want to preprocess some saved weights and use
&gt;&gt;&gt; # the result as new weights.
&gt;&gt;&gt; saved_weights = [0.1, 0.2, 0.3, 0.25]
&gt;&gt;&gt; loaded_weights = torch.tensor(saved_weights)
&gt;&gt;&gt; weights = preprocess(loaded_weights)  # some function
&gt;&gt;&gt; weights
tensor([-0.5503,  0.4926, -2.1158, -0.8303])

&gt;&gt;&gt; # Now, start to record operations done to weights
&gt;&gt;&gt; weights.requires_grad_()
&gt;&gt;&gt; out = weights.pow(2).sum()
&gt;&gt;&gt; out.backward()
&gt;&gt;&gt; weights.grad
tensor([-1.1007,  0.9853, -4.2316, -1.6606])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.Tensor.requires_grad_.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.Tensor.requires_grad_.html</a>
  </p>
</div>
