<h1 id="torch-jit-fork">torch.jit.fork</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.jit.fork">
<code>torch.jit.fork(func, *args, **kwargs)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/jit/_async.html#fork"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Creates an asynchronous task executing <code>func</code> and a reference to the value of the result of this execution. <code>fork</code> will return immediately, so the return value of <code>func</code> may not have been computed yet. To force completion of the task and access the return value invoke <code>torch.jit.wait</code> on the Future. <code>fork</code> invoked with a <code>func</code> which returns <code>T</code> is typed as <code>torch.jit.Future[T]</code>. <code>fork</code> calls can be arbitrarily nested, and may be invoked with positional and keyword arguments. Asynchronous execution will only occur when run in TorchScript. If run in pure python, <code>fork</code> will not execute in parallel. <code>fork</code> will also not execute in parallel when invoked while tracing, however the <code>fork</code> and <code>wait</code> calls will be captured in the exported IR Graph.</p> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p><code>fork</code> tasks will execute non-deterministically. We recommend only spawning parallel fork tasks for pure functions that do not modify their inputs, module attributes, or global state.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>func</strong> (<em>callable</em><em> or </em><a class="reference internal" href="torch.nn.module#torch.nn.Module" title="torch.nn.Module">torch.nn.Module</a>) – A Python function or <code>torch.nn.Module</code> that will be invoked. If executed in TorchScript, it will execute asynchronously, otherwise it will not. Traced invocations of fork will be captured in the IR.</li> <li>
<strong>*args</strong> – arguments to invoke <code>func</code> with.</li> <li>
<strong>**kwargs</strong> – arguments to invoke <code>func</code> with.</li> </ul> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<p>a reference to the execution of <code>func</code>. The value <code>T</code> can only be accessed by forcing completion of <code>func</code> through <code>torch.jit.wait</code>.</p> </dd> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><code>torch.jit.Future[T]</code></p> </dd> </dl> <p>Example (fork a free function):</p> <pre data-language="python">import torch
from torch import Tensor
def foo(a : Tensor, b : int) -&gt; Tensor:
    return a + b
def bar(a):
    fut : torch.jit.Future[Tensor] = torch.jit.fork(foo, a, b=2)
    return torch.jit.wait(fut)
script_bar = torch.jit.script(bar)
input = torch.tensor(2)
# only the scripted version executes asynchronously
assert script_bar(input) == bar(input)
# trace is not run asynchronously, but fork is captured in IR
graph = torch.jit.trace(bar, (input,)).graph
assert "fork" in str(graph)
</pre> <p>Example (fork a module method):</p> <pre data-language="python">import torch
from torch import Tensor
class AddMod(torch.nn.Module):
    def forward(self, a: Tensor, b : int):
        return a + b
class Mod(torch.nn.Module):
    def __init__(self):
        super(self).__init__()
        self.mod = AddMod()
    def forward(self, input):
        fut = torch.jit.fork(self.mod, a, b=2)
        return torch.jit.wait(fut)
input = torch.tensor(2)
mod = Mod()
assert mod(input) == torch.jit.script(mod).forward(input)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.jit.fork.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.jit.fork.html</a>
  </p>
</div>
