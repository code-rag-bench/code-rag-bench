<h1 id="maxunpool2d">MaxUnpool2d</h1> <dl class="py class"> <dt class="sig sig-object py" id="torch.nn.MaxUnpool2d">
<code>class torch.nn.MaxUnpool2d(kernel_size, stride=None, padding=0)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/nn/modules/pooling.html#MaxUnpool2d"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Computes a partial inverse of <a class="reference internal" href="torch.nn.maxpool2d#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><code>MaxPool2d</code></a>.</p> <p><a class="reference internal" href="torch.nn.maxpool2d#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><code>MaxPool2d</code></a> is not fully invertible, since the non-maximal values are lost.</p> <p><a class="reference internal" href="#torch.nn.MaxUnpool2d" title="torch.nn.MaxUnpool2d"><code>MaxUnpool2d</code></a> takes in as input the output of <a class="reference internal" href="torch.nn.maxpool2d#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><code>MaxPool2d</code></a> including the indices of the maximal values and computes a partial inverse in which all non-maximal values are set to zero.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>This operation may behave nondeterministically when the input indices has repeat values. See <a class="reference external" href="https://github.com/pytorch/pytorch/issues/80827">https://github.com/pytorch/pytorch/issues/80827</a> and <a class="reference internal" href="https://pytorch.org/docs/2.1/notes/randomness.html"><span class="doc">Reproducibility</span></a> for more information.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p><a class="reference internal" href="torch.nn.maxpool2d#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><code>MaxPool2d</code></a> can map several input sizes to the same output sizes. Hence, the inversion process can get ambiguous. To accommodate this, you can provide the needed output size as an additional argument <code>output_size</code> in the forward call. See the Inputs and Example below.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a>) – Size of the max pooling window.</li> <li>
<strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a>) – Stride of the max pooling window. It is set to <code>kernel_size</code> by default.</li> <li>
<strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)">tuple</a>) – Padding that was added to the input</li> </ul> </dd> </dl> <dl> <dt>Inputs:</dt>
<dd>
<ul class="simple"> <li>
<code>input</code>: the input Tensor to invert</li> <li>
<code>indices</code>: the indices given out by <a class="reference internal" href="torch.nn.maxpool2d#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><code>MaxPool2d</code></a>
</li> <li>
<code>output_size</code> (optional): the targeted output size</li> </ul> </dd> <dt>Shape:</dt>
<dd>
<ul> <li>Input: <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>C</mi><mo separator="true">,</mo><msub><mi>H</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo separator="true">,</mo><msub><mi>W</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, C, H_{in}, W_{in})</annotation></semantics></math></span></span></span> or <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>C</mi><mo separator="true">,</mo><msub><mi>H</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo separator="true">,</mo><msub><mi>W</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(C, H_{in}, W_{in})</annotation></semantics></math></span></span></span>.</li> <li>
<p>Output: <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>C</mi><mo separator="true">,</mo><msub><mi>H</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo separator="true">,</mo><msub><mi>W</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, C, H_{out}, W_{out})</annotation></semantics></math></span></span></span> or <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>C</mi><mo separator="true">,</mo><msub><mi>H</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo separator="true">,</mo><msub><mi>W</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(C, H_{out}, W_{out})</annotation></semantics></math></span></span></span>, where</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>H</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>=</mo><mo stretchy="false">(</mo><msub><mi>H</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>×</mo><mtext>stride[0]</mtext><mo>−</mo><mn>2</mn><mo>×</mo><mtext>padding[0]</mtext><mo>+</mo><mtext>kernel_size[0]</mtext></mrow><annotation encoding="application/x-tex">H_{out} = (H_{in} - 1) \times \text{stride[0]} - 2 \times \text{padding[0]} + \text{kernel\_size[0]} </annotation></semantics></math></span></span></span>
</div>
<div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>W</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo>=</mo><mo stretchy="false">(</mo><msub><mi>W</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>×</mo><mtext>stride[1]</mtext><mo>−</mo><mn>2</mn><mo>×</mo><mtext>padding[1]</mtext><mo>+</mo><mtext>kernel_size[1]</mtext></mrow><annotation encoding="application/x-tex">W_{out} = (W_{in} - 1) \times \text{stride[1]} - 2 \times \text{padding[1]} + \text{kernel\_size[1]} </annotation></semantics></math></span></span></span>
</div>
<p>or as given by <code>output_size</code> in the call operator</p> </li> </ul> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; pool = nn.MaxPool2d(2, stride=2, return_indices=True)
&gt;&gt;&gt; unpool = nn.MaxUnpool2d(2, stride=2)
&gt;&gt;&gt; input = torch.tensor([[[[ 1.,  2.,  3.,  4.],
                            [ 5.,  6.,  7.,  8.],
                            [ 9., 10., 11., 12.],
                            [13., 14., 15., 16.]]]])
&gt;&gt;&gt; output, indices = pool(input)
&gt;&gt;&gt; unpool(output, indices)
tensor([[[[  0.,   0.,   0.,   0.],
          [  0.,   6.,   0.,   8.],
          [  0.,   0.,   0.,   0.],
          [  0.,  14.,   0.,  16.]]]])
&gt;&gt;&gt; # Now using output_size to resolve an ambiguous size for the inverse
&gt;&gt;&gt; input = torch.torch.tensor([[[[ 1.,  2.,  3., 4., 5.],
                                  [ 6.,  7.,  8., 9., 10.],
                                  [11., 12., 13., 14., 15.],
                                  [16., 17., 18., 19., 20.]]]])
&gt;&gt;&gt; output, indices = pool(input)
&gt;&gt;&gt; # This call will not work without specifying output_size
&gt;&gt;&gt; unpool(output, indices, output_size=input.size())
tensor([[[[ 0.,  0.,  0.,  0.,  0.],
          [ 0.,  7.,  0.,  9.,  0.],
          [ 0.,  0.,  0.,  0.,  0.],
          [ 0., 17.,  0., 19.,  0.]]]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.nn.MaxUnpool2d.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.nn.MaxUnpool2d.html</a>
  </p>
</div>
