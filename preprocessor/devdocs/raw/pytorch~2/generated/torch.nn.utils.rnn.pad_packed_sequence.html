<h1 id="torch-nn-utils-rnn-pad-packed-sequence">torch.nn.utils.rnn.pad_packed_sequence</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.nn.utils.rnn.pad_packed_sequence">
<code>torch.nn.utils.rnn.pad_packed_sequence(sequence, batch_first=False, padding_value=0.0, total_length=None)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/nn/utils/rnn.html#pad_packed_sequence"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Pads a packed batch of variable length sequences.</p> <p>It is an inverse operation to <a class="reference internal" href="torch.nn.utils.rnn.pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence" title="torch.nn.utils.rnn.pack_padded_sequence"><code>pack_padded_sequence()</code></a>.</p> <p>The returned Tensor’s data will be of size <code>T x B x *</code>, where <code>T</code> is the length of the longest sequence and <code>B</code> is the batch size. If <code>batch_first</code> is True, the data will be transposed into <code>B x T x *</code> format.</p> <h4 class="rubric">Example</h4> <pre data-language="python">&gt;&gt;&gt; from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence
&gt;&gt;&gt; seq = torch.tensor([[1, 2, 0], [3, 0, 0], [4, 5, 6]])
&gt;&gt;&gt; lens = [2, 1, 3]
&gt;&gt;&gt; packed = pack_padded_sequence(seq, lens, batch_first=True, enforce_sorted=False)
&gt;&gt;&gt; packed
PackedSequence(data=tensor([4, 1, 3, 5, 2, 6]), batch_sizes=tensor([3, 2, 1]),
               sorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))
&gt;&gt;&gt; seq_unpacked, lens_unpacked = pad_packed_sequence(packed, batch_first=True)
&gt;&gt;&gt; seq_unpacked
tensor([[1, 2, 0],
        [3, 0, 0],
        [4, 5, 6]])
&gt;&gt;&gt; lens_unpacked
tensor([2, 1, 3])
</pre> <div class="admonition note"> <p class="admonition-title">Note</p> <p><code>total_length</code> is useful to implement the <code>pack sequence -&gt; recurrent network -&gt; unpack sequence</code> pattern in a <a class="reference internal" href="torch.nn.module#torch.nn.Module" title="torch.nn.Module"><code>Module</code></a> wrapped in <a class="reference internal" href="torch.nn.dataparallel#torch.nn.DataParallel" title="torch.nn.DataParallel"><code>DataParallel</code></a>. See <a class="reference internal" href="https://pytorch.org/docs/2.1/notes/faq.html#pack-rnn-unpack-with-data-parallelism"><span class="std std-ref">this FAQ section</span></a> for details.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>sequence</strong> (<a class="reference internal" href="torch.nn.utils.rnn.packedsequence#torch.nn.utils.rnn.PackedSequence" title="torch.nn.utils.rnn.PackedSequence">PackedSequence</a>) – batch to pad</li> <li>
<strong>batch_first</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)">bool</a><em>, </em><em>optional</em>) – if <code>True</code>, the output will be in <code>B x T x *</code> format.</li> <li>
<strong>padding_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.12)">float</a><em>, </em><em>optional</em>) – values for padded elements.</li> <li>
<strong>total_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)">int</a><em>, </em><em>optional</em>) – if not <code>None</code>, the output will be padded to have length <code>total_length</code>. This method will throw <a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.12)"><code>ValueError</code></a> if <code>total_length</code> is less than the max sequence length in <code>sequence</code>.</li> </ul> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<p>Tuple of Tensor containing the padded sequence, and a Tensor containing the list of lengths of each sequence in the batch. Batch elements will be re-ordered as they were ordered originally when the batch was passed to <code>pack_padded_sequence</code> or <code>pack_sequence</code>.</p> </dd> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)">Tuple</a>[<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>, <a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>]</p> </dd> </dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.nn.utils.rnn.pad_packed_sequence.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.nn.utils.rnn.pad_packed_sequence.html</a>
  </p>
</div>
