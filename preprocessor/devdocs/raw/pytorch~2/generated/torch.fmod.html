<h1 id="torch-fmod">torch.fmod</h1> <dl class="py function"> <dt class="sig sig-object py" id="torch.fmod">
<code>torch.fmod(input, other, *, out=None) → Tensor</code> </dt> <dd>
<p>Applies C++’s <a class="reference external" href="https://en.cppreference.com/w/cpp/numeric/math/fmod">std::fmod</a> entrywise. The result has the same sign as the dividend <code>input</code> and its absolute value is less than that of <code>other</code>.</p> <p>This function may be defined in terms of <a class="reference internal" href="torch.div#torch.div" title="torch.div"><code>torch.div()</code></a> as</p> <pre data-language="python">torch.fmod(a, b) == a - a.div(b, rounding_mode="trunc") * b
</pre> <p>Supports <a class="reference internal" href="https://pytorch.org/docs/2.1/notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcasting to a common shape</span></a>, <a class="reference internal" href="../tensor_attributes#type-promotion-doc"><span class="std std-ref">type promotion</span></a>, and integer and float inputs.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>When the divisor is zero, returns <code>NaN</code> for floating point dtypes on both CPU and GPU; raises <code>RuntimeError</code> for integer division by zero on CPU; Integer division by zero on GPU may return any value.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Complex inputs are not supported. In some cases, it is not mathematically possible to satisfy the definition of a modulo operation with complex numbers.</p> </div> <div class="admonition seealso"> <p class="admonition-title">See also</p> <p><a class="reference internal" href="torch.remainder#torch.remainder" title="torch.remainder"><code>torch.remainder()</code></a> which implements Python’s modulus operator. This one is defined using division rounding down the result.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the dividend</li> <li>
<strong>other</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em> or </em><em>Scalar</em>) – the divisor</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; torch.fmod(torch.tensor([-3., -2, -1, 1, 2, 3]), 2)
tensor([-1., -0., -1.,  1.,  0.,  1.])
&gt;&gt;&gt; torch.fmod(torch.tensor([1, 2, 3, 4, 5]), -1.5)
tensor([1.0000, 0.5000, 0.0000, 1.0000, 0.5000])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/generated/torch.fmod.html" class="_attribution-link">https://pytorch.org/docs/2.1/generated/torch.fmod.html</a>
  </p>
</div>
