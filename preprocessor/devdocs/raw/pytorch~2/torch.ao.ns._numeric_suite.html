<h1 id="id1">torch.ao.ns._numeric_suite</h1> <div class="admonition warning" id="torch-ao-ns-numeric-suite"> <p class="admonition-title">Warning</p> <p>This module is an early prototype and is subject to change.</p> </div> <dl class="py function" id="module-torch.ao.ns._numeric_suite"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.compare_weights">
<code>torch.ao.ns._numeric_suite.compare_weights(float_dict, quantized_dict)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#compare_weights"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compare the weights of the float module with its corresponding quantized module. Return a dict with key corresponding to module names and each entry being a dictionary with two keys ‘float’ and ‘quantized’, containing the float and quantized weights. This dict can be used to compare and compute the quantization error of the weights of float and quantized models.</p> <p>Example usage:</p> <pre data-language="python">wt_compare_dict = compare_weights(
    float_model.state_dict(), qmodel.state_dict())
for key in wt_compare_dict:
    print(
        key,
        compute_error(
            wt_compare_dict[key]['float'],
            wt_compare_dict[key]['quantized'].dequantize()
        )
    )
</pre> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>float_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.12)">Dict</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.12)">Any</a><em>]</em>) – state dict of the float model</li> <li>
<strong>quantized_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.12)">Dict</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Any" title="(in Python v3.12)">Any</a><em>]</em>) – state dict of the quantized model</li> </ul> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<p>dict with key corresponding to module names and each entry being a dictionary with two keys ‘float’ and ‘quantized’, containing the float and quantized weights</p> </dd> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p>weight_dict</p> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.get_logger_dict">
<code>torch.ao.ns._numeric_suite.get_logger_dict(mod, prefix='')</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#get_logger_dict"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Traverse the modules and save all logger stats into target dict. This is mainly used for quantization accuracy debug.</p> <dl class="simple"> <dt>Type of loggers supported:</dt>
<dd>
<p>ShadowLogger: used to log the outputs of the quantized module and its matching float shadow module, OutputLogger: used to log the outputs of the modules</p> </dd> </dl> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>mod</strong> (<a class="reference internal" href="generated/torch.nn.module#torch.nn.Module" title="torch.nn.modules.module.Module">Module</a>) – module we want to save all logger stats</li> <li>
<strong>prefix</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>) – prefix for the current module</li> </ul> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<p>the dictionary used to save all logger stats</p> </dd> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p>target_dict</p> </dd> </dl> </dd>
</dl> <dl class="py class"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.Logger">
<code>class torch.ao.ns._numeric_suite.Logger</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#Logger"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Base class for stats logging</p> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.Logger.forward">
<code>forward(x)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#Logger.forward"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> </dd>
</dl> <dl class="py class"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.ShadowLogger">
<code>class torch.ao.ns._numeric_suite.ShadowLogger</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#ShadowLogger"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Class used in Shadow module to record the outputs of the original and shadow modules.</p> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.ShadowLogger.forward">
<code>forward(x, y)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#ShadowLogger.forward"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> </dd>
</dl> <dl class="py class"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.OutputLogger">
<code>class torch.ao.ns._numeric_suite.OutputLogger</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#OutputLogger"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Class used to log the outputs of the module</p> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.OutputLogger.forward">
<code>forward(x)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#OutputLogger.forward"><span class="viewcode-link">[source]</span></a>
</dt> 
</dl> </dd>
</dl> <dl class="py class"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.Shadow">
<code>class torch.ao.ns._numeric_suite.Shadow(q_module, float_module, logger_cls)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#Shadow"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Shadow module attaches the float module to its matching quantized module as the shadow. Then it uses Logger module to process the outputs of both modules.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>q_module</strong> – module quantized from float_module that we want to shadow</li> <li>
<strong>float_module</strong> – float module used to shadow q_module</li> <li>
<strong>logger_cls</strong> – type of logger used to process the outputs of q_module and float_module. ShadowLogger or custom loggers can be used.</li> </ul> </dd> </dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.Shadow.forward">
<code>forward(*x)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#Shadow.forward"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.Shadow.add">
<code>add(x, y)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#Shadow.add"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.Shadow.add_scalar">
<code>add_scalar(x, y)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#Shadow.add_scalar"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.Shadow.mul">
<code>mul(x, y)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#Shadow.mul"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.Shadow.mul_scalar">
<code>mul_scalar(x, y)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#Shadow.mul_scalar"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.Shadow.cat">
<code>cat(x, dim=0)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#Shadow.cat"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a></p> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.Shadow.add_relu">
<code>add_relu(x, y)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#Shadow.add_relu"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<dl class="field-list simple"> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p><a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor">Tensor</a></p> </dd> </dl> </dd>
</dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.prepare_model_with_stubs">
<code>torch.ao.ns._numeric_suite.prepare_model_with_stubs(float_module, q_module, module_swap_list, logger_cls)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#prepare_model_with_stubs"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Prepare the model by attaching the float module to its matching quantized module as the shadow if the float module type is in module_swap_list.</p> <p>Example usage:</p> <pre data-language="python">prepare_model_with_stubs(float_model, q_model, module_swap_list, Logger)
q_model(data)
ob_dict = get_logger_dict(q_model)
</pre> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>float_module</strong> (<a class="reference internal" href="generated/torch.nn.module#torch.nn.Module" title="torch.nn.modules.module.Module">Module</a>) – float module used to generate the q_module</li> <li>
<strong>q_module</strong> (<a class="reference internal" href="generated/torch.nn.module#torch.nn.Module" title="torch.nn.modules.module.Module">Module</a>) – module quantized from float_module</li> <li>
<strong>module_swap_list</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Set" title="(in Python v3.12)">Set</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.12)">type</a><em>]</em>) – list of float module types to attach the shadow</li> <li>
<strong>logger_cls</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.12)">Callable</a>) – type of logger to be used in shadow module to process the outputs of quantized module and its float shadow module</li> </ul> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.compare_model_stub">
<code>torch.ao.ns._numeric_suite.compare_model_stub(float_model, q_model, module_swap_list, *data, logger_cls=&lt;class 'torch.ao.ns._numeric_suite.ShadowLogger'&gt;)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#compare_model_stub"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compare quantized module in a model with its floating point counterpart, feeding both of them the same input. Return a dict with key corresponding to module names and each entry being a dictionary with two keys ‘float’ and ‘quantized’, containing the output tensors of quantized and its matching float shadow module. This dict can be used to compare and compute the module level quantization error.</p> <p>This function first call prepare_model_with_stubs() to swap the quantized module that we want to compare with the Shadow module, which takes quantized module, corresponding float module and logger as input, and creates a forward path inside to make the float module to shadow quantized module sharing the same input. The logger can be customizable, default logger is ShadowLogger and it will save the outputs of the quantized module and float module that can be used to compute the module level quantization error.</p> <p>Example usage:</p> <pre data-language="python">module_swap_list = [torchvision.models.quantization.resnet.QuantizableBasicBlock]
ob_dict = compare_model_stub(float_model,qmodel,module_swap_list, data)
for key in ob_dict:
    print(key, compute_error(ob_dict[key]['float'], ob_dict[key]['quantized'].dequantize()))
</pre> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>float_model</strong> (<a class="reference internal" href="generated/torch.nn.module#torch.nn.Module" title="torch.nn.modules.module.Module">Module</a>) – float model used to generate the q_model</li> <li>
<strong>q_model</strong> (<a class="reference internal" href="generated/torch.nn.module#torch.nn.Module" title="torch.nn.modules.module.Module">Module</a>) – model quantized from float_model</li> <li>
<strong>module_swap_list</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Set" title="(in Python v3.12)">Set</a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.12)">type</a><em>]</em>) – list of float module types at which shadow modules will be attached.</li> <li>
<strong>data</strong> – input data used to run the prepared q_model</li> <li>
<strong>logger_cls</strong> – type of logger to be used in shadow module to process the outputs of quantized module and its float shadow module</li> </ul> </dd> <dt class="field-even">Return type</dt> <dd class="field-even">
<p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.12)">Dict</a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)">str</a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Dict" title="(in Python v3.12)">Dict</a>]</p> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.get_matching_activations">
<code>torch.ao.ns._numeric_suite.get_matching_activations(float_module, q_module)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#get_matching_activations"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Find the matching activation between float and quantized modules.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>float_module</strong> (<a class="reference internal" href="generated/torch.nn.module#torch.nn.Module" title="torch.nn.modules.module.Module">Module</a>) – float module used to generate the q_module</li> <li>
<strong>q_module</strong> (<a class="reference internal" href="generated/torch.nn.module#torch.nn.Module" title="torch.nn.modules.module.Module">Module</a>) – module quantized from float_module</li> </ul> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<p>dict with key corresponding to quantized module names and each entry being a dictionary with two keys ‘float’ and ‘quantized’, containing the matching float and quantized activations</p> </dd> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p>act_dict</p> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.prepare_model_outputs">
<code>torch.ao.ns._numeric_suite.prepare_model_outputs(float_module, q_module, logger_cls=&lt;class 'torch.ao.ns._numeric_suite.OutputLogger'&gt;, allow_list=None)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#prepare_model_outputs"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Prepare the model by attaching the logger to both float module and quantized module if they are in the allow_list.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>float_module</strong> (<a class="reference internal" href="generated/torch.nn.module#torch.nn.Module" title="torch.nn.modules.module.Module">Module</a>) – float module used to generate the q_module</li> <li>
<strong>q_module</strong> (<a class="reference internal" href="generated/torch.nn.module#torch.nn.Module" title="torch.nn.modules.module.Module">Module</a>) – module quantized from float_module</li> <li>
<strong>logger_cls</strong> – type of logger to be attached to float_module and q_module</li> <li>
<strong>allow_list</strong> – list of module types to attach logger</li> </ul> </dd> </dl> </dd>
</dl> <dl class="py function"> <dt class="sig sig-object py" id="torch.ao.ns._numeric_suite.compare_model_outputs">
<code>torch.ao.ns._numeric_suite.compare_model_outputs(float_model, q_model, *data, logger_cls=&lt;class 'torch.ao.ns._numeric_suite.OutputLogger'&gt;, allow_list=None)</code> <a class="reference internal" href="https://pytorch.org/docs/2.1/_modules/torch/ao/ns/_numeric_suite.html#compare_model_outputs"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Compare output activations between float and quantized models at corresponding locations for the same input. Return a dict with key corresponding to quantized module names and each entry being a dictionary with two keys ‘float’ and ‘quantized’, containing the activations of quantized model and float model at matching locations. This dict can be used to compare and compute the propagation quantization error.</p> <p>Example usage:</p> <pre data-language="python">act_compare_dict = compare_model_outputs(float_model, qmodel, data)
for key in act_compare_dict:
    print(
        key,
        compute_error(
            act_compare_dict[key]['float'],
            act_compare_dict[key]['quantized'].dequantize()
        )
    )
</pre> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>float_model</strong> (<a class="reference internal" href="generated/torch.nn.module#torch.nn.Module" title="torch.nn.modules.module.Module">Module</a>) – float model used to generate the q_model</li> <li>
<strong>q_model</strong> (<a class="reference internal" href="generated/torch.nn.module#torch.nn.Module" title="torch.nn.modules.module.Module">Module</a>) – model quantized from float_model</li> <li>
<strong>data</strong> – input data used to run the prepared float_model and q_model</li> <li>
<strong>logger_cls</strong> – type of logger to be attached to float_module and q_module</li> <li>
<strong>allow_list</strong> – list of module types to attach logger</li> </ul> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<p>dict with key corresponding to quantized module names and each entry being a dictionary with two keys ‘float’ and ‘quantized’, containing the matching float and quantized activations</p> </dd> <dt class="field-odd">Return type</dt> <dd class="field-odd">
<p>act_compare_dict</p> </dd> </dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/torch.ao.ns._numeric_suite.html" class="_attribution-link">https://pytorch.org/docs/2.1/torch.ao.ns._numeric_suite.html</a>
  </p>
</div>
