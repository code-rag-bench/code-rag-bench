<h1>pandas.DataFrame.to_hdf</h1> <dl class="py method"> <dt class="sig sig-object py" id="pandas.DataFrame.to_hdf"> <span class="sig-prename descclassname"><span class="pre">DataFrame.</span></span><span class="sig-name descname"><span class="pre">to_hdf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path_or_buf</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'a'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complevel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complib</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">append</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">format</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_itemsize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nan_rep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropna</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_columns</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">errors</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'strict'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encoding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'UTF-8'</span></span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/pandas-dev/pandas/blob/v1.4.0/pandas/core/generic.py#L2649-L2791"><span class="viewcode-link"><span class="pre">[source]</span></span></a>
</dt> <dd>
<p>Write the contained data to an HDF5 file using HDFStore.</p> <p>Hierarchical Data Format (HDF) is self-describing, allowing an application to interpret the structure and contents of a file with no outside information. One HDF file can hold a mix of related objects which can be accessed as a group or as individual objects.</p> <p>In order to add another DataFrame or Series to an existing HDF file please use append mode and a different a key.</p> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>One can store a subclass of <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> or <code class="docutils literal notranslate"><span class="pre">Series</span></code> to HDF5, but the type of the subclass is lost upon storing.</p> </div> <p>For more information see the <a class="reference internal" href="../../user_guide/io#io-hdf5"><span class="std std-ref">user guide</span></a>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>path_or_buf</strong><span class="classifier">:str or pandas.HDFStore</span>
</dt>
<dd>
<p>File path or HDFStore object.</p> </dd> <dt>
<strong>key</strong><span class="classifier">:str</span>
</dt>
<dd>
<p>Identifier for the group in the store.</p> </dd> <dt>
<strong>mode</strong><span class="classifier">:{‘a’, ‘w’, ‘r+’}, default ‘a’</span>
</dt>
<dd>
<p>Mode to open file:</p> <ul class="simple"> <li><p>‘w’: write, a new file is created (an existing file with the same name would be deleted).</p></li> <li><p>‘a’: append, an existing file is opened for reading and writing, and if the file does not exist it is created.</p></li> <li><p>‘r+’: similar to ‘a’, but the file must already exist.</p></li> </ul> </dd> <dt>
<strong>complevel</strong><span class="classifier">:{0-9}, default None</span>
</dt>
<dd>
<p>Specifies a compression level for data. A value of 0 or None disables compression.</p> </dd> <dt>
<strong>complib</strong><span class="classifier">:{‘zlib’, ‘lzo’, ‘bzip2’, ‘blosc’}, default ‘zlib’</span>
</dt>
<dd>
<p>Specifies the compression library to be used. As of v0.20.2 these additional compressors for Blosc are supported (default if no compressor specified: ‘blosc:blosclz’): {‘blosc:blosclz’, ‘blosc:lz4’, ‘blosc:lz4hc’, ‘blosc:snappy’, ‘blosc:zlib’, ‘blosc:zstd’}. Specifying a compression library which is not available issues a ValueError.</p> </dd> <dt>
<strong>append</strong><span class="classifier">:bool, default False</span>
</dt>
<dd>
<p>For Table formats, append the input data to the existing.</p> </dd> <dt>
<strong>format</strong><span class="classifier">:{‘fixed’, ‘table’, None}, default ‘fixed’</span>
</dt>
<dd>
<p>Possible values:</p> <ul class="simple"> <li><p>‘fixed’: Fixed format. Fast writing/reading. Not-appendable, nor searchable.</p></li> <li><p>‘table’: Table format. Write as a PyTables Table structure which may perform worse but allow more flexible operations like searching / selecting subsets of the data.</p></li> <li><p>If None, pd.get_option(‘io.hdf.default_format’) is checked, followed by fallback to “fixed”.</p></li> </ul> </dd> <dt>
<strong>errors</strong><span class="classifier">:str, default ‘strict’</span>
</dt>
<dd>
<p>Specifies how encoding and decoding errors are to be handled. See the errors argument for <a class="reference external" href="https://docs.python.org/3/library/functions.html#open" title="(in Python v3.10)"><code class="xref py py-func docutils literal notranslate"><span class="pre">open()</span></code></a> for a full list of options.</p> </dd> <dt>
<strong>encoding</strong><span class="classifier">:str, default “UTF-8”</span>
</dt>
 <dt>
<strong>min_itemsize</strong><span class="classifier">:dict or int, optional</span>
</dt>
<dd>
<p>Map column names to minimum string sizes for columns.</p> </dd> <dt>
<strong>nan_rep</strong><span class="classifier">:Any, optional</span>
</dt>
<dd>
<p>How to represent null values as str. Not allowed with append=True.</p> </dd> <dt>
<strong>data_columns</strong><span class="classifier">:list of columns or True, optional</span>
</dt>
<dd>
<p>List of columns to create as indexed data columns for on-disk queries, or True to use all columns. By default only the axes of the object are indexed. See <a class="reference internal" href="../../user_guide/io#io-hdf5-query-data-columns"><span class="std std-ref">Query via data columns</span></a>. Applicable only to format=’table’.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="pandas.read_hdf#pandas.read_hdf" title="pandas.read_hdf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">read_hdf</span></code></a></dt>
<dd>
<p>Read from HDF file.</p> </dd> <dt><a class="reference internal" href="pandas.dataframe.to_parquet#pandas.DataFrame.to_parquet" title="pandas.DataFrame.to_parquet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataFrame.to_parquet</span></code></a></dt>
<dd>
<p>Write a DataFrame to the binary parquet format.</p> </dd> <dt><a class="reference internal" href="pandas.dataframe.to_sql#pandas.DataFrame.to_sql" title="pandas.DataFrame.to_sql"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataFrame.to_sql</span></code></a></dt>
<dd>
<p>Write to a SQL table.</p> </dd> <dt><a class="reference internal" href="pandas.dataframe.to_feather#pandas.DataFrame.to_feather" title="pandas.DataFrame.to_feather"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataFrame.to_feather</span></code></a></dt>
<dd>
<p>Write out feather-format for DataFrames.</p> </dd> <dt><a class="reference internal" href="pandas.dataframe.to_csv#pandas.DataFrame.to_csv" title="pandas.DataFrame.to_csv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DataFrame.to_csv</span></code></a></dt>
<dd>
<p>Write out to a csv file.</p> </dd> </dl> </div> <p class="rubric">Examples</p> <div class="doctest highlight-default notranslate">
<div class="highlight"><pre data-language="python">&gt;&gt;&gt; df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]},
...                   index=['a', 'b', 'c'])  
&gt;&gt;&gt; df.to_hdf('data.h5', key='df', mode='w')  
</pre></div> </div> <p>We can add another object to the same file:</p> <div class="doctest highlight-default notranslate">
<div class="highlight"><pre data-language="python">&gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])  
&gt;&gt;&gt; s.to_hdf('data.h5', key='s')  
</pre></div> </div> <p>Reading from HDF file:</p> <div class="doctest highlight-default notranslate">
<div class="highlight"><pre data-language="python">&gt;&gt;&gt; pd.read_hdf('data.h5', 'df')  
A  B
a  1  4
b  2  5
c  3  6
&gt;&gt;&gt; pd.read_hdf('data.h5', 's')  
0    1
1    2
2    3
3    4
dtype: int64
</pre></div> </div> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2008&ndash;2022, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://pandas.pydata.org/pandas-docs/version/1.4.0/reference/api/pandas.DataFrame.to_hdf.html" class="_attribution-link">https://pandas.pydata.org/pandas-docs/version/1.4.0/reference/api/pandas.DataFrame.to_hdf.html</a>
  </p>
</div>
