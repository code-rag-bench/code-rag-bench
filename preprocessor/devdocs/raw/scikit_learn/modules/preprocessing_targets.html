<h1 id="preprocessing-targets">6.9. Transforming the prediction target (y)</h1> <p>These are transformers that are not intended to be used on features, only on supervised learning targets. See also <a class="reference internal" href="compose#transformed-target-regressor"><span class="std std-ref">Transforming target in regression</span></a> if you want to transform the prediction target for learning, but evaluate the model in the original (untransformed) space.</p>  <h2 id="label-binarization">
<span class="section-number">6.9.1. </span>Label binarization</h2>  <h3 id="labelbinarizer">
<span class="section-number">6.9.1.1. </span>LabelBinarizer</h3> <p><a class="reference internal" href="generated/sklearn.preprocessing.labelbinarizer#sklearn.preprocessing.LabelBinarizer" title="sklearn.preprocessing.LabelBinarizer"><code>LabelBinarizer</code></a> is a utility class to help create a <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-label-indicator-matrix"><span class="xref std std-term">label indicator matrix</span></a> from a list of <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-multiclass"><span class="xref std std-term">multiclass</span></a> labels:</p> <pre data-language="python">&gt;&gt;&gt; from sklearn import preprocessing
&gt;&gt;&gt; lb = preprocessing.LabelBinarizer()
&gt;&gt;&gt; lb.fit([1, 2, 6, 4, 2])
LabelBinarizer()
&gt;&gt;&gt; lb.classes_
array([1, 2, 4, 6])
&gt;&gt;&gt; lb.transform([1, 6])
array([[1, 0, 0, 0],
       [0, 0, 0, 1]])
</pre> <p>Using this format can enable multiclass classification in estimators that support the label indicator matrix format.</p> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>LabelBinarizer is not needed if you are using an estimator that already supports <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-multiclass"><span class="xref std std-term">multiclass</span></a> data.</p> </div> <p>For more information about multiclass classification, refer to <a class="reference internal" href="multiclass#multiclass-classification"><span class="std std-ref">Multiclass classification</span></a>.</p>   <h3 id="multilabelbinarizer">
<span class="section-number">6.9.1.2. </span>MultiLabelBinarizer</h3> <p>In <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-multilabel"><span class="xref std std-term">multilabel</span></a> learning, the joint set of binary classification tasks is expressed with a label binary indicator array: each sample is one row of a 2d array of shape (n_samples, n_classes) with binary values where the one, i.e. the non zero elements, corresponds to the subset of labels for that sample. An array such as <code>np.array([[1, 0, 0], [0, 1, 1], [0, 0, 0]])</code> represents label 0 in the first sample, labels 1 and 2 in the second sample, and no labels in the third sample.</p> <p>Producing multilabel data as a list of sets of labels may be more intuitive. The <a class="reference internal" href="generated/sklearn.preprocessing.multilabelbinarizer#sklearn.preprocessing.MultiLabelBinarizer" title="sklearn.preprocessing.MultiLabelBinarizer"><code>MultiLabelBinarizer</code></a> transformer can be used to convert between a collection of collections of labels and the indicator format:</p> <pre data-language="python">&gt;&gt;&gt; from sklearn.preprocessing import MultiLabelBinarizer
&gt;&gt;&gt; y = [[2, 3, 4], [2], [0, 1, 3], [0, 1, 2, 3, 4], [0, 1, 2]]
&gt;&gt;&gt; MultiLabelBinarizer().fit_transform(y)
array([[0, 0, 1, 1, 1],
       [0, 0, 1, 0, 0],
       [1, 1, 0, 1, 0],
       [1, 1, 1, 1, 1],
       [1, 1, 1, 0, 0]])
</pre> <p>For more information about multilabel classification, refer to <a class="reference internal" href="multiclass#multilabel-classification"><span class="std std-ref">Multilabel classification</span></a>.</p>    <h2 id="label-encoding">
<span class="section-number">6.9.2. </span>Label encoding</h2> <p><a class="reference internal" href="generated/sklearn.preprocessing.labelencoder#sklearn.preprocessing.LabelEncoder" title="sklearn.preprocessing.LabelEncoder"><code>LabelEncoder</code></a> is a utility class to help normalize labels such that they contain only values between 0 and n_classes-1. This is sometimes useful for writing efficient Cython routines. <a class="reference internal" href="generated/sklearn.preprocessing.labelencoder#sklearn.preprocessing.LabelEncoder" title="sklearn.preprocessing.LabelEncoder"><code>LabelEncoder</code></a> can be used as follows:</p> <pre data-language="python">&gt;&gt;&gt; from sklearn import preprocessing
&gt;&gt;&gt; le = preprocessing.LabelEncoder()
&gt;&gt;&gt; le.fit([1, 2, 2, 6])
LabelEncoder()
&gt;&gt;&gt; le.classes_
array([1, 2, 6])
&gt;&gt;&gt; le.transform([1, 1, 2, 6])
array([0, 0, 1, 2])
&gt;&gt;&gt; le.inverse_transform([0, 0, 1, 2])
array([1, 1, 2, 6])
</pre> <p>It can also be used to transform non-numerical labels (as long as they are hashable and comparable) to numerical labels:</p> <pre data-language="python">&gt;&gt;&gt; le = preprocessing.LabelEncoder()
&gt;&gt;&gt; le.fit(["paris", "paris", "tokyo", "amsterdam"])
LabelEncoder()
&gt;&gt;&gt; list(le.classes_)
['amsterdam', 'paris', 'tokyo']
&gt;&gt;&gt; le.transform(["tokyo", "tokyo", "paris"])
array([2, 2, 1])
&gt;&gt;&gt; list(le.inverse_transform([2, 2, 1]))
['tokyo', 'tokyo', 'paris']
</pre><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/preprocessing_targets.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/preprocessing_targets.html</a>
  </p>
</div>
