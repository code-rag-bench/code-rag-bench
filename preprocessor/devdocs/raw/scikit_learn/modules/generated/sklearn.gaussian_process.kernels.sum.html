<h1>sklearn.gaussian_process.kernels.Sum</h1> <dl class="py class"> <dt id="sklearn.gaussian_process.kernels.Sum">
<code>class sklearn.gaussian_process.kernels.Sum(k1, k2)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/gaussian_process/kernels.py#L746"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>The <code>Sum</code> kernel takes two kernels <span class="math notranslate nohighlight">\(k_1\)</span> and <span class="math notranslate nohighlight">\(k_2\)</span> and combines them via</p> <div class="math notranslate nohighlight"> \[k_{sum}(X, Y) = k_1(X, Y) + k_2(X, Y)\]</div> <p>Note that the <code>__add__</code> magic method is overridden, so <code>Sum(RBF(), RBF())</code> is equivalent to using the + operator with <code>RBF() + RBF()</code>.</p> <p>Read more in the <a class="reference internal" href="../gaussian_process#gp-kernels"><span class="std std-ref">User Guide</span></a>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.18.</span></p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>k1Kernel</code> </dt>
<dd>
<p>The first base-kernel of the sum-kernel</p> </dd> <dt>
<code>k2Kernel</code> </dt>
<dd>
<p>The second base-kernel of the sum-kernel</p> </dd> </dl> </dd> <dt class="field-even">Attributes</dt> <dd class="field-even">
<dl class="simple"> <dt>
 <a class="reference internal" href="#sklearn.gaussian_process.kernels.Sum.bounds" title="sklearn.gaussian_process.kernels.Sum.bounds"><code>bounds</code></a>
</dt>
<dd>
<p>Returns the log-transformed bounds on the theta.</p> </dd> <dt>
 <a class="reference internal" href="#sklearn.gaussian_process.kernels.Sum.hyperparameters" title="sklearn.gaussian_process.kernels.Sum.hyperparameters"><code>hyperparameters</code></a>
</dt>
<dd>
<p>Returns a list of all hyperparameter.</p> </dd> <dt>
 <a class="reference internal" href="#sklearn.gaussian_process.kernels.Sum.n_dims" title="sklearn.gaussian_process.kernels.Sum.n_dims"><code>n_dims</code></a>
</dt>
<dd>
<p>Returns the number of non-fixed hyperparameters of the kernel.</p> </dd> <dt>
 <a class="reference internal" href="#sklearn.gaussian_process.kernels.Sum.requires_vector_input" title="sklearn.gaussian_process.kernels.Sum.requires_vector_input"><code>requires_vector_input</code></a>
</dt>
<dd>
<p>Returns whether the kernel is stationary.</p> </dd> <dt>
 <a class="reference internal" href="#sklearn.gaussian_process.kernels.Sum.theta" title="sklearn.gaussian_process.kernels.Sum.theta"><code>theta</code></a>
</dt>
<dd>
<p>Returns the (flattened, log-transformed) non-fixed hyperparameters.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.datasets import make_friedman2
&gt;&gt;&gt; from sklearn.gaussian_process import GaussianProcessRegressor
&gt;&gt;&gt; from sklearn.gaussian_process.kernels import RBF, Sum, ConstantKernel
&gt;&gt;&gt; X, y = make_friedman2(n_samples=500, noise=0, random_state=0)
&gt;&gt;&gt; kernel = Sum(ConstantKernel(2), RBF())
&gt;&gt;&gt; gpr = GaussianProcessRegressor(kernel=kernel,
...         random_state=0).fit(X, y)
&gt;&gt;&gt; gpr.score(X, y)
1.0
&gt;&gt;&gt; kernel
1.41**2 + RBF(length_scale=1)
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils align-default">   <tr>
<td><p><a class="reference internal" href="#sklearn.gaussian_process.kernels.Sum.__call__" title="sklearn.gaussian_process.kernels.Sum.__call__"><code>__call__</code></a>(X[, Y, eval_gradient])</p></td> <td><p>Return the kernel k(X, Y) and optionally its gradient.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.gaussian_process.kernels.Sum.clone_with_theta" title="sklearn.gaussian_process.kernels.Sum.clone_with_theta"><code>clone_with_theta</code></a>(theta)</p></td> <td><p>Returns a clone of self with given hyperparameters theta.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.gaussian_process.kernels.Sum.diag" title="sklearn.gaussian_process.kernels.Sum.diag"><code>diag</code></a>(X)</p></td> <td><p>Returns the diagonal of the kernel k(X, X).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.gaussian_process.kernels.Sum.get_params" title="sklearn.gaussian_process.kernels.Sum.get_params"><code>get_params</code></a>([deep])</p></td> <td><p>Get parameters of this kernel.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.gaussian_process.kernels.Sum.is_stationary" title="sklearn.gaussian_process.kernels.Sum.is_stationary"><code>is_stationary</code></a>()</p></td> <td><p>Returns whether the kernel is stationary.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.gaussian_process.kernels.Sum.set_params" title="sklearn.gaussian_process.kernels.Sum.set_params"><code>set_params</code></a>(**params)</p></td> <td><p>Set the parameters of this kernel.</p></td> </tr>  </table> <dl class="py method"> <dt id="sklearn.gaussian_process.kernels.Sum.__call__">
<code>__call__(X, Y=None, eval_gradient=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/gaussian_process/kernels.py#L785"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the kernel k(X, Y) and optionally its gradient.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples_X, n_features) or list of object</code> </dt>
<dd>
<p>Left argument of the returned kernel k(X, Y)</p> </dd> <dt>
<code>Yarray-like of shape (n_samples_X, n_features) or list of object, default=None</code> </dt>
<dd>
<p>Right argument of the returned kernel k(X, Y). If None, k(X, X) is evaluated instead.</p> </dd> <dt>
<code>eval_gradientbool, default=False</code> </dt>
<dd>
<p>Determines whether the gradient with respect to the log of the kernel hyperparameter is computed.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>Kndarray of shape (n_samples_X, n_samples_Y)</code> </dt>
<dd>
<p>Kernel k(X, Y)</p> </dd> <dt>
<code>K_gradientndarray of shape (n_samples_X, n_samples_X, n_dims), optional</code> </dt>
<dd>
<p>The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when <code>eval_gradient</code> is True.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.gaussian_process.kernels.Sum.bounds">
<code>property bounds</code> </dt> <dd>
<p>Returns the log-transformed bounds on the theta.</p> <dl class="field-list simple"> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>boundsndarray of shape (n_dims, 2)</code> </dt>
<dd>
<p>The log-transformed bounds on the kernel’s hyperparameters theta</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.gaussian_process.kernels.Sum.clone_with_theta">
<code>clone_with_theta(theta)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/gaussian_process/kernels.py#L227"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns a clone of self with given hyperparameters theta.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>thetandarray of shape (n_dims,)</code> </dt>
<dd>
<p>The hyperparameters</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.gaussian_process.kernels.Sum.diag">
<code>diag(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/gaussian_process/kernels.py#L820"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns the diagonal of the kernel k(X, X).</p> <p>The result of this method is identical to <code>np.diag(self(X))</code>; however, it can be evaluated more efficiently since only the diagonal is evaluated.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples_X, n_features) or list of object</code> </dt>
<dd>
<p>Argument to the kernel.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>K_diagndarray of shape (n_samples_X,)</code> </dt>
<dd>
<p>Diagonal of kernel k(X, X)</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.gaussian_process.kernels.Sum.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/gaussian_process/kernels.py#L647"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters of this kernel.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>deepbool, default=True</code> </dt>
<dd>
<p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>paramsdict</code> </dt>
<dd>
<p>Parameter names mapped to their values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.gaussian_process.kernels.Sum.hyperparameters">
<code>property hyperparameters</code> </dt> <dd>
<p>Returns a list of all hyperparameter.</p> </dd>
</dl> <dl class="py method"> <dt id="sklearn.gaussian_process.kernels.Sum.is_stationary">
<code>is_stationary()</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/gaussian_process/kernels.py#L735"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Returns whether the kernel is stationary.</p> </dd>
</dl> <dl class="py method"> <dt id="sklearn.gaussian_process.kernels.Sum.n_dims">
<code>property n_dims</code> </dt> <dd>
<p>Returns the number of non-fixed hyperparameters of the kernel.</p> </dd>
</dl> <dl class="py method"> <dt id="sklearn.gaussian_process.kernels.Sum.requires_vector_input">
<code>property requires_vector_input</code> </dt> <dd>
<p>Returns whether the kernel is stationary.</p> </dd>
</dl> <dl class="py method"> <dt id="sklearn.gaussian_process.kernels.Sum.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/gaussian_process/kernels.py#L190"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this kernel.</p> <p>The method works on simple kernels as well as on nested kernels. The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<dl class="simple"> <dt>self</dt>
 </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.gaussian_process.kernels.Sum.theta">
<code>property theta</code> </dt> <dd>
<p>Returns the (flattened, log-transformed) non-fixed hyperparameters.</p> <p>Note that theta are typically the log-transformed values of the kernel’s hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale.</p> <dl class="field-list simple"> <dt class="field-odd">Returns</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>thetandarray of shape (n_dims,)</code> </dt>
<dd>
<p>The non-fixed, log-transformed hyperparameters of the kernel</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/generated/sklearn.gaussian_process.kernels.Sum.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/generated/sklearn.gaussian_process.kernels.Sum.html</a>
  </p>
</div>
