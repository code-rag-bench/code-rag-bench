<h1 id="torch">torch</h1> <p>The torch package contains data structures for multi-dimensional tensors and defines mathematical operations over these tensors. Additionally, it provides many utilities for efficient serializing of Tensors and arbitrary types, and other useful utilities.</p> <p>It has a CUDA counterpart, that enables you to run your tensor computations on an NVIDIA GPU with compute capability &gt;= 3.0</p>  <h2 id="tensors">Tensors</h2> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.is_tensor#torch.is_tensor" title="torch.is_tensor"><code>is_tensor</code></a>
</td> <td><p>Returns True if <code>obj</code> is a PyTorch tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.is_storage#torch.is_storage" title="torch.is_storage"><code>is_storage</code></a>
</td> <td><p>Returns True if <code>obj</code> is a PyTorch storage object.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.is_complex#torch.is_complex" title="torch.is_complex"><code>is_complex</code></a>
</td> <td><p>Returns True if the data type of <code>input</code> is a complex data type i.e., one of <code>torch.complex64</code>, and <code>torch.complex128</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.is_floating_point#torch.is_floating_point" title="torch.is_floating_point"><code>is_floating_point</code></a>
</td> <td><p>Returns True if the data type of <code>input</code> is a floating point data type i.e., one of <code>torch.float64</code>, <code>torch.float32</code>, <code>torch.float16</code>, and <code>torch.bfloat16</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.is_nonzero#torch.is_nonzero" title="torch.is_nonzero"><code>is_nonzero</code></a>
</td> <td><p>Returns True if the <code>input</code> is a single element tensor which is not equal to zero after type conversions.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.set_default_dtype#torch.set_default_dtype" title="torch.set_default_dtype"><code>set_default_dtype</code></a>
</td> <td><p>Sets the default floating point dtype to <code>d</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.get_default_dtype#torch.get_default_dtype" title="torch.get_default_dtype"><code>get_default_dtype</code></a>
</td> <td><p>Get the current default floating point <a class="reference internal" href="tensor_attributes#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.set_default_tensor_type#torch.set_default_tensor_type" title="torch.set_default_tensor_type"><code>set_default_tensor_type</code></a>
</td> <td><p>Sets the default <code>torch.Tensor</code> type to floating point tensor type <code>t</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.numel#torch.numel" title="torch.numel"><code>numel</code></a>
</td> <td><p>Returns the total number of elements in the <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.set_printoptions#torch.set_printoptions" title="torch.set_printoptions"><code>set_printoptions</code></a>
</td> <td><p>Set options for printing.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.set_flush_denormal#torch.set_flush_denormal" title="torch.set_flush_denormal"><code>set_flush_denormal</code></a>
</td> <td><p>Disables denormal floating numbers on CPU.</p></td> </tr>  </table>  <h3 id="tensor-creation-ops">Creation Ops</h3> <div class="admonition note" id="creation-ops"> <p class="admonition-title">Note</p> <p>Random sampling creation ops are listed under <a class="reference internal" href="#random-sampling"><span class="std std-ref">Random sampling</span></a> and include: <a class="reference internal" href="generated/torch.rand#torch.rand" title="torch.rand"><code>torch.rand()</code></a> <a class="reference internal" href="generated/torch.rand_like#torch.rand_like" title="torch.rand_like"><code>torch.rand_like()</code></a> <a class="reference internal" href="generated/torch.randn#torch.randn" title="torch.randn"><code>torch.randn()</code></a> <a class="reference internal" href="generated/torch.randn_like#torch.randn_like" title="torch.randn_like"><code>torch.randn_like()</code></a> <a class="reference internal" href="generated/torch.randint#torch.randint" title="torch.randint"><code>torch.randint()</code></a> <a class="reference internal" href="generated/torch.randint_like#torch.randint_like" title="torch.randint_like"><code>torch.randint_like()</code></a> <a class="reference internal" href="generated/torch.randperm#torch.randperm" title="torch.randperm"><code>torch.randperm()</code></a> You may also use <a class="reference internal" href="generated/torch.empty#torch.empty" title="torch.empty"><code>torch.empty()</code></a> with the <a class="reference internal" href="#inplace-random-sampling"><span class="std std-ref">In-place random sampling</span></a> methods to create <a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> s with values sampled from a broader range of distributions.</p> </div> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.tensor#torch.tensor" title="torch.tensor"><code>tensor</code></a>
</td> <td><p>Constructs a tensor with <code>data</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.sparse_coo_tensor#torch.sparse_coo_tensor" title="torch.sparse_coo_tensor"><code>sparse_coo_tensor</code></a>
</td> <td><p>Constructs a <a class="reference internal" href="sparse#sparse-coo-docs"><span class="std std-ref">sparse tensor in COO(rdinate) format</span></a> with specified values at the given <code>indices</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.as_tensor#torch.as_tensor" title="torch.as_tensor"><code>as_tensor</code></a>
</td> <td><p>Convert the data into a <code>torch.Tensor</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.as_strided#torch.as_strided" title="torch.as_strided"><code>as_strided</code></a>
</td> <td><p>Create a view of an existing <code>torch.Tensor</code> <code>input</code> with specified <code>size</code>, <code>stride</code> and <code>storage_offset</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.from_numpy#torch.from_numpy" title="torch.from_numpy"><code>from_numpy</code></a>
</td> <td><p>Creates a <a class="reference internal" href="tensors#torch.Tensor" title="torch.Tensor"><code>Tensor</code></a> from a <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.20)"><code>numpy.ndarray</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.zeros#torch.zeros" title="torch.zeros"><code>zeros</code></a>
</td> <td><p>Returns a tensor filled with the scalar value <code>0</code>, with the shape defined by the variable argument <code>size</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.zeros_like#torch.zeros_like" title="torch.zeros_like"><code>zeros_like</code></a>
</td> <td><p>Returns a tensor filled with the scalar value <code>0</code>, with the same size as <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.ones#torch.ones" title="torch.ones"><code>ones</code></a>
</td> <td><p>Returns a tensor filled with the scalar value <code>1</code>, with the shape defined by the variable argument <code>size</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.ones_like#torch.ones_like" title="torch.ones_like"><code>ones_like</code></a>
</td> <td><p>Returns a tensor filled with the scalar value <code>1</code>, with the same size as <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.arange#torch.arange" title="torch.arange"><code>arange</code></a>
</td> <td><p>Returns a 1-D tensor of size <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">⌈</mo><mfrac><mrow><mtext>end</mtext><mo>−</mo><mtext>start</mtext></mrow><mtext>step</mtext></mfrac><mo fence="true">⌉</mo></mrow><annotation encoding="application/x-tex">\left\lceil \frac{\text{end} - \text{start}}{\text{step}} \right\rceil</annotation></semantics></math></span></span> </span> with values from the interval <code>[start, end)</code> taken with common difference <code>step</code> beginning from <code>start</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.range#torch.range" title="torch.range"><code>range</code></a>
</td> <td><p>Returns a 1-D tensor of size <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo fence="true">⌊</mo><mfrac><mrow><mtext>end</mtext><mo>−</mo><mtext>start</mtext></mrow><mtext>step</mtext></mfrac><mo fence="true">⌋</mo></mrow><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\left\lfloor \frac{\text{end} - \text{start}}{\text{step}} \right\rfloor + 1</annotation></semantics></math></span></span> </span> with values from <code>start</code> to <code>end</code> with step <code>step</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.linspace#torch.linspace" title="torch.linspace"><code>linspace</code></a>
</td> <td><p>Creates a one-dimensional tensor of size <code>steps</code> whose values are evenly spaced from <code>start</code> to <code>end</code>, inclusive.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.logspace#torch.logspace" title="torch.logspace"><code>logspace</code></a>
</td> <td><p>Creates a one-dimensional tensor of size <code>steps</code> whose values are evenly spaced from <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mtext>base</mtext><mtext>start</mtext></msup></mrow><annotation encoding="application/x-tex">{{\text{{base}}}}^{{\text{{start}}}}</annotation></semantics></math></span></span> </span> to <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mtext>base</mtext><mtext>end</mtext></msup></mrow><annotation encoding="application/x-tex">{{\text{{base}}}}^{{\text{{end}}}}</annotation></semantics></math></span></span> </span>, inclusive, on a logarithmic scale with base <code>base</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.eye#torch.eye" title="torch.eye"><code>eye</code></a>
</td> <td><p>Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.empty#torch.empty" title="torch.empty"><code>empty</code></a>
</td> <td><p>Returns a tensor filled with uninitialized data.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.empty_like#torch.empty_like" title="torch.empty_like"><code>empty_like</code></a>
</td> <td><p>Returns an uninitialized tensor with the same size as <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.empty_strided#torch.empty_strided" title="torch.empty_strided"><code>empty_strided</code></a>
</td> <td><p>Returns a tensor filled with uninitialized data.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.full#torch.full" title="torch.full"><code>full</code></a>
</td> <td><p>Creates a tensor of size <code>size</code> filled with <code>fill_value</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.full_like#torch.full_like" title="torch.full_like"><code>full_like</code></a>
</td> <td><p>Returns a tensor with the same size as <code>input</code> filled with <code>fill_value</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.quantize_per_tensor#torch.quantize_per_tensor" title="torch.quantize_per_tensor"><code>quantize_per_tensor</code></a>
</td> <td><p>Converts a float tensor to a quantized tensor with given scale and zero point.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.quantize_per_channel#torch.quantize_per_channel" title="torch.quantize_per_channel"><code>quantize_per_channel</code></a>
</td> <td><p>Converts a float tensor to a per-channel quantized tensor with given scales and zero points.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.dequantize#torch.dequantize" title="torch.dequantize"><code>dequantize</code></a>
</td> <td><p>Returns an fp32 Tensor by dequantizing a quantized Tensor</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.complex#torch.complex" title="torch.complex"><code>complex</code></a>
</td> <td><p>Constructs a complex tensor with its real part equal to <a class="reference internal" href="generated/torch.real#torch.real" title="torch.real"><code>real</code></a> and its imaginary part equal to <a class="reference internal" href="generated/torch.imag#torch.imag" title="torch.imag"><code>imag</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.polar#torch.polar" title="torch.polar"><code>polar</code></a>
</td> <td><p>Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute value <a class="reference internal" href="generated/torch.abs#torch.abs" title="torch.abs"><code>abs</code></a> and angle <a class="reference internal" href="generated/torch.angle#torch.angle" title="torch.angle"><code>angle</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.heaviside#torch.heaviside" title="torch.heaviside"><code>heaviside</code></a>
</td> <td><p>Computes the Heaviside step function for each element in <code>input</code>.</p></td> </tr>  </table>   <h3 id="indexing-slicing-joining-mutating-ops">Indexing, Slicing, Joining, Mutating Ops</h3> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.cat#torch.cat" title="torch.cat"><code>cat</code></a>
</td> <td><p>Concatenates the given sequence of <code>seq</code> tensors in the given dimension.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.chunk#torch.chunk" title="torch.chunk"><code>chunk</code></a>
</td> <td><p>Splits a tensor into a specific number of chunks.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.column_stack#torch.column_stack" title="torch.column_stack"><code>column_stack</code></a>
</td> <td><p>Creates a new tensor by horizontally stacking the tensors in <code>tensors</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.dstack#torch.dstack" title="torch.dstack"><code>dstack</code></a>
</td> <td><p>Stack tensors in sequence depthwise (along third axis).</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.gather#torch.gather" title="torch.gather"><code>gather</code></a>
</td> <td><p>Gathers values along an axis specified by <code>dim</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.hstack#torch.hstack" title="torch.hstack"><code>hstack</code></a>
</td> <td><p>Stack tensors in sequence horizontally (column wise).</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.index_select#torch.index_select" title="torch.index_select"><code>index_select</code></a>
</td> <td><p>Returns a new tensor which indexes the <code>input</code> tensor along dimension <code>dim</code> using the entries in <code>index</code> which is a <code>LongTensor</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.masked_select#torch.masked_select" title="torch.masked_select"><code>masked_select</code></a>
</td> <td><p>Returns a new 1-D tensor which indexes the <code>input</code> tensor according to the boolean mask <code>mask</code> which is a <code>BoolTensor</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.movedim#torch.movedim" title="torch.movedim"><code>movedim</code></a>
</td> <td><p>Moves the dimension(s) of <code>input</code> at the position(s) in <code>source</code> to the position(s) in <code>destination</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.moveaxis#torch.moveaxis" title="torch.moveaxis"><code>moveaxis</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.movedim#torch.movedim" title="torch.movedim"><code>torch.movedim()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.narrow#torch.narrow" title="torch.narrow"><code>narrow</code></a>
</td> <td><p>Returns a new tensor that is a narrowed version of <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.nonzero#torch.nonzero" title="torch.nonzero"><code>nonzero</code></a>
</td> <td></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.reshape#torch.reshape" title="torch.reshape"><code>reshape</code></a>
</td> <td><p>Returns a tensor with the same data and number of elements as <code>input</code>, but with the specified shape.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.row_stack#torch.row_stack" title="torch.row_stack"><code>row_stack</code></a>
</td> <td><p>Alias of <a class="reference internal" href="generated/torch.vstack#torch.vstack" title="torch.vstack"><code>torch.vstack()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.scatter#torch.scatter" title="torch.scatter"><code>scatter</code></a>
</td> <td><p>Out-of-place version of <a class="reference internal" href="tensors#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>torch.Tensor.scatter_()</code></a></p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.scatter_add#torch.scatter_add" title="torch.scatter_add"><code>scatter_add</code></a>
</td> <td><p>Out-of-place version of <a class="reference internal" href="tensors#torch.Tensor.scatter_add_" title="torch.Tensor.scatter_add_"><code>torch.Tensor.scatter_add_()</code></a></p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.split#torch.split" title="torch.split"><code>split</code></a>
</td> <td><p>Splits the tensor into chunks.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.squeeze#torch.squeeze" title="torch.squeeze"><code>squeeze</code></a>
</td> <td><p>Returns a tensor with all the dimensions of <code>input</code> of size <code>1</code> removed.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.stack#torch.stack" title="torch.stack"><code>stack</code></a>
</td> <td><p>Concatenates a sequence of tensors along a new dimension.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.swapaxes#torch.swapaxes" title="torch.swapaxes"><code>swapaxes</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.transpose#torch.transpose" title="torch.transpose"><code>torch.transpose()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.swapdims#torch.swapdims" title="torch.swapdims"><code>swapdims</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.transpose#torch.transpose" title="torch.transpose"><code>torch.transpose()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.t#torch.t" title="torch.t"><code>t</code></a>
</td> <td><p>Expects <code>input</code> to be &lt;= 2-D tensor and transposes dimensions 0 and 1.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.take#torch.take" title="torch.take"><code>take</code></a>
</td> <td><p>Returns a new tensor with the elements of <code>input</code> at the given indices.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.tensor_split#torch.tensor_split" title="torch.tensor_split"><code>tensor_split</code></a>
</td> <td><p>Splits a tensor into multiple sub-tensors, all of which are views of <code>input</code>, along dimension <code>dim</code> according to the indices or number of sections specified by <code>indices_or_sections</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.tile#torch.tile" title="torch.tile"><code>tile</code></a>
</td> <td><p>Constructs a tensor by repeating the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.transpose#torch.transpose" title="torch.transpose"><code>transpose</code></a>
</td> <td><p>Returns a tensor that is a transposed version of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.unbind#torch.unbind" title="torch.unbind"><code>unbind</code></a>
</td> <td><p>Removes a tensor dimension.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.unsqueeze#torch.unsqueeze" title="torch.unsqueeze"><code>unsqueeze</code></a>
</td> <td><p>Returns a new tensor with a dimension of size one inserted at the specified position.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.vstack#torch.vstack" title="torch.vstack"><code>vstack</code></a>
</td> <td><p>Stack tensors in sequence vertically (row wise).</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.where#torch.where" title="torch.where"><code>where</code></a>
</td> <td><p>Return a tensor of elements selected from either <code>x</code> or <code>y</code>, depending on <code>condition</code>.</p></td> </tr>  </table>    <h2 id="id1">Generators</h2> <table class="longtable docutils colwidths-auto align-default" id="generators">  <tr>
<td>


<a class="reference internal" href="generated/torch.generator#torch.Generator" title="torch.Generator"><code>Generator</code></a>
</td> <td><p>Creates and returns a generator object that manages the state of the algorithm which produces pseudo random numbers.</p></td> </tr>  </table>   <h2 id="id2">Random sampling</h2> <table class="longtable docutils colwidths-auto align-default" id="random-sampling">  <tr>
<td>


<a class="reference internal" href="generated/torch.seed#torch.seed" title="torch.seed"><code>seed</code></a>
</td> <td><p>Sets the seed for generating random numbers to a non-deterministic random number.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.manual_seed#torch.manual_seed" title="torch.manual_seed"><code>manual_seed</code></a>
</td> <td><p>Sets the seed for generating random numbers.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.initial_seed#torch.initial_seed" title="torch.initial_seed"><code>initial_seed</code></a>
</td> <td><p>Returns the initial seed for generating random numbers as a Python <code>long</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.get_rng_state#torch.get_rng_state" title="torch.get_rng_state"><code>get_rng_state</code></a>
</td> <td><p>Returns the random number generator state as a <code>torch.ByteTensor</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.set_rng_state#torch.set_rng_state" title="torch.set_rng_state"><code>set_rng_state</code></a>
</td> <td><p>Sets the random number generator state.</p></td> </tr>  </table> <dl class="attribute"> <dt id="torch.torch.default_generator">
<code>torch.default_generator Returns the default CPU torch.Generator</code> </dt> 
</dl> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.bernoulli#torch.bernoulli" title="torch.bernoulli"><code>bernoulli</code></a>
</td> <td><p>Draws binary random numbers (0 or 1) from a Bernoulli distribution.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.multinomial#torch.multinomial" title="torch.multinomial"><code>multinomial</code></a>
</td> <td><p>Returns a tensor where each row contains <code>num_samples</code> indices sampled from the multinomial probability distribution located in the corresponding row of tensor <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.normal#torch.normal" title="torch.normal"><code>normal</code></a>
</td> <td><p>Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.poisson#torch.poisson" title="torch.poisson"><code>poisson</code></a>
</td> <td><p>Returns a tensor of the same size as <code>input</code> with each element sampled from a Poisson distribution with rate parameter given by the corresponding element in <code>input</code> i.e.,</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.rand#torch.rand" title="torch.rand"><code>rand</code></a>
</td> <td><p>Returns a tensor filled with random numbers from a uniform distribution on the interval <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">[0, 1)</annotation></semantics></math></span></span> </span></p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.rand_like#torch.rand_like" title="torch.rand_like"><code>rand_like</code></a>
</td> <td><p>Returns a tensor with the same size as <code>input</code> that is filled with random numbers from a uniform distribution on the interval <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">[0, 1)</annotation></semantics></math></span></span> </span>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.randint#torch.randint" title="torch.randint"><code>randint</code></a>
</td> <td><p>Returns a tensor filled with random integers generated uniformly between <code>low</code> (inclusive) and <code>high</code> (exclusive).</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.randint_like#torch.randint_like" title="torch.randint_like"><code>randint_like</code></a>
</td> <td><p>Returns a tensor with the same shape as Tensor <code>input</code> filled with random integers generated uniformly between <code>low</code> (inclusive) and <code>high</code> (exclusive).</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.randn#torch.randn" title="torch.randn"><code>randn</code></a>
</td> <td><p>Returns a tensor filled with random numbers from a normal distribution with mean <code>0</code> and variance <code>1</code> (also called the standard normal distribution).</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.randn_like#torch.randn_like" title="torch.randn_like"><code>randn_like</code></a>
</td> <td><p>Returns a tensor with the same size as <code>input</code> that is filled with random numbers from a normal distribution with mean 0 and variance 1.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.randperm#torch.randperm" title="torch.randperm"><code>randperm</code></a>
</td> <td><p>Returns a random permutation of integers from <code>0</code> to <code>n - 1</code>.</p></td> </tr>  </table>  <h3 id="inplace-random-sampling">In-place random sampling</h3> <p id="in-place-random-sampling">There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation:</p> <ul class="simple"> <li>
<a class="reference internal" href="tensors#torch.Tensor.bernoulli_" title="torch.Tensor.bernoulli_"><code>torch.Tensor.bernoulli_()</code></a> - in-place version of <a class="reference internal" href="generated/torch.bernoulli#torch.bernoulli" title="torch.bernoulli"><code>torch.bernoulli()</code></a>
</li> <li>
<a class="reference internal" href="tensors#torch.Tensor.cauchy_" title="torch.Tensor.cauchy_"><code>torch.Tensor.cauchy_()</code></a> - numbers drawn from the Cauchy distribution</li> <li>
<a class="reference internal" href="tensors#torch.Tensor.exponential_" title="torch.Tensor.exponential_"><code>torch.Tensor.exponential_()</code></a> - numbers drawn from the exponential distribution</li> <li>
<a class="reference internal" href="tensors#torch.Tensor.geometric_" title="torch.Tensor.geometric_"><code>torch.Tensor.geometric_()</code></a> - elements drawn from the geometric distribution</li> <li>
<a class="reference internal" href="tensors#torch.Tensor.log_normal_" title="torch.Tensor.log_normal_"><code>torch.Tensor.log_normal_()</code></a> - samples from the log-normal distribution</li> <li>
<a class="reference internal" href="tensors#torch.Tensor.normal_" title="torch.Tensor.normal_"><code>torch.Tensor.normal_()</code></a> - in-place version of <a class="reference internal" href="generated/torch.normal#torch.normal" title="torch.normal"><code>torch.normal()</code></a>
</li> <li>
<a class="reference internal" href="tensors#torch.Tensor.random_" title="torch.Tensor.random_"><code>torch.Tensor.random_()</code></a> - numbers sampled from the discrete uniform distribution</li> <li>
<a class="reference internal" href="tensors#torch.Tensor.uniform_" title="torch.Tensor.uniform_"><code>torch.Tensor.uniform_()</code></a> - numbers sampled from the continuous uniform distribution</li> </ul>   <h3 id="quasi-random-sampling">Quasi-random sampling</h3> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td><p><a class="reference internal" href="generated/torch.quasirandom.sobolengine#torch.quasirandom.SobolEngine" title="torch.quasirandom.SobolEngine"><code>quasirandom.SobolEngine</code></a></p></td> <td><p>The <a class="reference internal" href="generated/torch.quasirandom.sobolengine#torch.quasirandom.SobolEngine" title="torch.quasirandom.SobolEngine"><code>torch.quasirandom.SobolEngine</code></a> is an engine for generating (scrambled) Sobol sequences.</p></td> </tr>  </table>    <h2 id="serialization">Serialization</h2> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.save#torch.save" title="torch.save"><code>save</code></a>
</td> <td><p>Saves an object to a disk file.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.load#torch.load" title="torch.load"><code>load</code></a>
</td> <td><p>Loads an object saved with <a class="reference internal" href="generated/torch.save#torch.save" title="torch.save"><code>torch.save()</code></a> from a file.</p></td> </tr>  </table>   <h2 id="parallelism">Parallelism</h2> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.get_num_threads#torch.get_num_threads" title="torch.get_num_threads"><code>get_num_threads</code></a>
</td> <td><p>Returns the number of threads used for parallelizing CPU operations</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.set_num_threads#torch.set_num_threads" title="torch.set_num_threads"><code>set_num_threads</code></a>
</td> <td><p>Sets the number of threads used for intraop parallelism on CPU.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.get_num_interop_threads#torch.get_num_interop_threads" title="torch.get_num_interop_threads"><code>get_num_interop_threads</code></a>
</td> <td><p>Returns the number of threads used for inter-op parallelism on CPU (e.g.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.set_num_interop_threads#torch.set_num_interop_threads" title="torch.set_num_interop_threads"><code>set_num_interop_threads</code></a>
</td> <td><p>Sets the number of threads used for interop parallelism (e.g.</p></td> </tr>  </table>   <h2 id="locally-disabling-gradient-computation">Locally disabling gradient computation</h2> <p>The context managers <a class="reference internal" href="generated/torch.no_grad#torch.no_grad" title="torch.no_grad"><code>torch.no_grad()</code></a>, <a class="reference internal" href="generated/torch.enable_grad#torch.enable_grad" title="torch.enable_grad"><code>torch.enable_grad()</code></a>, and <a class="reference internal" href="generated/torch.set_grad_enabled#torch.set_grad_enabled" title="torch.set_grad_enabled"><code>torch.set_grad_enabled()</code></a> are helpful for locally disabling and enabling gradient computation. See <a class="reference internal" href="autograd#locally-disable-grad"><span class="std std-ref">Locally disabling gradient computation</span></a> for more details on their usage. These context managers are thread local, so they won’t work if you send work to another thread using the <code>threading</code> module, etc.</p> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; x = torch.zeros(1, requires_grad=True)
&gt;&gt;&gt; with torch.no_grad():
...     y = x * 2
&gt;&gt;&gt; y.requires_grad
False

&gt;&gt;&gt; is_train = False
&gt;&gt;&gt; with torch.set_grad_enabled(is_train):
...     y = x * 2
&gt;&gt;&gt; y.requires_grad
False

&gt;&gt;&gt; torch.set_grad_enabled(True)  # this can also be used as a function
&gt;&gt;&gt; y = x * 2
&gt;&gt;&gt; y.requires_grad
True

&gt;&gt;&gt; torch.set_grad_enabled(False)
&gt;&gt;&gt; y = x * 2
&gt;&gt;&gt; y.requires_grad
False
</pre> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.no_grad#torch.no_grad" title="torch.no_grad"><code>no_grad</code></a>
</td> <td><p>Context-manager that disabled gradient calculation.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.enable_grad#torch.enable_grad" title="torch.enable_grad"><code>enable_grad</code></a>
</td> <td><p>Context-manager that enables gradient calculation.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.set_grad_enabled#torch.set_grad_enabled" title="torch.set_grad_enabled"><code>set_grad_enabled</code></a>
</td> <td><p>Context-manager that sets gradient calculation to on or off.</p></td> </tr>  </table>   <h2 id="math-operations">Math operations</h2>  <h3 id="pointwise-ops">Pointwise Ops</h3> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.abs#torch.abs" title="torch.abs"><code>abs</code></a>
</td> <td><p>Computes the absolute value of each element in <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.absolute#torch.absolute" title="torch.absolute"><code>absolute</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.abs#torch.abs" title="torch.abs"><code>torch.abs()</code></a></p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.acos#torch.acos" title="torch.acos"><code>acos</code></a>
</td> <td><p>Computes the inverse cosine of each element in <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.arccos#torch.arccos" title="torch.arccos"><code>arccos</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.acos#torch.acos" title="torch.acos"><code>torch.acos()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.acosh#torch.acosh" title="torch.acosh"><code>acosh</code></a>
</td> <td><p>Returns a new tensor with the inverse hyperbolic cosine of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.arccosh#torch.arccosh" title="torch.arccosh"><code>arccosh</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.acosh#torch.acosh" title="torch.acosh"><code>torch.acosh()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.add#torch.add" title="torch.add"><code>add</code></a>
</td> <td><p>Adds the scalar <code>other</code> to each element of the input <code>input</code> and returns a new resulting tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.addcdiv#torch.addcdiv" title="torch.addcdiv"><code>addcdiv</code></a>
</td> <td><p>Performs the element-wise division of <code>tensor1</code> by <code>tensor2</code>, multiply the result by the scalar <code>value</code> and add it to <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.addcmul#torch.addcmul" title="torch.addcmul"><code>addcmul</code></a>
</td> <td><p>Performs the element-wise multiplication of <code>tensor1</code> by <code>tensor2</code>, multiply the result by the scalar <code>value</code> and add it to <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.angle#torch.angle" title="torch.angle"><code>angle</code></a>
</td> <td><p>Computes the element-wise angle (in radians) of the given <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.asin#torch.asin" title="torch.asin"><code>asin</code></a>
</td> <td><p>Returns a new tensor with the arcsine of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.arcsin#torch.arcsin" title="torch.arcsin"><code>arcsin</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.asin#torch.asin" title="torch.asin"><code>torch.asin()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.asinh#torch.asinh" title="torch.asinh"><code>asinh</code></a>
</td> <td><p>Returns a new tensor with the inverse hyperbolic sine of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.arcsinh#torch.arcsinh" title="torch.arcsinh"><code>arcsinh</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.asinh#torch.asinh" title="torch.asinh"><code>torch.asinh()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.atan#torch.atan" title="torch.atan"><code>atan</code></a>
</td> <td><p>Returns a new tensor with the arctangent of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.arctan#torch.arctan" title="torch.arctan"><code>arctan</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.atan#torch.atan" title="torch.atan"><code>torch.atan()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.atanh#torch.atanh" title="torch.atanh"><code>atanh</code></a>
</td> <td><p>Returns a new tensor with the inverse hyperbolic tangent of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.arctanh#torch.arctanh" title="torch.arctanh"><code>arctanh</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.atanh#torch.atanh" title="torch.atanh"><code>torch.atanh()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.atan2#torch.atan2" title="torch.atan2"><code>atan2</code></a>
</td> <td><p>Element-wise arctangent of <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>input</mtext><mi>i</mi></msub><mi mathvariant="normal">/</mi><msub><mtext>other</mtext><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{input}_{i} / \text{other}_{i}</annotation></semantics></math></span></span> </span> with consideration of the quadrant.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.bitwise_not#torch.bitwise_not" title="torch.bitwise_not"><code>bitwise_not</code></a>
</td> <td><p>Computes the bitwise NOT of the given input tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.bitwise_and#torch.bitwise_and" title="torch.bitwise_and"><code>bitwise_and</code></a>
</td> <td><p>Computes the bitwise AND of <code>input</code> and <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.bitwise_or#torch.bitwise_or" title="torch.bitwise_or"><code>bitwise_or</code></a>
</td> <td><p>Computes the bitwise OR of <code>input</code> and <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.bitwise_xor#torch.bitwise_xor" title="torch.bitwise_xor"><code>bitwise_xor</code></a>
</td> <td><p>Computes the bitwise XOR of <code>input</code> and <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.ceil#torch.ceil" title="torch.ceil"><code>ceil</code></a>
</td> <td><p>Returns a new tensor with the ceil of the elements of <code>input</code>, the smallest integer greater than or equal to each element.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.clamp#torch.clamp" title="torch.clamp"><code>clamp</code></a>
</td> <td><p>Clamp all elements in <code>input</code> into the range <code>[</code> <a class="reference internal" href="generated/torch.min#torch.min" title="torch.min"><code>min</code></a>, <a class="reference internal" href="generated/torch.max#torch.max" title="torch.max"><code>max</code></a> <code>]</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.clip#torch.clip" title="torch.clip"><code>clip</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.clamp#torch.clamp" title="torch.clamp"><code>torch.clamp()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.conj#torch.conj" title="torch.conj"><code>conj</code></a>
</td> <td><p>Computes the element-wise conjugate of the given <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.copysign#torch.copysign" title="torch.copysign"><code>copysign</code></a>
</td> <td><p>Create a new floating-point tensor with the magnitude of <code>input</code> and the sign of <code>other</code>, elementwise.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.cos#torch.cos" title="torch.cos"><code>cos</code></a>
</td> <td><p>Returns a new tensor with the cosine of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.cosh#torch.cosh" title="torch.cosh"><code>cosh</code></a>
</td> <td><p>Returns a new tensor with the hyperbolic cosine of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.deg2rad#torch.deg2rad" title="torch.deg2rad"><code>deg2rad</code></a>
</td> <td><p>Returns a new tensor with each of the elements of <code>input</code> converted from angles in degrees to radians.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.div#torch.div" title="torch.div"><code>div</code></a>
</td> <td><p>Divides each element of the input <code>input</code> by the corresponding element of <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.divide#torch.divide" title="torch.divide"><code>divide</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.div#torch.div" title="torch.div"><code>torch.div()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.digamma#torch.digamma" title="torch.digamma"><code>digamma</code></a>
</td> <td><p>Computes the logarithmic derivative of the gamma function on <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.erf#torch.erf" title="torch.erf"><code>erf</code></a>
</td> <td><p>Computes the error function of each element.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.erfc#torch.erfc" title="torch.erfc"><code>erfc</code></a>
</td> <td><p>Computes the complementary error function of each element of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.erfinv#torch.erfinv" title="torch.erfinv"><code>erfinv</code></a>
</td> <td><p>Computes the inverse error function of each element of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.exp#torch.exp" title="torch.exp"><code>exp</code></a>
</td> <td><p>Returns a new tensor with the exponential of the elements of the input tensor <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.exp2#torch.exp2" title="torch.exp2"><code>exp2</code></a>
</td> <td><p>Computes the base two exponential function of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.expm1#torch.expm1" title="torch.expm1"><code>expm1</code></a>
</td> <td><p>Returns a new tensor with the exponential of the elements minus 1 of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.fake_quantize_per_channel_affine#torch.fake_quantize_per_channel_affine" title="torch.fake_quantize_per_channel_affine"><code>fake_quantize_per_channel_affine</code></a>
</td> <td><p>Returns a new tensor with the data in <code>input</code> fake quantized per channel using <code>scale</code>, <code>zero_point</code>, <code>quant_min</code> and <code>quant_max</code>, across the channel specified by <code>axis</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.fake_quantize_per_tensor_affine#torch.fake_quantize_per_tensor_affine" title="torch.fake_quantize_per_tensor_affine"><code>fake_quantize_per_tensor_affine</code></a>
</td> <td><p>Returns a new tensor with the data in <code>input</code> fake quantized using <code>scale</code>, <code>zero_point</code>, <code>quant_min</code> and <code>quant_max</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.fix#torch.fix" title="torch.fix"><code>fix</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.trunc#torch.trunc" title="torch.trunc"><code>torch.trunc()</code></a></p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.float_power#torch.float_power" title="torch.float_power"><code>float_power</code></a>
</td> <td><p>Raises <code>input</code> to the power of <code>exponent</code>, elementwise, in double precision.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.floor#torch.floor" title="torch.floor"><code>floor</code></a>
</td> <td><p>Returns a new tensor with the floor of the elements of <code>input</code>, the largest integer less than or equal to each element.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.floor_divide#torch.floor_divide" title="torch.floor_divide"><code>floor_divide</code></a>
</td> <td></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.fmod#torch.fmod" title="torch.fmod"><code>fmod</code></a>
</td> <td><p>Computes the element-wise remainder of division.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.frac#torch.frac" title="torch.frac"><code>frac</code></a>
</td> <td><p>Computes the fractional portion of each element in <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.imag#torch.imag" title="torch.imag"><code>imag</code></a>
</td> <td><p>Returns a new tensor containing imaginary values of the <code>self</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.ldexp#torch.ldexp" title="torch.ldexp"><code>ldexp</code></a>
</td> <td><p>Multiplies <code>input</code> by 2**:attr:<code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.lerp#torch.lerp" title="torch.lerp"><code>lerp</code></a>
</td> <td><p>Does a linear interpolation of two tensors <code>start</code> (given by <code>input</code>) and <code>end</code> based on a scalar or tensor <code>weight</code> and returns the resulting <code>out</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.lgamma#torch.lgamma" title="torch.lgamma"><code>lgamma</code></a>
</td> <td><p>Computes the logarithm of the gamma function on <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.log#torch.log" title="torch.log"><code>log</code></a>
</td> <td><p>Returns a new tensor with the natural logarithm of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.log10#torch.log10" title="torch.log10"><code>log10</code></a>
</td> <td><p>Returns a new tensor with the logarithm to the base 10 of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.log1p#torch.log1p" title="torch.log1p"><code>log1p</code></a>
</td> <td><p>Returns a new tensor with the natural logarithm of (1 + <code>input</code>).</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.log2#torch.log2" title="torch.log2"><code>log2</code></a>
</td> <td><p>Returns a new tensor with the logarithm to the base 2 of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.logaddexp#torch.logaddexp" title="torch.logaddexp"><code>logaddexp</code></a>
</td> <td><p>Logarithm of the sum of exponentiations of the inputs.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.logaddexp2#torch.logaddexp2" title="torch.logaddexp2"><code>logaddexp2</code></a>
</td> <td><p>Logarithm of the sum of exponentiations of the inputs in base-2.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.logical_and#torch.logical_and" title="torch.logical_and"><code>logical_and</code></a>
</td> <td><p>Computes the element-wise logical AND of the given input tensors.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.logical_not#torch.logical_not" title="torch.logical_not"><code>logical_not</code></a>
</td> <td><p>Computes the element-wise logical NOT of the given input tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.logical_or#torch.logical_or" title="torch.logical_or"><code>logical_or</code></a>
</td> <td><p>Computes the element-wise logical OR of the given input tensors.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.logical_xor#torch.logical_xor" title="torch.logical_xor"><code>logical_xor</code></a>
</td> <td><p>Computes the element-wise logical XOR of the given input tensors.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.logit#torch.logit" title="torch.logit"><code>logit</code></a>
</td> <td><p>Returns a new tensor with the logit of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.hypot#torch.hypot" title="torch.hypot"><code>hypot</code></a>
</td> <td><p>Given the legs of a right triangle, return its hypotenuse.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.i0#torch.i0" title="torch.i0"><code>i0</code></a>
</td> <td><p>Computes the zeroth order modified Bessel function of the first kind for each element of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.igamma#torch.igamma" title="torch.igamma"><code>igamma</code></a>
</td> <td><p>Computes the regularized lower incomplete gamma function:</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.igammac#torch.igammac" title="torch.igammac"><code>igammac</code></a>
</td> <td><p>Computes the regularized upper incomplete gamma function:</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.mul#torch.mul" title="torch.mul"><code>mul</code></a>
</td> <td><p>Multiplies each element of the input <code>input</code> with the scalar <code>other</code> and returns a new resulting tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.multiply#torch.multiply" title="torch.multiply"><code>multiply</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.mul#torch.mul" title="torch.mul"><code>torch.mul()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.mvlgamma#torch.mvlgamma" title="torch.mvlgamma"><code>mvlgamma</code></a>
</td> <td><p>Computes the <a class="reference external" href="https://en.wikipedia.org/wiki/Multivariate_gamma_function">multivariate log-gamma function</a>) with dimension <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span></span> </span> element-wise, given by</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.nan_to_num#torch.nan_to_num" title="torch.nan_to_num"><code>nan_to_num</code></a>
</td> <td><p>Replaces <code>NaN</code>, positive infinity, and negative infinity values in <code>input</code> with the values specified by <code>nan</code>, <code>posinf</code>, and <code>neginf</code>, respectively.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.neg#torch.neg" title="torch.neg"><code>neg</code></a>
</td> <td><p>Returns a new tensor with the negative of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.negative#torch.negative" title="torch.negative"><code>negative</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.neg#torch.neg" title="torch.neg"><code>torch.neg()</code></a></p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.nextafter#torch.nextafter" title="torch.nextafter"><code>nextafter</code></a>
</td> <td><p>Return the next floating-point value after <code>input</code> towards <code>other</code>, elementwise.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.polygamma#torch.polygamma" title="torch.polygamma"><code>polygamma</code></a>
</td> <td><p>Computes the <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>n</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding="application/x-tex">n^{th}</annotation></semantics></math></span></span> </span> derivative of the digamma function on <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.pow#torch.pow" title="torch.pow"><code>pow</code></a>
</td> <td><p>Takes the power of each element in <code>input</code> with <code>exponent</code> and returns a tensor with the result.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.rad2deg#torch.rad2deg" title="torch.rad2deg"><code>rad2deg</code></a>
</td> <td><p>Returns a new tensor with each of the elements of <code>input</code> converted from angles in radians to degrees.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.real#torch.real" title="torch.real"><code>real</code></a>
</td> <td><p>Returns a new tensor containing real values of the <code>self</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.reciprocal#torch.reciprocal" title="torch.reciprocal"><code>reciprocal</code></a>
</td> <td><p>Returns a new tensor with the reciprocal of the elements of <code>input</code></p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.remainder#torch.remainder" title="torch.remainder"><code>remainder</code></a>
</td> <td><p>Computes the element-wise remainder of division.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.round#torch.round" title="torch.round"><code>round</code></a>
</td> <td><p>Returns a new tensor with each of the elements of <code>input</code> rounded to the closest integer.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.rsqrt#torch.rsqrt" title="torch.rsqrt"><code>rsqrt</code></a>
</td> <td><p>Returns a new tensor with the reciprocal of the square-root of each of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.sigmoid#torch.sigmoid" title="torch.sigmoid"><code>sigmoid</code></a>
</td> <td><p>Returns a new tensor with the sigmoid of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.sign#torch.sign" title="torch.sign"><code>sign</code></a>
</td> <td><p>Returns a new tensor with the signs of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.sgn#torch.sgn" title="torch.sgn"><code>sgn</code></a>
</td> <td><p>For complex tensors, this function returns a new tensor whose elemants have the same angle as that of the elements of <code>input</code> and absolute value 1.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.signbit#torch.signbit" title="torch.signbit"><code>signbit</code></a>
</td> <td><p>Tests if each element of <code>input</code> has its sign bit set (is less than zero) or not.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.sin#torch.sin" title="torch.sin"><code>sin</code></a>
</td> <td><p>Returns a new tensor with the sine of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.sinc#torch.sinc" title="torch.sinc"><code>sinc</code></a>
</td> <td><p>Computes the normalized sinc of <code>input.</code></p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.sinh#torch.sinh" title="torch.sinh"><code>sinh</code></a>
</td> <td><p>Returns a new tensor with the hyperbolic sine of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.sqrt#torch.sqrt" title="torch.sqrt"><code>sqrt</code></a>
</td> <td><p>Returns a new tensor with the square-root of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.square#torch.square" title="torch.square"><code>square</code></a>
</td> <td><p>Returns a new tensor with the square of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.sub#torch.sub" title="torch.sub"><code>sub</code></a>
</td> <td><p>Subtracts <code>other</code>, scaled by <code>alpha</code>, from <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.subtract#torch.subtract" title="torch.subtract"><code>subtract</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.sub#torch.sub" title="torch.sub"><code>torch.sub()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.tan#torch.tan" title="torch.tan"><code>tan</code></a>
</td> <td><p>Returns a new tensor with the tangent of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.tanh#torch.tanh" title="torch.tanh"><code>tanh</code></a>
</td> <td><p>Returns a new tensor with the hyperbolic tangent of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.true_divide#torch.true_divide" title="torch.true_divide"><code>true_divide</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.div#torch.div" title="torch.div"><code>torch.div()</code></a> with <code>rounding_mode=None</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.trunc#torch.trunc" title="torch.trunc"><code>trunc</code></a>
</td> <td><p>Returns a new tensor with the truncated integer values of the elements of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.xlogy#torch.xlogy" title="torch.xlogy"><code>xlogy</code></a>
</td> <td><p>Computes <code>input * log(other)</code> with the following cases.</p></td> </tr>  </table>   <h3 id="reduction-ops">Reduction Ops</h3> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.argmax#torch.argmax" title="torch.argmax"><code>argmax</code></a>
</td> <td><p>Returns the indices of the maximum value of all elements in the <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.argmin#torch.argmin" title="torch.argmin"><code>argmin</code></a>
</td> <td><p>Returns the indices of the minimum value(s) of the flattened tensor or along a dimension</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.amax#torch.amax" title="torch.amax"><code>amax</code></a>
</td> <td><p>Returns the maximum value of each slice of the <code>input</code> tensor in the given dimension(s) <code>dim</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.amin#torch.amin" title="torch.amin"><code>amin</code></a>
</td> <td><p>Returns the minimum value of each slice of the <code>input</code> tensor in the given dimension(s) <code>dim</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.all#torch.all" title="torch.all"><code>all</code></a>
</td> <td><p>Tests if all elements in <code>input</code> evaluate to <code>True</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.any#torch.any" title="torch.any"><code>any</code></a>
</td> <td>

<dl class="field-list simple"> <dt class="field-odd">param input</dt> <dd class="field-odd">
<p>the input tensor.</p> </dd> </dl> </td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.max#torch.max" title="torch.max"><code>max</code></a>
</td> <td><p>Returns the maximum value of all elements in the <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.min#torch.min" title="torch.min"><code>min</code></a>
</td> <td><p>Returns the minimum value of all elements in the <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.dist#torch.dist" title="torch.dist"><code>dist</code></a>
</td> <td><p>Returns the p-norm of (<code>input</code> - <code>other</code>)</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.logsumexp#torch.logsumexp" title="torch.logsumexp"><code>logsumexp</code></a>
</td> <td><p>Returns the log of summed exponentials of each row of the <code>input</code> tensor in the given dimension <code>dim</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.mean#torch.mean" title="torch.mean"><code>mean</code></a>
</td> <td><p>Returns the mean value of all elements in the <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.median#torch.median" title="torch.median"><code>median</code></a>
</td> <td><p>Returns the median of the values in <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.nanmedian#torch.nanmedian" title="torch.nanmedian"><code>nanmedian</code></a>
</td> <td><p>Returns the median of the values in <code>input</code>, ignoring <code>NaN</code> values.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.mode#torch.mode" title="torch.mode"><code>mode</code></a>
</td> <td><p>Returns a namedtuple <code>(values, indices)</code> where <code>values</code> is the mode value of each row of the <code>input</code> tensor in the given dimension <code>dim</code>, i.e.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.norm#torch.norm" title="torch.norm"><code>norm</code></a>
</td> <td><p>Returns the matrix norm or vector norm of a given tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.nansum#torch.nansum" title="torch.nansum"><code>nansum</code></a>
</td> <td><p>Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.prod#torch.prod" title="torch.prod"><code>prod</code></a>
</td> <td><p>Returns the product of all elements in the <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.quantile#torch.quantile" title="torch.quantile"><code>quantile</code></a>
</td> <td><p>Returns the q-th quantiles of all elements in the <code>input</code> tensor, doing a linear interpolation when the q-th quantile lies between two data points.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.nanquantile#torch.nanquantile" title="torch.nanquantile"><code>nanquantile</code></a>
</td> <td><p>This is a variant of <a class="reference internal" href="generated/torch.quantile#torch.quantile" title="torch.quantile"><code>torch.quantile()</code></a> that “ignores” <code>NaN</code> values, computing the quantiles <code>q</code> as if <code>NaN</code> values in <code>input</code> did not exist.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.std#torch.std" title="torch.std"><code>std</code></a>
</td> <td><p>Returns the standard-deviation of all elements in the <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.std_mean#torch.std_mean" title="torch.std_mean"><code>std_mean</code></a>
</td> <td><p>Returns the standard-deviation and mean of all elements in the <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.sum#torch.sum" title="torch.sum"><code>sum</code></a>
</td> <td><p>Returns the sum of all elements in the <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.unique#torch.unique" title="torch.unique"><code>unique</code></a>
</td> <td><p>Returns the unique elements of the input tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.unique_consecutive#torch.unique_consecutive" title="torch.unique_consecutive"><code>unique_consecutive</code></a>
</td> <td><p>Eliminates all but the first element from every consecutive group of equivalent elements.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.var#torch.var" title="torch.var"><code>var</code></a>
</td> <td><p>Returns the variance of all elements in the <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.var_mean#torch.var_mean" title="torch.var_mean"><code>var_mean</code></a>
</td> <td><p>Returns the variance and mean of all elements in the <code>input</code> tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.count_nonzero#torch.count_nonzero" title="torch.count_nonzero"><code>count_nonzero</code></a>
</td> <td><p>Counts the number of non-zero values in the tensor <code>input</code> along the given <code>dim</code>.</p></td> </tr>  </table>   <h3 id="comparison-ops">Comparison Ops</h3> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.allclose#torch.allclose" title="torch.allclose"><code>allclose</code></a>
</td> <td><p>This function checks if all <code>input</code> and <code>other</code> satisfy the condition:</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.argsort#torch.argsort" title="torch.argsort"><code>argsort</code></a>
</td> <td><p>Returns the indices that sort a tensor along a given dimension in ascending order by value.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.eq#torch.eq" title="torch.eq"><code>eq</code></a>
</td> <td><p>Computes element-wise equality</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.equal#torch.equal" title="torch.equal"><code>equal</code></a>
</td> <td><p><code>True</code> if two tensors have the same size and elements, <code>False</code> otherwise.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.ge#torch.ge" title="torch.ge"><code>ge</code></a>
</td> <td><p>Computes <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo>≥</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} \geq \text{other}</annotation></semantics></math></span></span> </span> element-wise.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.greater_equal#torch.greater_equal" title="torch.greater_equal"><code>greater_equal</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.ge#torch.ge" title="torch.ge"><code>torch.ge()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.gt#torch.gt" title="torch.gt"><code>gt</code></a>
</td> <td><p>Computes <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo>&gt;</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} &gt; \text{other}</annotation></semantics></math></span></span> </span> element-wise.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.greater#torch.greater" title="torch.greater"><code>greater</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.gt#torch.gt" title="torch.gt"><code>torch.gt()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.isclose#torch.isclose" title="torch.isclose"><code>isclose</code></a>
</td> <td><p>Returns a new tensor with boolean elements representing if each element of <code>input</code> is “close” to the corresponding element of <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.isfinite#torch.isfinite" title="torch.isfinite"><code>isfinite</code></a>
</td> <td><p>Returns a new tensor with boolean elements representing if each element is <code>finite</code> or not.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.isinf#torch.isinf" title="torch.isinf"><code>isinf</code></a>
</td> <td><p>Tests if each element of <code>input</code> is infinite (positive or negative infinity) or not.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.isposinf#torch.isposinf" title="torch.isposinf"><code>isposinf</code></a>
</td> <td><p>Tests if each element of <code>input</code> is positive infinity or not.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.isneginf#torch.isneginf" title="torch.isneginf"><code>isneginf</code></a>
</td> <td><p>Tests if each element of <code>input</code> is negative infinity or not.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.isnan#torch.isnan" title="torch.isnan"><code>isnan</code></a>
</td> <td><p>Returns a new tensor with boolean elements representing if each element of <code>input</code> is NaN or not.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.isreal#torch.isreal" title="torch.isreal"><code>isreal</code></a>
</td> <td><p>Returns a new tensor with boolean elements representing if each element of <code>input</code> is real-valued or not.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.kthvalue#torch.kthvalue" title="torch.kthvalue"><code>kthvalue</code></a>
</td> <td><p>Returns a namedtuple <code>(values, indices)</code> where <code>values</code> is the <code>k</code> th smallest element of each row of the <code>input</code> tensor in the given dimension <code>dim</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.le#torch.le" title="torch.le"><code>le</code></a>
</td> <td><p>Computes <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo>≤</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} \leq \text{other}</annotation></semantics></math></span></span> </span> element-wise.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.less_equal#torch.less_equal" title="torch.less_equal"><code>less_equal</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.le#torch.le" title="torch.le"><code>torch.le()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.lt#torch.lt" title="torch.lt"><code>lt</code></a>
</td> <td><p>Computes <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo>&lt;</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} &lt; \text{other}</annotation></semantics></math></span></span> </span> element-wise.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.less#torch.less" title="torch.less"><code>less</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.lt#torch.lt" title="torch.lt"><code>torch.lt()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.maximum#torch.maximum" title="torch.maximum"><code>maximum</code></a>
</td> <td><p>Computes the element-wise maximum of <code>input</code> and <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.minimum#torch.minimum" title="torch.minimum"><code>minimum</code></a>
</td> <td><p>Computes the element-wise minimum of <code>input</code> and <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.fmax#torch.fmax" title="torch.fmax"><code>fmax</code></a>
</td> <td><p>Computes the element-wise maximum of <code>input</code> and <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.fmin#torch.fmin" title="torch.fmin"><code>fmin</code></a>
</td> <td><p>Computes the element-wise minimum of <code>input</code> and <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.ne#torch.ne" title="torch.ne"><code>ne</code></a>
</td> <td><p>Computes <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo mathvariant="normal">≠</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} \neq \text{other}</annotation></semantics></math></span></span> </span> element-wise.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.not_equal#torch.not_equal" title="torch.not_equal"><code>not_equal</code></a>
</td> <td><p>Alias for <a class="reference internal" href="generated/torch.ne#torch.ne" title="torch.ne"><code>torch.ne()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.sort#torch.sort" title="torch.sort"><code>sort</code></a>
</td> <td><p>Sorts the elements of the <code>input</code> tensor along a given dimension in ascending order by value.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.topk#torch.topk" title="torch.topk"><code>topk</code></a>
</td> <td><p>Returns the <code>k</code> largest elements of the given <code>input</code> tensor along a given dimension.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.msort#torch.msort" title="torch.msort"><code>msort</code></a>
</td> <td><p>Sorts the elements of the <code>input</code> tensor along its first dimension in ascending order by value.</p></td> </tr>  </table>   <h3 id="spectral-ops">Spectral Ops</h3> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.stft#torch.stft" title="torch.stft"><code>stft</code></a>
</td> <td><p>Short-time Fourier transform (STFT).</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.istft#torch.istft" title="torch.istft"><code>istft</code></a>
</td> <td><p>Inverse short time Fourier Transform.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.bartlett_window#torch.bartlett_window" title="torch.bartlett_window"><code>bartlett_window</code></a>
</td> <td><p>Bartlett window function.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.blackman_window#torch.blackman_window" title="torch.blackman_window"><code>blackman_window</code></a>
</td> <td><p>Blackman window function.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.hamming_window#torch.hamming_window" title="torch.hamming_window"><code>hamming_window</code></a>
</td> <td><p>Hamming window function.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.hann_window#torch.hann_window" title="torch.hann_window"><code>hann_window</code></a>
</td> <td><p>Hann window function.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.kaiser_window#torch.kaiser_window" title="torch.kaiser_window"><code>kaiser_window</code></a>
</td> <td><p>Computes the Kaiser window with window length <code>window_length</code> and shape parameter <code>beta</code>.</p></td> </tr>  </table>   <h3 id="other-operations">Other Operations</h3> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.atleast_1d#torch.atleast_1d" title="torch.atleast_1d"><code>atleast_1d</code></a>
</td> <td><p>Returns a 1-dimensional view of each input tensor with zero dimensions.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.atleast_2d#torch.atleast_2d" title="torch.atleast_2d"><code>atleast_2d</code></a>
</td> <td><p>Returns a 2-dimensional view of each input tensor with zero dimensions.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.atleast_3d#torch.atleast_3d" title="torch.atleast_3d"><code>atleast_3d</code></a>
</td> <td><p>Returns a 3-dimensional view of each input tensor with zero dimensions.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.bincount#torch.bincount" title="torch.bincount"><code>bincount</code></a>
</td> <td><p>Count the frequency of each value in an array of non-negative ints.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.block_diag#torch.block_diag" title="torch.block_diag"><code>block_diag</code></a>
</td> <td><p>Create a block diagonal matrix from provided tensors.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.broadcast_tensors#torch.broadcast_tensors" title="torch.broadcast_tensors"><code>broadcast_tensors</code></a>
</td> <td><p>Broadcasts the given tensors according to <a class="reference internal" href="https://pytorch.org/docs/1.8.0/notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">Broadcasting semantics</span></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.broadcast_to#torch.broadcast_to" title="torch.broadcast_to"><code>broadcast_to</code></a>
</td> <td><p>Broadcasts <code>input</code> to the shape <code>shape</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.broadcast_shapes#torch.broadcast_shapes" title="torch.broadcast_shapes"><code>broadcast_shapes</code></a>
</td> <td><p>Similar to <a class="reference internal" href="generated/torch.broadcast_tensors#torch.broadcast_tensors" title="torch.broadcast_tensors"><code>broadcast_tensors()</code></a> but for shapes.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.bucketize#torch.bucketize" title="torch.bucketize"><code>bucketize</code></a>
</td> <td><p>Returns the indices of the buckets to which each value in the <code>input</code> belongs, where the boundaries of the buckets are set by <code>boundaries</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.cartesian_prod#torch.cartesian_prod" title="torch.cartesian_prod"><code>cartesian_prod</code></a>
</td> <td><p>Do cartesian product of the given sequence of tensors.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.cdist#torch.cdist" title="torch.cdist"><code>cdist</code></a>
</td> <td><p>Computes batched the p-norm distance between each pair of the two collections of row vectors.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.clone#torch.clone" title="torch.clone"><code>clone</code></a>
</td> <td><p>Returns a copy of <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.combinations#torch.combinations" title="torch.combinations"><code>combinations</code></a>
</td> <td><p>Compute combinations of length <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span></span> </span> of the given tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.cross#torch.cross" title="torch.cross"><code>cross</code></a>
</td> <td><p>Returns the cross product of vectors in dimension <code>dim</code> of <code>input</code> and <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.cummax#torch.cummax" title="torch.cummax"><code>cummax</code></a>
</td> <td><p>Returns a namedtuple <code>(values, indices)</code> where <code>values</code> is the cumulative maximum of elements of <code>input</code> in the dimension <code>dim</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.cummin#torch.cummin" title="torch.cummin"><code>cummin</code></a>
</td> <td><p>Returns a namedtuple <code>(values, indices)</code> where <code>values</code> is the cumulative minimum of elements of <code>input</code> in the dimension <code>dim</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.cumprod#torch.cumprod" title="torch.cumprod"><code>cumprod</code></a>
</td> <td><p>Returns the cumulative product of elements of <code>input</code> in the dimension <code>dim</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.cumsum#torch.cumsum" title="torch.cumsum"><code>cumsum</code></a>
</td> <td><p>Returns the cumulative sum of elements of <code>input</code> in the dimension <code>dim</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.diag#torch.diag" title="torch.diag"><code>diag</code></a>
</td> <td>

<ul class="simple"> <li>If <code>input</code> is a vector (1-D tensor), then returns a 2-D square tensor</li> </ul> </td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.diag_embed#torch.diag_embed" title="torch.diag_embed"><code>diag_embed</code></a>
</td> <td><p>Creates a tensor whose diagonals of certain 2D planes (specified by <code>dim1</code> and <code>dim2</code>) are filled by <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.diagflat#torch.diagflat" title="torch.diagflat"><code>diagflat</code></a>
</td> <td>

<ul class="simple"> <li>If <code>input</code> is a vector (1-D tensor), then returns a 2-D square tensor</li> </ul> </td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.diagonal#torch.diagonal" title="torch.diagonal"><code>diagonal</code></a>
</td> <td><p>Returns a partial view of <code>input</code> with the its diagonal elements with respect to <code>dim1</code> and <code>dim2</code> appended as a dimension at the end of the shape.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.diff#torch.diff" title="torch.diff"><code>diff</code></a>
</td> <td><p>Computes the n-th forward difference along the given dimension.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.einsum#torch.einsum" title="torch.einsum"><code>einsum</code></a>
</td> <td><p>Sums the product of the elements of the input <code>operands</code> along dimensions specified using a notation based on the Einstein summation convention.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.flatten#torch.flatten" title="torch.flatten"><code>flatten</code></a>
</td> <td><p>Flattens <code>input</code> by reshaping it into a one-dimensional tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.flip#torch.flip" title="torch.flip"><code>flip</code></a>
</td> <td><p>Reverse the order of a n-D tensor along given axis in dims.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.fliplr#torch.fliplr" title="torch.fliplr"><code>fliplr</code></a>
</td> <td><p>Flip tensor in the left/right direction, returning a new tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.flipud#torch.flipud" title="torch.flipud"><code>flipud</code></a>
</td> <td><p>Flip tensor in the up/down direction, returning a new tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.kron#torch.kron" title="torch.kron"><code>kron</code></a>
</td> <td><p>Computes the Kronecker product, denoted by <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊗</mo></mrow><annotation encoding="application/x-tex">\otimes</annotation></semantics></math></span></span> </span>, of <code>input</code> and <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.rot90#torch.rot90" title="torch.rot90"><code>rot90</code></a>
</td> <td><p>Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.gcd#torch.gcd" title="torch.gcd"><code>gcd</code></a>
</td> <td><p>Computes the element-wise greatest common divisor (GCD) of <code>input</code> and <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.histc#torch.histc" title="torch.histc"><code>histc</code></a>
</td> <td><p>Computes the histogram of a tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.meshgrid#torch.meshgrid" title="torch.meshgrid"><code>meshgrid</code></a>
</td> <td><p>Take <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> </span> tensors, each of which can be either scalar or 1-dimensional vector, and create <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> </span> N-dimensional grids, where the <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span></span> </span> <sup>th</sup> grid is defined by expanding the <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span></span> </span> <sup>th</sup> input over dimensions defined by other inputs.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.lcm#torch.lcm" title="torch.lcm"><code>lcm</code></a>
</td> <td><p>Computes the element-wise least common multiple (LCM) of <code>input</code> and <code>other</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.logcumsumexp#torch.logcumsumexp" title="torch.logcumsumexp"><code>logcumsumexp</code></a>
</td> <td><p>Returns the logarithm of the cumulative summation of the exponentiation of elements of <code>input</code> in the dimension <code>dim</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.ravel#torch.ravel" title="torch.ravel"><code>ravel</code></a>
</td> <td><p>Return a contiguous flattened tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.renorm#torch.renorm" title="torch.renorm"><code>renorm</code></a>
</td> <td><p>Returns a tensor where each sub-tensor of <code>input</code> along dimension <code>dim</code> is normalized such that the <code>p</code>-norm of the sub-tensor is lower than the value <code>maxnorm</code></p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.repeat_interleave#torch.repeat_interleave" title="torch.repeat_interleave"><code>repeat_interleave</code></a>
</td> <td><p>Repeat elements of a tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.roll#torch.roll" title="torch.roll"><code>roll</code></a>
</td> <td><p>Roll the tensor along the given dimension(s).</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.searchsorted#torch.searchsorted" title="torch.searchsorted"><code>searchsorted</code></a>
</td> <td><p>Find the indices from the <em>innermost</em> dimension of <code>sorted_sequence</code> such that, if the corresponding values in <code>values</code> were inserted before the indices, the order of the corresponding <em>innermost</em> dimension within <code>sorted_sequence</code> would be preserved.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.tensordot#torch.tensordot" title="torch.tensordot"><code>tensordot</code></a>
</td> <td><p>Returns a contraction of a and b over multiple dimensions.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.trace#torch.trace" title="torch.trace"><code>trace</code></a>
</td> <td><p>Returns the sum of the elements of the diagonal of the input 2-D matrix.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.tril#torch.tril" title="torch.tril"><code>tril</code></a>
</td> <td><p>Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices <code>input</code>, the other elements of the result tensor <code>out</code> are set to 0.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.tril_indices#torch.tril_indices" title="torch.tril_indices"><code>tril_indices</code></a>
</td> <td><p>Returns the indices of the lower triangular part of a <code>row</code>-by- <code>col</code> matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.triu#torch.triu" title="torch.triu"><code>triu</code></a>
</td> <td><p>Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices <code>input</code>, the other elements of the result tensor <code>out</code> are set to 0.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.triu_indices#torch.triu_indices" title="torch.triu_indices"><code>triu_indices</code></a>
</td> <td><p>Returns the indices of the upper triangular part of a <code>row</code> by <code>col</code> matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.vander#torch.vander" title="torch.vander"><code>vander</code></a>
</td> <td><p>Generates a Vandermonde matrix.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.view_as_real#torch.view_as_real" title="torch.view_as_real"><code>view_as_real</code></a>
</td> <td><p>Returns a view of <code>input</code> as a real tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.view_as_complex#torch.view_as_complex" title="torch.view_as_complex"><code>view_as_complex</code></a>
</td> <td><p>Returns a view of <code>input</code> as a complex tensor.</p></td> </tr>  </table>   <h3 id="blas-and-lapack-operations">BLAS and LAPACK Operations</h3> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.addbmm#torch.addbmm" title="torch.addbmm"><code>addbmm</code></a>
</td> <td><p>Performs a batch matrix-matrix product of matrices stored in <code>batch1</code> and <code>batch2</code>, with a reduced add step (all matrix multiplications get accumulated along the first dimension).</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.addmm#torch.addmm" title="torch.addmm"><code>addmm</code></a>
</td> <td><p>Performs a matrix multiplication of the matrices <code>mat1</code> and <code>mat2</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.addmv#torch.addmv" title="torch.addmv"><code>addmv</code></a>
</td> <td><p>Performs a matrix-vector product of the matrix <code>mat</code> and the vector <code>vec</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.addr#torch.addr" title="torch.addr"><code>addr</code></a>
</td> <td><p>Performs the outer-product of vectors <code>vec1</code> and <code>vec2</code> and adds it to the matrix <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.baddbmm#torch.baddbmm" title="torch.baddbmm"><code>baddbmm</code></a>
</td> <td><p>Performs a batch matrix-matrix product of matrices in <code>batch1</code> and <code>batch2</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.bmm#torch.bmm" title="torch.bmm"><code>bmm</code></a>
</td> <td><p>Performs a batch matrix-matrix product of matrices stored in <code>input</code> and <code>mat2</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.chain_matmul#torch.chain_matmul" title="torch.chain_matmul"><code>chain_matmul</code></a>
</td> <td><p>Returns the matrix product of the <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> </span> 2-D tensors.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.cholesky#torch.cholesky" title="torch.cholesky"><code>cholesky</code></a>
</td> <td><p>Computes the Cholesky decomposition of a symmetric positive-definite matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> </span> or for batches of symmetric positive-definite matrices.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.cholesky_inverse#torch.cholesky_inverse" title="torch.cholesky_inverse"><code>cholesky_inverse</code></a>
</td> <td><p>Computes the inverse of a symmetric positive-definite matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> </span> using its Cholesky factor <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span></span> </span>: returns matrix <code>inv</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.cholesky_solve#torch.cholesky_solve" title="torch.cholesky_solve"><code>cholesky_solve</code></a>
</td> <td><p>Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span></span> </span>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.dot#torch.dot" title="torch.dot"><code>dot</code></a>
</td> <td><p>Computes the dot product of two 1D tensors.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.eig#torch.eig" title="torch.eig"><code>eig</code></a>
</td> <td><p>Computes the eigenvalues and eigenvectors of a real square matrix.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.geqrf#torch.geqrf" title="torch.geqrf"><code>geqrf</code></a>
</td> <td><p>This is a low-level function for calling LAPACK directly.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.ger#torch.ger" title="torch.ger"><code>ger</code></a>
</td> <td><p>Alias of <a class="reference internal" href="generated/torch.outer#torch.outer" title="torch.outer"><code>torch.outer()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.inner#torch.inner" title="torch.inner"><code>inner</code></a>
</td> <td><p>Computes the dot product for 1D tensors.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.inverse#torch.inverse" title="torch.inverse"><code>inverse</code></a>
</td> <td><p>Takes the inverse of the square matrix <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.det#torch.det" title="torch.det"><code>det</code></a>
</td> <td><p>Calculates determinant of a square matrix or batches of square matrices.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.logdet#torch.logdet" title="torch.logdet"><code>logdet</code></a>
</td> <td><p>Calculates log determinant of a square matrix or batches of square matrices.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.slogdet#torch.slogdet" title="torch.slogdet"><code>slogdet</code></a>
</td> <td><p>Calculates the sign and log absolute value of the determinant(s) of a square matrix or batches of square matrices.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.lstsq#torch.lstsq" title="torch.lstsq"><code>lstsq</code></a>
</td> <td><p>Computes the solution to the least squares and least norm problems for a full rank matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> </span> of size <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>m</mi><mo>×</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(m \times n)</annotation></semantics></math></span></span> </span> and a matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span> </span> of size <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>m</mi><mo>×</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(m \times k)</annotation></semantics></math></span></span> </span>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.lu#torch.lu" title="torch.lu"><code>lu</code></a>
</td> <td><p>Computes the LU factorization of a matrix or batches of matrices <code>A</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.lu_solve#torch.lu_solve" title="torch.lu_solve"><code>lu_solve</code></a>
</td> <td><p>Returns the LU solve of the linear system <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>x</mi><mo>=</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Ax = b</annotation></semantics></math></span></span> </span> using the partially pivoted LU factorization of A from <a class="reference internal" href="generated/torch.lu#torch.lu" title="torch.lu"><code>torch.lu()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.lu_unpack#torch.lu_unpack" title="torch.lu_unpack"><code>lu_unpack</code></a>
</td> <td><p>Unpacks the data and pivots from a LU factorization of a tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.matmul#torch.matmul" title="torch.matmul"><code>matmul</code></a>
</td> <td><p>Matrix product of two tensors.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.matrix_power#torch.matrix_power" title="torch.matrix_power"><code>matrix_power</code></a>
</td> <td><p>Returns the matrix raised to the power <code>n</code> for square matrices.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.matrix_rank#torch.matrix_rank" title="torch.matrix_rank"><code>matrix_rank</code></a>
</td> <td><p>Returns the numerical rank of a 2-D tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.matrix_exp#torch.matrix_exp" title="torch.matrix_exp"><code>matrix_exp</code></a>
</td> <td><p>Returns the matrix exponential.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.mm#torch.mm" title="torch.mm"><code>mm</code></a>
</td> <td><p>Performs a matrix multiplication of the matrices <code>input</code> and <code>mat2</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.mv#torch.mv" title="torch.mv"><code>mv</code></a>
</td> <td><p>Performs a matrix-vector product of the matrix <code>input</code> and the vector <code>vec</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.orgqr#torch.orgqr" title="torch.orgqr"><code>orgqr</code></a>
</td> <td><p>Computes the orthogonal matrix <code>Q</code> of a QR factorization, from the <code>(input, input2)</code> tuple returned by <a class="reference internal" href="generated/torch.geqrf#torch.geqrf" title="torch.geqrf"><code>torch.geqrf()</code></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.ormqr#torch.ormqr" title="torch.ormqr"><code>ormqr</code></a>
</td> <td><p>Multiplies <code>mat</code> (given by <code>input3</code>) by the orthogonal <code>Q</code> matrix of the QR factorization formed by <a class="reference internal" href="generated/torch.geqrf#torch.geqrf" title="torch.geqrf"><code>torch.geqrf()</code></a> that is represented by <code>(a, tau)</code> (given by (<code>input</code>, <code>input2</code>)).</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.outer#torch.outer" title="torch.outer"><code>outer</code></a>
</td> <td><p>Outer product of <code>input</code> and <code>vec2</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.pinverse#torch.pinverse" title="torch.pinverse"><code>pinverse</code></a>
</td> <td><p>Calculates the pseudo-inverse (also known as the Moore-Penrose inverse) of a 2D tensor.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.qr#torch.qr" title="torch.qr"><code>qr</code></a>
</td> <td><p>Computes the QR decomposition of a matrix or a batch of matrices <code>input</code>, and returns a namedtuple (Q, R) of tensors such that <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo>=</mo><mi>Q</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">\text{input} = Q R</annotation></semantics></math></span></span> </span> with <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span></span> </span> being an orthogonal matrix or batch of orthogonal matrices and <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span></span> </span> being an upper triangular matrix or batch of upper triangular matrices.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.solve#torch.solve" title="torch.solve"><code>solve</code></a>
</td> <td><p>This function returns the solution to the system of linear equations represented by <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>X</mi><mo>=</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">AX = B</annotation></semantics></math></span></span> </span> and the LU factorization of A, in order as a namedtuple <code>solution, LU</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.svd#torch.svd" title="torch.svd"><code>svd</code></a>
</td> <td><p>Computes the singular value decomposition of either a matrix or batch of matrices <code>input</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.svd_lowrank#torch.svd_lowrank" title="torch.svd_lowrank"><code>svd_lowrank</code></a>
</td> <td><p>Return the singular value decomposition <code>(U, S, V)</code> of a matrix, batches of matrices, or a sparse matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> </span> such that <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>≈</mo><mi>U</mi><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo stretchy="false">(</mo><mi>S</mi><mo stretchy="false">)</mo><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A \approx U diag(S) V^T</annotation></semantics></math></span></span> </span>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.pca_lowrank#torch.pca_lowrank" title="torch.pca_lowrank"><code>pca_lowrank</code></a>
</td> <td><p>Performs linear Principal Component Analysis (PCA) on a low-rank matrix, batches of such matrices, or sparse matrix.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.symeig#torch.symeig" title="torch.symeig"><code>symeig</code></a>
</td> <td><p>This function returns eigenvalues and eigenvectors of a real symmetric matrix <code>input</code> or a batch of real symmetric matrices, represented by a namedtuple (eigenvalues, eigenvectors).</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.lobpcg#torch.lobpcg" title="torch.lobpcg"><code>lobpcg</code></a>
</td> <td><p>Find the k largest (or smallest) eigenvalues and the corresponding eigenvectors of a symmetric positive defined generalized eigenvalue problem using matrix-free LOBPCG methods.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.trapz#torch.trapz" title="torch.trapz"><code>trapz</code></a>
</td> <td><p>Estimate <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∫</mo><mi>y</mi><mi>d</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">\int y\,dx</annotation></semantics></math></span></span> </span> along <code>dim</code>, using the trapezoid rule.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.triangular_solve#torch.triangular_solve" title="torch.triangular_solve"><code>triangular_solve</code></a>
</td> <td><p>Solves a system of equations with a triangular coefficient matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> </span> and multiple right-hand sides <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span> </span>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.vdot#torch.vdot" title="torch.vdot"><code>vdot</code></a>
</td> <td><p>Computes the dot product of two 1D tensors.</p></td> </tr>  </table>    <h2 id="utilities">Utilities</h2> <table class="longtable docutils colwidths-auto align-default">  <tr>
<td>


<a class="reference internal" href="generated/torch.compiled_with_cxx11_abi#torch.compiled_with_cxx11_abi" title="torch.compiled_with_cxx11_abi"><code>compiled_with_cxx11_abi</code></a>
</td> <td><p>Returns whether PyTorch was built with _GLIBCXX_USE_CXX11_ABI=1</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.result_type#torch.result_type" title="torch.result_type"><code>result_type</code></a>
</td> <td><p>Returns the <a class="reference internal" href="tensor_attributes#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> that would result from performing an arithmetic operation on the provided input tensors.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.can_cast#torch.can_cast" title="torch.can_cast"><code>can_cast</code></a>
</td> <td><p>Determines if a type conversion is allowed under PyTorch casting rules described in the type promotion <a class="reference internal" href="tensor_attributes#type-promotion-doc"><span class="std std-ref">documentation</span></a>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.promote_types#torch.promote_types" title="torch.promote_types"><code>promote_types</code></a>
</td> <td><p>Returns the <a class="reference internal" href="tensor_attributes#torch.torch.dtype" title="torch.torch.dtype"><code>torch.dtype</code></a> with the smallest size and scalar kind that is not smaller nor of lower kind than either <code>type1</code> or <code>type2</code>.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.use_deterministic_algorithms#torch.use_deterministic_algorithms" title="torch.use_deterministic_algorithms"><code>use_deterministic_algorithms</code></a>
</td> <td><p>Sets whether PyTorch operations must use “deterministic” algorithms.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch.are_deterministic_algorithms_enabled#torch.are_deterministic_algorithms_enabled" title="torch.are_deterministic_algorithms_enabled"><code>are_deterministic_algorithms_enabled</code></a>
</td> <td><p>Returns True if the global deterministic flag is turned on.</p></td> </tr> <tr>
<td>


<a class="reference internal" href="generated/torch._assert#torch._assert" title="torch._assert"><code>_assert</code></a>
</td> <td><p>A wrapper around Python’s assert which is symbolically traceable.</p></td> </tr>  </table><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 Torch Contributors<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://pytorch.org/docs/1.8.0/torch.html" class="_attribution-link">https://pytorch.org/docs/1.8.0/torch.html</a>
  </p>
</div>
