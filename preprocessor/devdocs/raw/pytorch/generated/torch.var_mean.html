<h1 id="torch-var-mean">torch.var_mean</h1> <dl class="function"> <dt id="torch.var_mean">
<code>torch.var_mean(input, unbiased=True) -&gt; (Tensor, Tensor)</code> </dt> <dd>
<p>Returns the variance and mean of all elements in the <code>input</code> tensor.</p> <p>If <code>unbiased</code> is <code>False</code>, then the variance will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</li> <li>
<strong>unbiased</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a>) – whether to use the unbiased estimation or not</li> </ul> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; a = torch.randn(1, 3)
&gt;&gt;&gt; a
tensor([[0.0146, 0.4258, 0.2211]])
&gt;&gt;&gt; torch.var_mean(a)
(tensor(0.0423), tensor(0.2205))
</pre> <dl class="function"> <dt>
<code>torch.var_mean(input, dim, keepdim=False, unbiased=True) -&gt; (Tensor, Tensor)</code> </dt> 
</dl> <p>Returns the variance and mean of each row of the <code>input</code> tensor in the given dimension <code>dim</code>.</p> <p>If <code>keepdim</code> is <code>True</code>, the output tensor is of the same size as <code>input</code> except in the dimension(s) <code>dim</code> where it is of size 1. Otherwise, <code>dim</code> is squeezed (see <a class="reference internal" href="torch.squeeze#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a>), resulting in the output tensor having 1 (or <code>len(dim)</code>) fewer dimension(s).</p> <p>If <code>unbiased</code> is <code>False</code>, then the variance will be calculated via the biased estimator. Otherwise, Bessel’s correction will be used.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</li> <li>
<strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a><em> or </em><em>tuple of python:ints</em>) – the dimension or dimensions to reduce.</li> <li>
<strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a>) – whether the output tensor has <code>dim</code> retained or not.</li> <li>
<strong>unbiased</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a>) – whether to use the unbiased estimation or not</li> </ul> </dd> </dl> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; a = torch.randn(4, 4)
&gt;&gt;&gt; a
tensor([[-1.5650,  2.0415, -0.1024, -0.5790],
        [ 0.2325, -2.6145, -1.6428, -0.3537],
        [-0.2159, -1.1069,  1.2882, -1.3265],
        [-0.6706, -1.5893,  0.6827,  1.6727]])
&gt;&gt;&gt; torch.var_mean(a, 1)
(tensor([2.3174, 1.6403, 1.4092, 2.0791]), tensor([-0.0512, -1.0946, -0.3403,  0.0239]))
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 Torch Contributors<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://pytorch.org/docs/1.8.0/generated/torch.var_mean.html" class="_attribution-link">https://pytorch.org/docs/1.8.0/generated/torch.var_mean.html</a>
  </p>
</div>
