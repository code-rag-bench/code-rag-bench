<h1 id="torch-searchsorted">torch.searchsorted</h1> <dl class="function"> <dt id="torch.searchsorted">
<code>torch.searchsorted(sorted_sequence, values, *, out_int32=False, right=False, out=None) → Tensor</code> </dt> <dd>
<p>Find the indices from the <em>innermost</em> dimension of <code>sorted_sequence</code> such that, if the corresponding values in <code>values</code> were inserted before the indices, the order of the corresponding <em>innermost</em> dimension within <code>sorted_sequence</code> would be preserved. Return a new tensor with the same size as <code>values</code>. If <code>right</code> is False (default), then the left boundary of <code>sorted_sequence</code> is closed. More formally, the returned index satisfies the following rules:</p> <table class="colwidths-given docutils colwidths-auto align-default">  <thead> <tr>
<th class="head"><p><code>sorted_sequence</code></p></th> <th class="head"><p><code>right</code></p></th> <th class="head"><p><em>returned index satisfies</em></p></th> </tr> </thead>  <tr>
<td><p>1-D</p></td> <td><p>False</p></td> <td><p><code>sorted_sequence[i-1] &lt; values[m][n]...[l][x] &lt;= sorted_sequence[i]</code></p></td> </tr> <tr>
<td><p>1-D</p></td> <td><p>True</p></td> <td><p><code>sorted_sequence[i-1] &lt;= values[m][n]...[l][x] &lt; sorted_sequence[i]</code></p></td> </tr> <tr>
<td><p>N-D</p></td> <td><p>False</p></td> <td><p><code>sorted_sequence[m][n]...[l][i-1] &lt; values[m][n]...[l][x] &lt;= sorted_sequence[m][n]...[l][i]</code></p></td> </tr> <tr>
<td><p>N-D</p></td> <td><p>True</p></td> <td><p><code>sorted_sequence[m][n]...[l][i-1] &lt;= values[m][n]...[l][x] &lt; sorted_sequence[m][n]...[l][i]</code></p></td> </tr>  </table> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>sorted_sequence</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – N-D or 1-D tensor, containing monotonically increasing sequence on the <em>innermost</em> dimension.</li> <li>
<strong>values</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em> or </em><em>Scalar</em>) – N-D tensor or a Scalar containing the search value(s).</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<ul class="simple"> <li>
<strong>out_int32</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a><em>, </em><em>optional</em>) – indicate the output data type. torch.int32 if True, torch.int64 otherwise. Default value is False, i.e. default output data type is torch.int64.</li> <li>
<strong>right</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a><em>, </em><em>optional</em>) – if False, return the first suitable location that is found. If True, return the last such index. If no suitable index found, return 0 for non-numerical value (eg. nan, inf) or the size of <em>innermost</em> dimension within <code>sorted_sequence</code> (one pass the last index of the <em>innermost</em> dimension). In other words, if False, gets the lower bound index for each value in <code>values</code> on the corresponding <em>innermost</em> dimension of the <code>sorted_sequence</code>. If True, gets the upper bound index instead. Default value is False.</li> <li>
<strong>out</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor, must be the same size as <code>values</code> if provided.</li> </ul> </dd> </dl> <div class="admonition note"> <p class="admonition-title">Note</p> <p>If your use case is always 1-D sorted sequence, <a class="reference internal" href="torch.bucketize#torch.bucketize" title="torch.bucketize"><code>torch.bucketize()</code></a> is preferred, because it has fewer dimension checks resulting in slightly better performance.</p> </div> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; sorted_sequence = torch.tensor([[1, 3, 5, 7, 9], [2, 4, 6, 8, 10]])
&gt;&gt;&gt; sorted_sequence
tensor([[ 1,  3,  5,  7,  9],
        [ 2,  4,  6,  8, 10]])
&gt;&gt;&gt; values = torch.tensor([[3, 6, 9], [3, 6, 9]])
&gt;&gt;&gt; values
tensor([[3, 6, 9],
        [3, 6, 9]])
&gt;&gt;&gt; torch.searchsorted(sorted_sequence, values)
tensor([[1, 3, 4],
        [1, 2, 4]])
&gt;&gt;&gt; torch.searchsorted(sorted_sequence, values, right=True)
tensor([[2, 3, 5],
        [1, 3, 4]])

&gt;&gt;&gt; sorted_sequence_1d = torch.tensor([1, 3, 5, 7, 9])
&gt;&gt;&gt; sorted_sequence_1d
tensor([1, 3, 5, 7, 9])
&gt;&gt;&gt; torch.searchsorted(sorted_sequence_1d, values)
tensor([[1, 3, 4],
        [1, 3, 4]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 Torch Contributors<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://pytorch.org/docs/1.8.0/generated/torch.searchsorted.html" class="_attribution-link">https://pytorch.org/docs/1.8.0/generated/torch.searchsorted.html</a>
  </p>
</div>
