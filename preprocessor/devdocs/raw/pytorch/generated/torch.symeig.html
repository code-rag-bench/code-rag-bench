<h1 id="torch-symeig">torch.symeig</h1> <dl class="function"> <dt id="torch.symeig">
<code>torch.symeig(input, eigenvectors=False, upper=True, *, out=None) -&gt; (Tensor, Tensor)</code> </dt> <dd>
<p>This function returns eigenvalues and eigenvectors of a real symmetric matrix <code>input</code> or a batch of real symmetric matrices, represented by a namedtuple (eigenvalues, eigenvectors).</p> <p>This function calculates all eigenvalues (and vectors) of <code>input</code> such that <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>input</mtext><mo>=</mo><mi>V</mi><mtext>diag</mtext><mo stretchy="false">(</mo><mi>e</mi><mo stretchy="false">)</mo><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\text{input} = V \text{diag}(e) V^T</annotation></semantics></math></span></span> </span>.</p> <p>The boolean argument <code>eigenvectors</code> defines computation of both eigenvectors and eigenvalues or eigenvalues only.</p> <p>If it is <code>False</code>, only eigenvalues are computed. If it is <code>True</code>, both eigenvalues and eigenvectors are computed.</p> <p>Since the input matrix <code>input</code> is supposed to be symmetric, only the upper triangular portion is used by default.</p> <p>If <code>upper</code> is <code>False</code>, then lower triangular portion is used.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The eigenvalues are returned in ascending order. If <code>input</code> is a batch of matrices, then the eigenvalues of each matrix in the batch is returned in ascending order.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Irrespective of the original strides, the returned matrix <code>V</code> will be transposed, i.e. with strides <code>V.contiguous().transpose(-1, -2).stride()</code>.</p> </div> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>Extra care needs to be taken when backward through outputs. Such operation is only stable when all eigenvalues are distinct and becomes less stable the smaller <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mo><mi>min</mi><mo>⁡</mo></mo><mrow><mi>i</mi><mo mathvariant="normal">≠</mo><mi>j</mi></mrow></msub><mi mathvariant="normal">∣</mi><msub><mi>λ</mi><mi>i</mi></msub><mo>−</mo><msub><mi>λ</mi><mi>j</mi></msub><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">\min_{i \neq j} |\lambda_i - \lambda_j|</annotation></semantics></math></span></span> </span> is.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor of size <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo>∗</mo><mo separator="true">,</mo><mi>n</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(*, n, n)</annotation></semantics></math></span></span> </span> where <code>*</code> is zero or more batch dimensions consisting of symmetric matrices.</li> <li>
<strong>eigenvectors</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a><em>, </em><em>optional</em>) – controls whether eigenvectors have to be computed</li> <li>
<strong>upper</strong> (<em>boolean</em><em>, </em><em>optional</em>) – controls whether to consider upper-triangular or lower-triangular region</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a><em>, </em><em>optional</em>) – the output tuple of (Tensor, Tensor)</p> </dd> <dt class="field-odd">Returns</dt> <dd class="field-odd">

<p>A namedtuple (eigenvalues, eigenvectors) containing</p>  <ul class="simple"> <li>
<strong>eigenvalues</strong> (<em>Tensor</em>): Shape <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo>∗</mo><mo separator="true">,</mo><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(*, m)</annotation></semantics></math></span></span> </span>. The eigenvalues in ascending order.</li> <li>
<strong>eigenvectors</strong> (<em>Tensor</em>): Shape <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo>∗</mo><mo separator="true">,</mo><mi>m</mi><mo separator="true">,</mo><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(*, m, m)</annotation></semantics></math></span></span> </span>. If <code>eigenvectors=False</code>, it’s an empty tensor. Otherwise, this tensor contains the orthonormal eigenvectors of the <code>input</code>.</li> </ul>  </dd> <dt class="field-even">Return type</dt> <dd class="field-even">
<p>(<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>, <a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>)</p> </dd> </dl> <p>Examples:</p> <pre data-language="python">&gt;&gt;&gt; a = torch.randn(5, 5)
&gt;&gt;&gt; a = a + a.t()  # To make a symmetric
&gt;&gt;&gt; a
tensor([[-5.7827,  4.4559, -0.2344, -1.7123, -1.8330],
        [ 4.4559,  1.4250, -2.8636, -3.2100, -0.1798],
        [-0.2344, -2.8636,  1.7112, -5.5785,  7.1988],
        [-1.7123, -3.2100, -5.5785, -2.6227,  3.1036],
        [-1.8330, -0.1798,  7.1988,  3.1036, -5.1453]])
&gt;&gt;&gt; e, v = torch.symeig(a, eigenvectors=True)
&gt;&gt;&gt; e
tensor([-13.7012,  -7.7497,  -2.3163,   5.2477,   8.1050])
&gt;&gt;&gt; v
tensor([[ 0.1643,  0.9034, -0.0291,  0.3508,  0.1817],
        [-0.2417, -0.3071, -0.5081,  0.6534,  0.4026],
        [-0.5176,  0.1223, -0.0220,  0.3295, -0.7798],
        [-0.4850,  0.2695, -0.5773, -0.5840,  0.1337],
        [ 0.6415, -0.0447, -0.6381, -0.0193, -0.4230]])
&gt;&gt;&gt; a_big = torch.randn(5, 2, 2)
&gt;&gt;&gt; a_big = a_big + a_big.transpose(-2, -1)  # To make a_big symmetric
&gt;&gt;&gt; e, v = a_big.symeig(eigenvectors=True)
&gt;&gt;&gt; torch.allclose(torch.matmul(v, torch.matmul(e.diag_embed(), v.transpose(-2, -1))), a_big)
True
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 Torch Contributors<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://pytorch.org/docs/1.8.0/generated/torch.symeig.html" class="_attribution-link">https://pytorch.org/docs/1.8.0/generated/torch.symeig.html</a>
  </p>
</div>
