<h1 id="torch-lstsq">torch.lstsq</h1> <dl class="function"> <dt id="torch.lstsq">
<code>torch.lstsq(input, A, *, out=None) → Tensor</code> </dt> <dd>
<p>Computes the solution to the least squares and least norm problems for a full rank matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> </span> of size <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>m</mi><mo>×</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(m \times n)</annotation></semantics></math></span></span> </span> and a matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span> </span> of size <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>m</mi><mo>×</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(m \times k)</annotation></semantics></math></span></span> </span>.</p> <p>If <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>≥</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \geq n</annotation></semantics></math></span></span> </span>, <a class="reference internal" href="#torch.lstsq" title="torch.lstsq"><code>lstsq()</code></a> solves the least-squares problem:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.15999999999999992em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mo><mi>min</mi><mo>⁡</mo></mo><mi>X</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi mathvariant="normal">∥</mi><mi>A</mi><mi>X</mi><mo>−</mo><mi>B</mi><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{ll} \min_X &amp; \|AX-B\|_2. \end{array}</annotation></semantics></math></span></span></span> </div>
<p>If <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>&lt;</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m &lt; n</annotation></semantics></math></span></span> </span>, <a class="reference internal" href="#torch.lstsq" title="torch.lstsq"><code>lstsq()</code></a> solves the least-norm problem:</p> <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.15999999999999992em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mo><mi>min</mi><mo>⁡</mo></mo><mi>X</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi mathvariant="normal">∥</mi><mi>X</mi><msub><mi mathvariant="normal">∥</mi><mn>2</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>subject to</mtext></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>A</mi><mi>X</mi><mo>=</mo><mi>B</mi><mi mathvariant="normal">.</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{ll} \min_X &amp; \|X\|_2 &amp; \text{subject to} &amp; AX = B. \end{array}</annotation></semantics></math></span></span></span> </div>
<p>Returned tensor <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span></span> </span> has shape <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo><mo>×</mo><mi>k</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\max(m, n) \times k)</annotation></semantics></math></span></span> </span>. The first <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> </span> rows of <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span></span> </span> contains the solution. If <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>≥</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \geq n</annotation></semantics></math></span></span> </span>, the residual sum of squares for the solution in each column is given by the sum of squares of elements in the remaining <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>−</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m - n</annotation></semantics></math></span></span> </span> rows of that column.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The case when <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>&lt;</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m &lt; n</annotation></semantics></math></span></span> </span> is not supported on the GPU.</p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span> </span>
</li> <li>
<strong>A</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> </span> by <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span> </span> matrix <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> </span>
</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a><em>, </em><em>optional</em>) – the optional destination tensor</p> </dd> <dt class="field-odd">Returns</dt> <dd class="field-odd">

<p>A namedtuple (solution, QR) containing:</p>  <ul class="simple"> <li>
<strong>solution</strong> (<em>Tensor</em>): the least squares solution</li> <li>
<strong>QR</strong> (<em>Tensor</em>): the details of the QR factorization</li> </ul>  </dd> <dt class="field-even">Return type</dt> <dd class="field-even">
<p>(<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>, <a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>)</p> </dd> </dl> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The returned matrices will always be transposed, irrespective of the strides of the input matrices. That is, they will have stride <code>(1, m)</code> instead of <code>(m, 1)</code>.</p> </div> <p>Example:</p> <pre data-language="python">&gt;&gt;&gt; A = torch.tensor([[1., 1, 1],
...                   [2, 3, 4],
...                   [3, 5, 2],
...                   [4, 2, 5],
...                   [5, 4, 3]])
&gt;&gt;&gt; B = torch.tensor([[-10., -3],
...                   [ 12, 14],
...                   [ 14, 12],
...                   [ 16, 16],
...                   [ 18, 16]])
&gt;&gt;&gt; X, _ = torch.lstsq(B, A)
&gt;&gt;&gt; X
tensor([[  2.0000,   1.0000],
        [  1.0000,   1.0000],
        [  1.0000,   2.0000],
        [ 10.9635,   4.8501],
        [  8.9332,   5.2418]])
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 Torch Contributors<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://pytorch.org/docs/1.8.0/generated/torch.lstsq.html" class="_attribution-link">https://pytorch.org/docs/1.8.0/generated/torch.lstsq.html</a>
  </p>
</div>
