<h1 id="torch-logsumexp">torch.logsumexp</h1> <dl class="function"> <dt id="torch.logsumexp">
<code>torch.logsumexp(input, dim, keepdim=False, *, out=None)</code> </dt> <dd>
<p>Returns the log of summed exponentials of each row of the <code>input</code> tensor in the given dimension <code>dim</code>. The computation is numerically stabilized.</p> <p>For summation index <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span></span> </span> given by <code>dim</code> and other indices <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span></span> </span>, the result is</p>  <div class="math"> <span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>logsumexp</mtext><mo stretchy="false">(</mo><mi>x</mi><msub><mo stretchy="false">)</mo><mi>i</mi></msub><mo>=</mo><mi>log</mi><mo>⁡</mo><munder><mo>∑</mo><mi>j</mi></munder><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{logsumexp}(x)_{i} = \log \sum_j \exp(x_{ij}) </annotation></semantics></math></span></span></span> </div> <p>If <code>keepdim</code> is <code>True</code>, the output tensor is of the same size as <code>input</code> except in the dimension(s) <code>dim</code> where it is of size 1. Otherwise, <code>dim</code> is squeezed (see <a class="reference internal" href="torch.squeeze#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a>), resulting in the output tensor having 1 (or <code>len(dim)</code>) fewer dimension(s).</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<ul class="simple"> <li>
<strong>input</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a>) – the input tensor.</li> <li>
<strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a><em> or </em><em>tuple of python:ints</em>) – the dimension or dimensions to reduce.</li> <li>
<strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)">bool</a>) – whether the output tensor has <code>dim</code> retained or not.</li> </ul> </dd> <dt class="field-even">Keyword Arguments</dt> <dd class="field-even">
<p><strong>out</strong> (<a class="reference internal" href="../tensors#torch.Tensor" title="torch.Tensor">Tensor</a><em>, </em><em>optional</em>) – the output tensor.</p> </dd> </dl> <dl> <dt>Example::</dt>
<dd>
<pre data-language="python">&gt;&gt;&gt; a = torch.randn(3, 3)
&gt;&gt;&gt; torch.logsumexp(a, 1)
tensor([ 0.8442,  1.4322,  0.8711])
</pre> </dd> </dl> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2019 Torch Contributors<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://pytorch.org/docs/1.8.0/generated/torch.logsumexp.html" class="_attribution-link">https://pytorch.org/docs/1.8.0/generated/torch.logsumexp.html</a>
  </p>
</div>
