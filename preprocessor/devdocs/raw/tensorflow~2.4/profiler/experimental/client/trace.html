<h1 class="devsite-page-title">tf.profiler.experimental.client.trace</h1>   <p><devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax> </p>    <p>Sends gRPC requests to one or more profiler servers to perform on-demand profiling.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.profiler.experimental.client.trace(
    service_addr, logdir, duration_ms, worker_list='',
    num_tracing_attempts=3, options=None
)
</pre>  <p>This method will block the calling thread until it receives responses from all servers or until deadline expiration. Both single host and multiple host profiling are supported on CPU, GPU, and TPU. The profiled results will be saved by each server to the specified TensorBoard log directory (i.e. the directory you save your model checkpoints). Use the TensorBoard profile plugin to view the visualization and analysis results.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">service_addr</code> </td> <td> A comma delimited string of gRPC addresses of the workers to profile. e.g. service_addr='grpc://localhost:6009' service_addr='grpc://10.0.0.2:8466,grpc://10.0.0.3:8466' service_addr='grpc://localhost:12345,grpc://localhost:23456' </td> </tr>
<tr> <td> <code translate="no" dir="ltr">logdir</code> </td> <td> Path to save profile data to, typically a TensorBoard log directory. This path must be accessible to both the client and server. e.g. logdir='gs://your_tb_dir' </td> </tr>
<tr> <td> <code translate="no" dir="ltr">duration_ms</code> </td> <td> Duration of tracing or monitoring in milliseconds. Must be greater than zero. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">worker_list</code> </td> <td> An optional TPU only configuration. The list of workers to profile in the current session. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_tracing_attempts</code> </td> <td> Optional. Automatically retry N times when no trace event is collected (default 3). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">options</code> </td> <td> profiler.experimental.ProfilerOptions namedtuple for miscellaneous profiler options. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">InvalidArgumentError</code> </td> <td> For when arguments fail validation checks. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">UnavailableError</code> </td> <td> If no trace event was collected. </td> </tr> </table> <p>Example usage (CPU/GPU):</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Start a profiler server before your model runs.
tf.profiler.experimental.server.start(6009)
# (Model code goes here).
# Send gRPC request to the profiler server to collect a trace of your model.
tf.profiler.experimental.client.trace('grpc://localhost:6009',
                                      '/nfs/tb_log', 2000)
</pre> <p>Example usage (Multiple GPUs):</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># E.g. your worker IP addresses are 10.0.0.2, 10.0.0.3, 10.0.0.4, and you
# would like to schedule start of profiling 1 second from now, for a
# duration of 2 seconds.
options['delay_ms'] = 1000
tf.profiler.experimental.client.trace(
    'grpc://10.0.0.2:8466,grpc://10.0.0.3:8466,grpc://10.0.0.4:8466',
    'gs://your_tb_dir',
    2000,
    options=options)
</pre> <p>Example usage (TPU):</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Send gRPC request to a TPU worker to collect a trace of your model. A
# profiler service has been started in the TPU worker at port 8466.
# E.g. your TPU IP address is 10.0.0.2 and you want to profile for 2 seconds
# .
tf.profiler.experimental.client.trace('grpc://10.0.0.2:8466',
                                      'gs://your_tb_dir', 2000)
</pre> <p>Example usage (Multiple TPUs):</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># Send gRPC request to a TPU pod to collect a trace of your model on
# multipleTPUs. A profiler service has been started in all the TPU workers
# at theport 8466.
# E.g. your TPU IP addresses are 10.0.0.2, 10.0.0.3, 10.0.0.4, and you want
# to profile for 2 seconds.
tf.profiler.experimental.client.trace('grpc://10.0.0.2:8466',
                                      'gs://your_tb_dir',
                                      2000, '10.0.0.2,10.0.0.3,10.0.0.4')
</pre> <p>Launch TensorBoard and point it to the same logdir you provided to this API.</p> <pre class="prettyprint lang-shell" translate="no" dir="ltr" data-language="cpp"># logdir can be gs://your_tb_dir as in the above examples.
$ tensorboard --logdir=/tmp/tb_log
</pre> <p>Open your browser and go to localhost:6006/#profile to view profiling results.</p>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/profiler/experimental/client/trace" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/profiler/experimental/client/trace</a>
  </p>
</div>
