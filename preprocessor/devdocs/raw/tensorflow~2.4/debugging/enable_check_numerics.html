<h1 class="devsite-page-title">tf.debugging.enable_check_numerics</h1>       <p>Enable tensor numerics checking in an eager/graph unified fashion.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/debugging/enable_check_numerics"><code translate="no" dir="ltr">tf.compat.v1.debugging.enable_check_numerics</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.debugging.enable_check_numerics(
    stack_height_limit=30, path_length_limit=50
)
</pre>  <p>The numerics checking mechanism will cause any TensorFlow eager execution or graph execution to error out as soon as an op's output tensor contains infinity or NaN.</p> <p>This method is idempotent. Calling it multiple times has the same effect as calling it once.</p> <p>This method takes effect only on the thread in which it is called.</p> <p>When a op's float-type output tensor contains any Infinity or NaN, an <a href="../errors/invalidargumenterror"><code translate="no" dir="ltr">tf.errors.InvalidArgumentError</code></a> will be thrown, with an error message that reveals the following information:</p> <ul> <li>The type of the op that generated the tensor with bad numerics.</li> <li>Data type (dtype) of the tensor.</li> <li>Shape of the tensor (to the extent known at the time of eager execution or graph construction).</li> <li>Name of the containing graph (if available).</li> <li>(Graph mode only): The stack trace of the intra-graph op's creation, with a stack-height limit and a path-length limit for visual clarity. The stack frames that belong to the user's code (as opposed to tensorflow's internal code) are highlighted with a text arrow ("-&gt;").</li> <li>(Eager mode only): How many of the offending tensor's elements are <code translate="no" dir="ltr">Infinity</code> and <code translate="no" dir="ltr">NaN</code>, respectively.</li> </ul> <p>Once enabled, the check-numerics mechanism can be disabled by using <a href="disable_check_numerics"><code translate="no" dir="ltr">tf.debugging.disable_check_numerics()</code></a>.</p> <h4 id="example_usage" data-text="Example usage:">Example usage:</h4> <ol> <li>
<p>Catching infinity during the execution of a <a href="../function"><code translate="no" dir="ltr">tf.function</code></a> graph:</p> <pre class="prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">import tensorflow as tf

tf.debugging.enable_check_numerics()

@tf.function
def square_log_x_plus_1(x):
  v = tf.math.log(x + 1)
  return tf.math.square(v)

x = -1.0

# When the following line runs, a function graph will be compiled
# from the Python function `square_log_x_plus_1()`. Due to the
# `enable_check_numerics()` call above, the graph will contain
# numerics checking ops that will run during the function graph's
# execution. The function call generates an -infinity when the Log
# (logarithm) op operates on the output tensor of the Add op.
# The program errors out at this line, printing an error message.
y = square_log_x_plus_1(x)
z = -y
</pre>
</li> <li>
<p>Catching NaN during eager execution:</p> <pre class="prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">import numpy as np
import tensorflow as tf

tf.debugging.enable_check_numerics()

x = np.array([[0.0, -1.0], [4.0, 3.0]])

# The following line executes the Sqrt op eagerly. Due to the negative
# element in the input array, a NaN is generated. Due to the
# `enable_check_numerics()` call above, the program errors immediately
# at this line, printing an error message.
y = tf.math.sqrt(x)
z = tf.matmul(y, y)
</pre>
</li> </ol> <blockquote class="note">
<strong>Note:</strong><span> If your code is running on TPUs, be sure to call <a href="../config/set_soft_device_placement"><code translate="no" dir="ltr">tf.config.set_soft_device_placement(True)</code></a> before calling <a href="enable_check_numerics"><code translate="no" dir="ltr">tf.debugging.enable_check_numerics()</code></a> as this API uses automatic outside compilation on TPUs. For example:</span>
</blockquote>
<pre class="prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">tf.config.set_soft_device_placement(True)
tf.debugging.enable_check_numerics()

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')
strategy = tf.distribute.TPUStrategy(resolver)
with strategy.scope():
  # ...
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">stack_height_limit</code> </td> <td> Limit to the height of the printed stack trace. Applicable only to ops in <a href="../function"><code translate="no" dir="ltr">tf.function</code></a>s (graphs). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">path_length_limit</code> </td> <td> Limit to the file path included in the printed stack trace. Applicable only to ops in <a href="../function"><code translate="no" dir="ltr">tf.function</code></a>s (graphs). </td> </tr> </table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/debugging/enable_check_numerics" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/debugging/enable_check_numerics</a>
  </p>
</div>
