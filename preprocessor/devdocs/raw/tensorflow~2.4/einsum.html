<h1 class="devsite-page-title">tf.einsum</h1>   <p><devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax> </p>   <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/ops/special_math_ops.py#L606-L751">  View source on GitHub </a> </td> </table> <p>Tensor contraction over specified indices and outer product.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Main aliases</b> </p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/einsum"><code translate="no" dir="ltr">tf.linalg.einsum</code></a></p> <b>Compat aliases for migration</b> <p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/einsum"><code translate="no" dir="ltr">tf.compat.v1.einsum</code></a>, <a href="https://www.tensorflow.org/api_docs/python/tf/einsum"><code translate="no" dir="ltr">tf.compat.v1.linalg.einsum</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.einsum(
    equation, *inputs, **kwargs
)
</pre>  <p>Einsum allows defining Tensors by defining their element-wise computation. This computation is defined by <code translate="no" dir="ltr">equation</code>, a shorthand form based on Einstein summation. As an example, consider multiplying two matrices A and B to form a matrix C. The elements of C are given by:</p> <div> $$ C_{i,k} = \sum_j A_{i,j} B_{j,k} $$ </div> <p>or</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">C[i,k] = sum_j A[i,j] * B[j,k]
</pre> <p>The corresponding einsum <code translate="no" dir="ltr">equation</code> is:</p> <pre class="prettyprint" translate="no" dir="ltr" data-language="cpp">ij,jk-&gt;ik
</pre> <p>In general, to convert the element-wise equation into the <code translate="no" dir="ltr">equation</code> string, use the following procedure (intermediate strings for matrix multiplication example provided in parentheses):</p> <ol> <li>remove variable names, brackets, and commas, (<code translate="no" dir="ltr">ik = sum_j ij * jk</code>)</li> <li>replace "*" with ",", (<code translate="no" dir="ltr">ik = sum_j ij , jk</code>)</li> <li>drop summation signs, and (<code translate="no" dir="ltr">ik = ij, jk</code>)</li> <li>move the output to the right, while replacing "=" with "-&gt;". (<code translate="no" dir="ltr">ij,jk-&gt;ik</code>)</li> </ol> <blockquote class="note">
<strong>Note:</strong><span> If the output indices are not specified repeated indices are summed. So <code translate="no" dir="ltr">ij,jk-&gt;ik</code> can be simplified to <code translate="no" dir="ltr">ij,jk</code>.</span>
</blockquote> <p>Many common operations can be expressed in this way. For example:</p> <p><strong>Matrix multiplication</strong></p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
m0 = tf.random.normal(shape=[2, 3])
m1 = tf.random.normal(shape=[3, 5])
e = tf.einsum('ij,jk-&gt;ik', m0, m1)
# output[i,k] = sum_j m0[i,j] * m1[j, k]
print(e.shape)
(2, 5)
</pre> <p>Repeated indices are summed if the output indices are not specified.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
e = tf.einsum('ij,jk', m0, m1)  # output[i,k] = sum_j m0[i,j] * m1[j, k]
print(e.shape)
(2, 5)
</pre> <p><strong>Dot product</strong></p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
u = tf.random.normal(shape=[5])
v = tf.random.normal(shape=[5])
e = tf.einsum('i,i-&gt;', u, v)  # output = sum_i u[i]*v[i]
print(e.shape)
()
</pre> <p><strong>Outer product</strong></p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
u = tf.random.normal(shape=[3])
v = tf.random.normal(shape=[5])
e = tf.einsum('i,j-&gt;ij', u, v)  # output[i,j] = u[i]*v[j]
print(e.shape)
(3, 5)
</pre> <p><strong>Transpose</strong></p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
m = tf.ones(2,3)
e = tf.einsum('ij-&gt;ji', m0)  # output[j,i] = m0[i,j]
print(e.shape)
(3, 2)
</pre> <p><strong>Diag</strong></p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
m = tf.reshape(tf.range(9), [3,3])
diag = tf.einsum('ii-&gt;i', m)
print(diag.shape)
(3,)
</pre> <p><strong>Trace</strong></p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# Repeated indices are summed.
trace = tf.einsum('ii', m)  # output[j,i] = trace(m) = sum_i m[i, i]
assert trace == sum(diag)
print(trace.shape)
()
</pre> <p><strong>Batch matrix multiplication</strong></p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
s = tf.random.normal(shape=[7,5,3])
t = tf.random.normal(shape=[7,3,2])
e = tf.einsum('bij,bjk-&gt;bik', s, t)
# output[a,i,k] = sum_j s[a,i,j] * t[a, j, k]
print(e.shape)
(7, 5, 2)
</pre> <p>This method does not support broadcasting on named-axes. All axes with matching labels should have the same length. If you have length-1 axes, use <code translate="no" dir="ltr">tf.squeseze</code> or <a href="reshape"><code translate="no" dir="ltr">tf.reshape</code></a> to eliminate them.</p> <p>To write code that is agnostic to the number of indices in the input use an ellipsis. The ellipsis is a placeholder for "whatever other indices fit here".</p> <p>For example, to perform a NumPy-style broadcasting-batch-matrix multiplication where the matrix multiply acts on the last two axes of the input, use:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
s = tf.random.normal(shape=[11, 7, 5, 3])
t = tf.random.normal(shape=[11, 7, 3, 2])
e =  tf.einsum('...ij,...jk-&gt;...ik', s, t)
print(e.shape)
(11, 7, 5, 2)
</pre> <p>Einsum <strong>will</strong> broadcast over axes covered by the ellipsis.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
s = tf.random.normal(shape=[11, 1, 5, 3])
t = tf.random.normal(shape=[1, 7, 3, 2])
e =  tf.einsum('...ij,...jk-&gt;...ik', s, t)
print(e.shape)
(11, 7, 5, 2)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">equation</code> </td> <td> a <code translate="no" dir="ltr">str</code> describing the contraction, in the same format as <code translate="no" dir="ltr">numpy.einsum</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">*inputs</code> </td> <td> the inputs to contract (each one a <code translate="no" dir="ltr">Tensor</code>), whose shapes should be consistent with <code translate="no" dir="ltr">equation</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">**kwargs</code> </td> <td> <ul> <li>optimize: Optimization strategy to use to find contraction path using opt_einsum. Must be 'greedy', 'optimal', 'branch-2', 'branch-all' or 'auto'. (optional, default: 'greedy').</li> <li>name: A name for the operation (optional). </li>
</ul>
</td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The contracted <code translate="no" dir="ltr">Tensor</code>, with shape determined by <code translate="no" dir="ltr">equation</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> If <ul> <li>the format of <code translate="no" dir="ltr">equation</code> is incorrect,</li> <li>number of inputs or their shapes are inconsistent with <code translate="no" dir="ltr">equation</code>. </li>
</ul>
</td> </tr> </table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/einsum" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/einsum</a>
  </p>
</div>
