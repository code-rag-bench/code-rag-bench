<h1 class="devsite-page-title">tf.keras.layers.LocallyConnected1D</h1>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/layers/local.py#L39-L338">  View source on GitHub </a> </td> </table> <p>Locally-connected layer for 1D inputs.</p> <p>Inherits From: <a href="layer"><code translate="no" dir="ltr">Layer</code></a>, <a href="../../module"><code translate="no" dir="ltr">Module</code></a></p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LocallyConnected1D"><code translate="no" dir="ltr">tf.compat.v1.keras.layers.LocallyConnected1D</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.layers.LocallyConnected1D(
    filters, kernel_size, strides=1, padding='valid', data_format=None,
    activation=None, use_bias=True, kernel_initializer='glorot_uniform',
    bias_initializer='zeros', kernel_regularizer=None,
    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,
    bias_constraint=None, implementation=1, **kwargs
)
</pre>  <p>The <code translate="no" dir="ltr">LocallyConnected1D</code> layer works similarly to the <code translate="no" dir="ltr">Conv1D</code> layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.</p> <blockquote class="note">
<strong>Note:</strong><span> layer attributes cannot be modified after the layer has been called once (except the <code translate="no" dir="ltr">trainable</code> attribute).</span>
</blockquote> <h4 id="example" data-text="Example:">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python"># apply a unshared weight convolution 1d of length 3 to a sequence with
# 10 timesteps, with 64 output filters
model = Sequential()
model.add(LocallyConnected1D(64, 3, input_shape=(10, 32)))
# now model.output_shape == (None, 8, 64)
# add a new conv1d on top
model.add(LocallyConnected1D(32, 3))
# now model.output_shape == (None, 6, 32)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Arguments</th></tr> 
<tr> <td> <code translate="no" dir="ltr">filters</code> </td> <td> Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">kernel_size</code> </td> <td> An integer or tuple/list of a single integer, specifying the length of the 1D convolution window. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">strides</code> </td> <td> An integer or tuple/list of a single integer, specifying the stride length of the convolution. Specifying any stride value != 1 is incompatible with specifying any <code translate="no" dir="ltr">dilation_rate</code> value != 1. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">padding</code> </td> <td> Currently only supports <code translate="no" dir="ltr">"valid"</code> (case-insensitive). <code translate="no" dir="ltr">"same"</code> may be supported in the future. <code translate="no" dir="ltr">"valid"</code> means no padding. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">data_format</code> </td> <td> A string, one of <code translate="no" dir="ltr">channels_last</code> (default) or <code translate="no" dir="ltr">channels_first</code>. The ordering of the dimensions in the inputs. <code translate="no" dir="ltr">channels_last</code> corresponds to inputs with shape <code translate="no" dir="ltr">(batch, length, channels)</code> while <code translate="no" dir="ltr">channels_first</code> corresponds to inputs with shape <code translate="no" dir="ltr">(batch, channels, length)</code>. It defaults to the <code translate="no" dir="ltr">image_data_format</code> value found in your Keras config file at <code translate="no" dir="ltr">~/.keras/keras.json</code>. If you never set it, then it will be "channels_last". </td> </tr>
<tr> <td> <code translate="no" dir="ltr">activation</code> </td> <td> Activation function to use. If you don't specify anything, no activation is applied (ie. "linear" activation: <code translate="no" dir="ltr">a(x) = x</code>). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_bias</code> </td> <td> Boolean, whether the layer uses a bias vector. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">kernel_initializer</code> </td> <td> Initializer for the <code translate="no" dir="ltr">kernel</code> weights matrix. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bias_initializer</code> </td> <td> Initializer for the bias vector. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">kernel_regularizer</code> </td> <td> Regularizer function applied to the <code translate="no" dir="ltr">kernel</code> weights matrix. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bias_regularizer</code> </td> <td> Regularizer function applied to the bias vector. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">activity_regularizer</code> </td> <td> Regularizer function applied to the output of the layer (its "activation").. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">kernel_constraint</code> </td> <td> Constraint function applied to the kernel matrix. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bias_constraint</code> </td> <td> Constraint function applied to the bias vector. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">implementation</code> </td> <td> implementation mode, either <code translate="no" dir="ltr">1</code>, <code translate="no" dir="ltr">2</code>, or <code translate="no" dir="ltr">3</code>. <code translate="no" dir="ltr">1</code> loops over input spatial locations to perform the forward pass. It is memory-efficient but performs a lot of (small) ops. <p><code translate="no" dir="ltr">2</code> stores layer weights in a dense but sparsely-populated 2D matrix and implements the forward pass as a single matrix-multiply. It uses a lot of RAM but performs few (large) ops.</p> <p><code translate="no" dir="ltr">3</code> stores layer weights in a sparse tensor and implements the forward pass as a single sparse matrix-multiply.</p> <p>How to choose:</p> <p><code translate="no" dir="ltr">1</code>: large, dense models, <code translate="no" dir="ltr">2</code>: small models, <code translate="no" dir="ltr">3</code>: large, sparse models,</p> <p>where "large" stands for large input/output activations (i.e. many <code translate="no" dir="ltr">filters</code>, <code translate="no" dir="ltr">input_filters</code>, large <code translate="no" dir="ltr">input_size</code>, <code translate="no" dir="ltr">output_size</code>), and "sparse" stands for few connections between inputs and outputs, i.e. small ratio <code translate="no" dir="ltr">filters * input_filters * kernel_size / (input_size * strides)</code>, where inputs to and outputs of the layer are assumed to have shapes <code translate="no" dir="ltr">(input_size, input_filters)</code>, <code translate="no" dir="ltr">(output_size, filters)</code> respectively.</p> <p>It is recommended to benchmark each in the setting of interest to pick the most efficient one (in terms of speed and memory usage). Correct choice of implementation can lead to dramatic speed improvements (e.g. 50X), potentially at the expense of RAM.</p> <p>Also, only <code translate="no" dir="ltr">padding="valid"</code> is supported by <code translate="no" dir="ltr">implementation=1</code>. </p>
</td> </tr> </table> <h4 id="input_shape" data-text="Input shape:">Input shape:</h4> <p>3D tensor with shape: <code translate="no" dir="ltr">(batch_size, steps, input_dim)</code></p> <h4 id="output_shape" data-text="Output shape:">Output shape:</h4> <p>3D tensor with shape: <code translate="no" dir="ltr">(batch_size, new_steps, filters)</code> <code translate="no" dir="ltr">steps</code> value might have changed due to padding or strides.</p>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/layers/LocallyConnected1D" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/layers/LocallyConnected1D</a>
  </p>
</div>
