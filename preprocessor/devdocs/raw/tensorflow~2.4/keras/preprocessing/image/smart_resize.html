<h1 class="devsite-page-title">tf.keras.preprocessing.image.smart_resize</h1>       <p>Resize images to a target size without aspect ratio distortion.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.preprocessing.image.smart_resize(
    x, size, interpolation='bilinear'
)
</pre>  <p>TensorFlow image datasets typically yield images that have each a different size. However, these images need to be batched before they can be processed by Keras layers. To be batched, images need to share the same height and width.</p> <h4 id="you_could_simply_do" data-text="You could simply do:">You could simply do:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">size = (200, 200)
ds = ds.map(lambda img: tf.image.resize(img, size))
```

However, if you do this, you distort the aspect ratio of your images, since
in general they do not all have the same aspect ratio as `size`. This is
fine in many cases, but not always (e.g. for GANs this can be a problem).

Note that passing the argument `preserve_aspect_ratio=True` to `resize`
will preserve the aspect ratio, but at the cost of no longer respecting the
provided target size. Because &lt;a href="../../../../tf/image/resize"&gt;&lt;code&gt;tf.image.resize&lt;/code&gt;&lt;/a&gt; doesn't crop images,
your output images will still have different sizes.

#### This calls for:



```python
size = (200, 200)
ds = ds.map(lambda img: smart_resize(img, size))
```

Your output images will actually be `(200, 200)`, and will not be distorted.
Instead, the parts of the image that do not fit within the target size
get cropped out.

The resizing process is:

1. Take the largest centered crop of the image that has the same aspect ratio
as the target size. For instance, if `size=(200, 200)` and the input image has
size `(340, 500)`, we take a crop of `(340, 340)` centered along the width.
2. Resize the cropped image to the target size. In the example above,
we resize the `(340, 340)` crop to `(200, 200)`.

&lt;!-- Tabular view --&gt;
 &lt;table class="responsive fixed orange"&gt;
&lt;colgroup&gt;&lt;col width="214px"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tr&gt;&lt;th colspan="2"&gt;&lt;h2 class="add-link"&gt;Arguments&lt;/h2&gt;&lt;/th&gt;&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;
`x`
&lt;/td&gt;
&lt;td&gt;
Input image (as a tensor or NumPy array). Must be in format
`(height, width, channels)`.
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;
&lt;td&gt;
`size`
&lt;/td&gt;
&lt;td&gt;
Tuple of `(height, width)` integer. Target size.
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;
&lt;td&gt;
`interpolation`
&lt;/td&gt;
&lt;td&gt;
String, interpolation to use for resizing.
Defaults to `'bilinear'`. Supports `bilinear`, `nearest`, `bicubic`,
`area`, `lanczos3`, `lanczos5`, `gaussian`, `mitchellcubic`.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;



&lt;!-- Tabular view --&gt;
 &lt;table class="responsive fixed orange"&gt;
&lt;colgroup&gt;&lt;col width="214px"&gt;&lt;col&gt;&lt;/colgroup&gt;
&lt;tr&gt;&lt;th colspan="2"&gt;&lt;h2 class="add-link"&gt;Returns&lt;/h2&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;tr class="alt"&gt;
&lt;td colspan="2"&gt;
Array with shape `(size[0], size[1], channels)`. If the input image was a
NumPy array, the output is a NumPy array, and if it was a TF tensor,
the output is a TF tensor.
&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;
</pre>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/preprocessing/image/smart_resize" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/preprocessing/image/smart_resize</a>
  </p>
</div>
