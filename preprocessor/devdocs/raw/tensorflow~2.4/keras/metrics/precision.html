<h1 class="devsite-page-title">tf.keras.metrics.Precision</h1>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/metrics.py#L1176-L1310">  View source on GitHub </a> </td> </table> <p>Computes the precision of the predictions with respect to the labels.</p> <p>Inherits From: <a href="metric"><code translate="no" dir="ltr">Metric</code></a>, <a href="../layers/layer"><code translate="no" dir="ltr">Layer</code></a>, <a href="../../module"><code translate="no" dir="ltr">Module</code></a></p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Main aliases</b> </p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision"><code translate="no" dir="ltr">tf.metrics.Precision</code></a></p> <b>Compat aliases for migration</b> <p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Precision"><code translate="no" dir="ltr">tf.compat.v1.keras.metrics.Precision</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.keras.metrics.Precision(
    thresholds=None, top_k=None, class_id=None, name=None, dtype=None
)
</pre>  <p>The metric creates two local variables, <code translate="no" dir="ltr">true_positives</code> and <code translate="no" dir="ltr">false_positives</code> that are used to compute the precision. This value is ultimately returned as <code translate="no" dir="ltr">precision</code>, an idempotent operation that simply divides <code translate="no" dir="ltr">true_positives</code> by the sum of <code translate="no" dir="ltr">true_positives</code> and <code translate="no" dir="ltr">false_positives</code>.</p> <p>If <code translate="no" dir="ltr">sample_weight</code> is <code translate="no" dir="ltr">None</code>, weights default to 1. Use <code translate="no" dir="ltr">sample_weight</code> of 0 to mask values.</p> <p>If <code translate="no" dir="ltr">top_k</code> is set, we'll calculate precision as how often on average a class among the top-k classes with the highest predicted values of a batch entry is correct and can be found in the label for that entry.</p> <p>If <code translate="no" dir="ltr">class_id</code> is specified, we calculate precision by considering only the entries in the batch for which <code translate="no" dir="ltr">class_id</code> is above the threshold and/or in the top-k highest predictions, and computing the fraction of them for which <code translate="no" dir="ltr">class_id</code> is indeed a correct label.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">thresholds</code> </td> <td> (Optional) A float value or a python list/tuple of float threshold values in [0, 1]. A threshold is compared with prediction values to determine the truth value of predictions (i.e., above the threshold is <code translate="no" dir="ltr">true</code>, below is <code translate="no" dir="ltr">false</code>). One metric value is generated for each threshold value. If neither thresholds nor top_k are set, the default is to calculate precision with <code translate="no" dir="ltr">thresholds=0.5</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">top_k</code> </td> <td> (Optional) Unset by default. An int value specifying the top-k predictions to consider when calculating precision. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">class_id</code> </td> <td> (Optional) Integer class ID for which we want binary metrics. This must be in the half-open interval <code translate="no" dir="ltr">[0, num_classes)</code>, where <code translate="no" dir="ltr">num_classes</code> is the last dimension of predictions. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> (Optional) string name of the metric instance. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> (Optional) data type of the metric result. </td> </tr> </table> <h4 id="standalone_usage" data-text="Standalone usage:">Standalone usage:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
m = tf.keras.metrics.Precision()
m.update_state([0, 1, 1, 1], [1, 0, 1, 1])
m.result().numpy()
0.6666667
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
m.reset_states()
m.update_state([0, 1, 1, 1], [1, 0, 1, 1], sample_weight=[0, 0, 1, 0])
m.result().numpy()
1.0
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# With top_k=2, it will calculate precision over y_true[:2] and y_pred[:2]
m = tf.keras.metrics.Precision(top_k=2)
m.update_state([0, 0, 1, 1], [1, 1, 1, 1])
m.result().numpy()
0.0
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
# With top_k=4, it will calculate precision over y_true[:4] and y_pred[:4]
m = tf.keras.metrics.Precision(top_k=4)
m.update_state([0, 0, 1, 1], [1, 1, 1, 1])
m.result().numpy()
0.5
</pre> <p>Usage with <code translate="no" dir="ltr">compile()</code> API:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">model.compile(optimizer='sgd',
              loss='mse',
              metrics=[tf.keras.metrics.Precision()])
</pre> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="reset_states" data-text="reset_states"><code translate="no" dir="ltr">reset_states</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/metrics.py#L1298-L1301">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
reset_states()
</pre> <p>Resets all of the metric state variables.</p> <p>This function is called between epochs/steps, when a metric is evaluated during training.</p> <h3 id="result" data-text="result"><code translate="no" dir="ltr">result</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/metrics.py#L1293-L1296">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
result()
</pre> <p>Computes and returns the metric value tensor.</p> <p>Result computation is an idempotent operation that simply calculates the metric value using the state variables.</p> <h3 id="update_state" data-text="update_state"><code translate="no" dir="ltr">update_state</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/keras/metrics.py#L1267-L1291">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
update_state(
    y_true, y_pred, sample_weight=None
)
</pre> <p>Accumulates true positive and false positive statistics.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">y_true</code> </td> <td> The ground truth values, with the same dimensions as <code translate="no" dir="ltr">y_pred</code>. Will be cast to <code translate="no" dir="ltr">bool</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">y_pred</code> </td> <td> The predicted values. Each element must be in the range <code translate="no" dir="ltr">[0, 1]</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sample_weight</code> </td> <td> Optional weighting of each example. Defaults to 1. Can be a <code translate="no" dir="ltr">Tensor</code> whose rank is either 0, or the same rank as <code translate="no" dir="ltr">y_true</code>, and must be broadcastable to <code translate="no" dir="ltr">y_true</code>. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> Update op. </td> </tr> 
</table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/metrics/Precision" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/metrics/Precision</a>
  </p>
</div>
