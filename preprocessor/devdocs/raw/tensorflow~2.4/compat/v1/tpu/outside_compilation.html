<h1 class="devsite-page-title">tf.compat.v1.tpu.outside_compilation</h1>       <p>Builds part of a computation outside any current TPU replicate scope.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.compat.v1.tpu.outside_compilation(
    computation, *args, **kwargs
)
</pre>  <p><code translate="no" dir="ltr">tf.tpu.outside_compilation()</code> is used to run ops in <code translate="no" dir="ltr">computation</code> on CPU instead of running on TPU. For example, users can run ops that are not supported on TPU's (e.g. tf.summary.write()) by explicitly placing those ops on CPU's. Below usage of outside compilation will place ops in <code translate="no" dir="ltr">computation_with_string_ops</code> on CPU.</p> <h4 id="example_usage" data-text="Example usage:">Example usage:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">def computation_with_string_ops(x):
  # strings types are not supported on TPU's and below ops must
  # run on CPU instead.
  output = tf.strings.format('1{}', x)
  return tf.strings.to_number(output)

def tpu_computation():
  # Expected output is 11.
  output = tf.tpu.outside_compilation(computation_with_string_ops, 1)
</pre> <p>Outside compilation should be called inside TPUReplicateContext. That is, <code translate="no" dir="ltr">tf.tpu.outside_compilation()</code> should be called inside a function that is passed to <code translate="no" dir="ltr">tpu.split_compile_and_replicate()</code> -- this is implied when outside compilation is invoked inside a function passed to TPUStrategy <code translate="no" dir="ltr">run()</code>. If invoked outside of TPUReplicateContext, then this simply returns the result of <code translate="no" dir="ltr">computation</code>, and therefore, would be a no-op. Note that outside compilation is different from <code translate="no" dir="ltr">tf.distribute.experimental.TPUStrategy.merge_call()</code> as logic in outside compilation is replicated and executed separately for each replica. On the other hand, <code translate="no" dir="ltr">merge_call()</code> requires a <code translate="no" dir="ltr">merge_fn</code> to aggregate the inputs from different replicas and is executed only once.</p> <p>For variables placed in TPU device, which includes variables created inside TPUStrategy scope, outside compilation logic must not include variable read/write. For variables placed on host, which is the case when variables created via TPUEstimator, variable read/write is only allowed if the variable is not accessed by any other ops in the TPU computation. Variable read/write from outside compilation cluster is not visible from TPU computation and vice versa. Therefore, if outside compilation logic contains such host variables read/write ops and if the variables are accessed by TPU computation as well, then this may lead to deadlock.</p> <p>Internally, <code translate="no" dir="ltr">tf.tpu.outside_compilation()</code> adds outside compilation attributes to all ops in <code translate="no" dir="ltr">computation</code>. During later graph pass, these ops with outside compilation attribute is extracted out and replicated into a host-side graph. Inputs to this extract host-side graph is sent from TPU computation graph to host graph via a pair of XlaSendToHost and XlaRecvFromHost ops. Note that using <code translate="no" dir="ltr">tf.tpu.outside_compilation()</code> may result in tensor transfer between TPU and CPU, leading to non-trivial performance impact.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">computation</code> </td> <td> A Python function that builds the computation to place on the host. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">*args</code> </td> <td> the positional arguments for the computation. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">**kwargs</code> </td> <td> the keyword arguments for the computation. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The Tensors returned by computation. </td> </tr> 
</table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/compat/v1/tpu/outside_compilation" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/compat/v1/tpu/outside_compilation</a>
  </p>
</div>
