<h1 class="devsite-page-title">Module: tf.compat.v1.raw_ops</h1>   <p><devsite-mathjax config="TeX-AMS-MML_SVG"></devsite-mathjax> </p>    <p>Public API for tf.raw_ops namespace.</p> <h2 id="functions" data-text="Functions">Functions</h2> <p><a href="../../raw_ops/abort"><code translate="no" dir="ltr">Abort(...)</code></a>: Raise a exception to abort the process when called.</p> <p><a href="../../raw_ops/abs"><code translate="no" dir="ltr">Abs(...)</code></a>: Computes the absolute value of a tensor.</p> <p><a href="../../raw_ops/accumulatenv2"><code translate="no" dir="ltr">AccumulateNV2(...)</code></a>: Returns the element-wise sum of a list of tensors.</p> <p><a href="../../raw_ops/accumulatorapplygradient"><code translate="no" dir="ltr">AccumulatorApplyGradient(...)</code></a>: Applies a gradient to a given accumulator.</p> <p><a href="../../raw_ops/accumulatornumaccumulated"><code translate="no" dir="ltr">AccumulatorNumAccumulated(...)</code></a>: Returns the number of gradients aggregated in the given accumulators.</p> <p><a href="../../raw_ops/accumulatorsetglobalstep"><code translate="no" dir="ltr">AccumulatorSetGlobalStep(...)</code></a>: Updates the accumulator with a new value for global_step.</p> <p><a href="../../raw_ops/accumulatortakegradient"><code translate="no" dir="ltr">AccumulatorTakeGradient(...)</code></a>: Extracts the average gradient in the given ConditionalAccumulator.</p> <p><a href="../../raw_ops/acos"><code translate="no" dir="ltr">Acos(...)</code></a>: Computes acos of x element-wise.</p> <p><a href="../../raw_ops/acosh"><code translate="no" dir="ltr">Acosh(...)</code></a>: Computes inverse hyperbolic cosine of x element-wise.</p> <p><a href="../../raw_ops/add"><code translate="no" dir="ltr">Add(...)</code></a>: Returns x + y element-wise.</p> <p><a href="../../raw_ops/addmanysparsetotensorsmap"><code translate="no" dir="ltr">AddManySparseToTensorsMap(...)</code></a>: Add an <code translate="no" dir="ltr">N</code>-minibatch <code translate="no" dir="ltr">SparseTensor</code> to a <code translate="no" dir="ltr">SparseTensorsMap</code>, return <code translate="no" dir="ltr">N</code> handles.</p> <p><a href="../../raw_ops/addn"><code translate="no" dir="ltr">AddN(...)</code></a>: Add all input tensors element wise.</p> <p><a href="../../raw_ops/addsparsetotensorsmap"><code translate="no" dir="ltr">AddSparseToTensorsMap(...)</code></a>: Add a <code translate="no" dir="ltr">SparseTensor</code> to a <code translate="no" dir="ltr">SparseTensorsMap</code> return its handle.</p> <p><a href="../../raw_ops/addv2"><code translate="no" dir="ltr">AddV2(...)</code></a>: Returns x + y element-wise.</p> <p><a href="../../raw_ops/adjustcontrast"><code translate="no" dir="ltr">AdjustContrast(...)</code></a>: Deprecated. Disallowed in GraphDef version &gt;= 2.</p> <p><a href="../../raw_ops/adjustcontrastv2"><code translate="no" dir="ltr">AdjustContrastv2(...)</code></a>: Adjust the contrast of one or more images.</p> <p><a href="../../raw_ops/adjusthue"><code translate="no" dir="ltr">AdjustHue(...)</code></a>: Adjust the hue of one or more images.</p> <p><a href="../../raw_ops/adjustsaturation"><code translate="no" dir="ltr">AdjustSaturation(...)</code></a>: Adjust the saturation of one or more images.</p> <p><a href="../../raw_ops/all"><code translate="no" dir="ltr">All(...)</code></a>: Computes the "logical and" of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/allcandidatesampler"><code translate="no" dir="ltr">AllCandidateSampler(...)</code></a>: Generates labels for candidate sampling with a learned unigram distribution.</p> <p><a href="../../raw_ops/alltoall"><code translate="no" dir="ltr">AllToAll(...)</code></a>: An Op to exchange data across TPU replicas.</p> <p><a href="../../raw_ops/angle"><code translate="no" dir="ltr">Angle(...)</code></a>: Returns the argument of a complex number.</p> <p><a href="../../raw_ops/anonymousiterator"><code translate="no" dir="ltr">AnonymousIterator(...)</code></a>: A container for an iterator resource.</p> <p><a href="../../raw_ops/anonymousiteratorv2"><code translate="no" dir="ltr">AnonymousIteratorV2(...)</code></a>: A container for an iterator resource.</p> <p><a href="../../raw_ops/anonymousmemorycache"><code translate="no" dir="ltr">AnonymousMemoryCache(...)</code></a></p> <p><a href="../../raw_ops/anonymousmultideviceiterator"><code translate="no" dir="ltr">AnonymousMultiDeviceIterator(...)</code></a>: A container for a multi device iterator resource.</p> <p><a href="../../raw_ops/anonymousrandomseedgenerator"><code translate="no" dir="ltr">AnonymousRandomSeedGenerator(...)</code></a></p> <p><a href="../../raw_ops/anonymousseedgenerator"><code translate="no" dir="ltr">AnonymousSeedGenerator(...)</code></a></p> <p><a href="../../raw_ops/any"><code translate="no" dir="ltr">Any(...)</code></a>: Computes the "logical or" of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/applyadamax"><code translate="no" dir="ltr">ApplyAdaMax(...)</code></a>: Update '*var' according to the AdaMax algorithm.</p> <p><a href="../../raw_ops/applyadadelta"><code translate="no" dir="ltr">ApplyAdadelta(...)</code></a>: Update '*var' according to the adadelta scheme.</p> <p><a href="../../raw_ops/applyadagrad"><code translate="no" dir="ltr">ApplyAdagrad(...)</code></a>: Update '*var' according to the adagrad scheme.</p> <p><a href="../../raw_ops/applyadagradda"><code translate="no" dir="ltr">ApplyAdagradDA(...)</code></a>: Update '*var' according to the proximal adagrad scheme.</p> <p><a href="../../raw_ops/applyadagradv2"><code translate="no" dir="ltr">ApplyAdagradV2(...)</code></a>: Update '*var' according to the adagrad scheme.</p> <p><a href="../../raw_ops/applyadam"><code translate="no" dir="ltr">ApplyAdam(...)</code></a>: Update '*var' according to the Adam algorithm.</p> <p><a href="../../raw_ops/applyaddsign"><code translate="no" dir="ltr">ApplyAddSign(...)</code></a>: Update '*var' according to the AddSign update.</p> <p><a href="../../raw_ops/applycenteredrmsprop"><code translate="no" dir="ltr">ApplyCenteredRMSProp(...)</code></a>: Update '*var' according to the centered RMSProp algorithm.</p> <p><a href="../../raw_ops/applyftrl"><code translate="no" dir="ltr">ApplyFtrl(...)</code></a>: Update '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/applyftrlv2"><code translate="no" dir="ltr">ApplyFtrlV2(...)</code></a>: Update '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/applygradientdescent"><code translate="no" dir="ltr">ApplyGradientDescent(...)</code></a>: Update '*var' by subtracting 'alpha' * 'delta' from it.</p> <p><a href="../../raw_ops/applymomentum"><code translate="no" dir="ltr">ApplyMomentum(...)</code></a>: Update '*var' according to the momentum scheme.</p> <p><a href="../../raw_ops/applypowersign"><code translate="no" dir="ltr">ApplyPowerSign(...)</code></a>: Update '*var' according to the AddSign update.</p> <p><a href="../../raw_ops/applyproximaladagrad"><code translate="no" dir="ltr">ApplyProximalAdagrad(...)</code></a>: Update '<em>var' and '</em>accum' according to FOBOS with Adagrad learning rate.</p> <p><a href="../../raw_ops/applyproximalgradientdescent"><code translate="no" dir="ltr">ApplyProximalGradientDescent(...)</code></a>: Update '*var' as FOBOS algorithm with fixed learning rate.</p> <p><a href="../../raw_ops/applyrmsprop"><code translate="no" dir="ltr">ApplyRMSProp(...)</code></a>: Update '*var' according to the RMSProp algorithm.</p> <p><a href="../../raw_ops/approximateequal"><code translate="no" dir="ltr">ApproximateEqual(...)</code></a>: Returns the truth value of abs(x-y) &lt; tolerance element-wise.</p> <p><a href="../../raw_ops/argmax"><code translate="no" dir="ltr">ArgMax(...)</code></a>: Returns the index with the largest value across dimensions of a tensor.</p> <p><a href="../../raw_ops/argmin"><code translate="no" dir="ltr">ArgMin(...)</code></a>: Returns the index with the smallest value across dimensions of a tensor.</p> <p><a href="../../raw_ops/asstring"><code translate="no" dir="ltr">AsString(...)</code></a>: Converts each entry in the given tensor to strings.</p> <p><a href="../../raw_ops/asin"><code translate="no" dir="ltr">Asin(...)</code></a>: Computes the trignometric inverse sine of x element-wise.</p> <p><a href="../../raw_ops/asinh"><code translate="no" dir="ltr">Asinh(...)</code></a>: Computes inverse hyperbolic sine of x element-wise.</p> <p><a href="../../raw_ops/assert"><code translate="no" dir="ltr">Assert(...)</code></a>: Asserts that the given condition is true.</p> <p><a href="../../raw_ops/assertcardinalitydataset"><code translate="no" dir="ltr">AssertCardinalityDataset(...)</code></a></p> <p><a href="../../raw_ops/assertnextdataset"><code translate="no" dir="ltr">AssertNextDataset(...)</code></a>: A transformation that asserts which transformations happen next.</p> <p><a href="../../raw_ops/assign"><code translate="no" dir="ltr">Assign(...)</code></a>: Update 'ref' by assigning 'value' to it.</p> <p><a href="../../raw_ops/assignadd"><code translate="no" dir="ltr">AssignAdd(...)</code></a>: Update 'ref' by adding 'value' to it.</p> <p><a href="../../raw_ops/assignaddvariableop"><code translate="no" dir="ltr">AssignAddVariableOp(...)</code></a>: Adds a value to the current value of a variable.</p> <p><a href="../../raw_ops/assignsub"><code translate="no" dir="ltr">AssignSub(...)</code></a>: Update 'ref' by subtracting 'value' from it.</p> <p><a href="../../raw_ops/assignsubvariableop"><code translate="no" dir="ltr">AssignSubVariableOp(...)</code></a>: Subtracts a value from the current value of a variable.</p> <p><a href="../../raw_ops/assignvariableop"><code translate="no" dir="ltr">AssignVariableOp(...)</code></a>: Assigns a new value to a variable.</p> <p><a href="../../raw_ops/atan"><code translate="no" dir="ltr">Atan(...)</code></a>: Computes the trignometric inverse tangent of x element-wise.</p> <p><a href="../../raw_ops/atan2"><code translate="no" dir="ltr">Atan2(...)</code></a>: Computes arctangent of <code translate="no" dir="ltr">y/x</code> element-wise, respecting signs of the arguments.</p> <p><a href="../../raw_ops/atanh"><code translate="no" dir="ltr">Atanh(...)</code></a>: Computes inverse hyperbolic tangent of x element-wise.</p> <p><a href="../../raw_ops/audiospectrogram"><code translate="no" dir="ltr">AudioSpectrogram(...)</code></a>: Produces a visualization of audio data over time.</p> <p><a href="../../raw_ops/audiosummary"><code translate="no" dir="ltr">AudioSummary(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with audio.</p> <p><a href="../../raw_ops/audiosummaryv2"><code translate="no" dir="ltr">AudioSummaryV2(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with audio.</p> <p><a href="../../raw_ops/autosharddataset"><code translate="no" dir="ltr">AutoShardDataset(...)</code></a>: Creates a dataset that shards the input dataset.</p> <p><a href="../../raw_ops/avgpool"><code translate="no" dir="ltr">AvgPool(...)</code></a>: Performs average pooling on the input.</p> <p><a href="../../raw_ops/avgpool3d"><code translate="no" dir="ltr">AvgPool3D(...)</code></a>: Performs 3D average pooling on the input.</p> <p><a href="../../raw_ops/avgpool3dgrad"><code translate="no" dir="ltr">AvgPool3DGrad(...)</code></a>: Computes gradients of average pooling function.</p> <p><a href="../../raw_ops/avgpoolgrad"><code translate="no" dir="ltr">AvgPoolGrad(...)</code></a>: Computes gradients of the average pooling function.</p> <p><a href="../../raw_ops/bandedtriangularsolve"><code translate="no" dir="ltr">BandedTriangularSolve(...)</code></a></p> <p><a href="../../raw_ops/barrier"><code translate="no" dir="ltr">Barrier(...)</code></a>: Defines a barrier that persists across different graph executions.</p> <p><a href="../../raw_ops/barrierclose"><code translate="no" dir="ltr">BarrierClose(...)</code></a>: Closes the given barrier.</p> <p><a href="../../raw_ops/barrierincompletesize"><code translate="no" dir="ltr">BarrierIncompleteSize(...)</code></a>: Computes the number of incomplete elements in the given barrier.</p> <p><a href="../../raw_ops/barrierinsertmany"><code translate="no" dir="ltr">BarrierInsertMany(...)</code></a>: For each key, assigns the respective value to the specified component.</p> <p><a href="../../raw_ops/barrierreadysize"><code translate="no" dir="ltr">BarrierReadySize(...)</code></a>: Computes the number of complete elements in the given barrier.</p> <p><a href="../../raw_ops/barriertakemany"><code translate="no" dir="ltr">BarrierTakeMany(...)</code></a>: Takes the given number of completed elements from a barrier.</p> <p><a href="../../raw_ops/batch"><code translate="no" dir="ltr">Batch(...)</code></a>: Batches all input tensors nondeterministically.</p> <p><a href="../../raw_ops/batchcholesky"><code translate="no" dir="ltr">BatchCholesky(...)</code></a></p> <p><a href="../../raw_ops/batchcholeskygrad"><code translate="no" dir="ltr">BatchCholeskyGrad(...)</code></a></p> <p><a href="../../raw_ops/batchdataset"><code translate="no" dir="ltr">BatchDataset(...)</code></a>: Creates a dataset that batches <code translate="no" dir="ltr">batch_size</code> elements from <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/batchdatasetv2"><code translate="no" dir="ltr">BatchDatasetV2(...)</code></a>: Creates a dataset that batches <code translate="no" dir="ltr">batch_size</code> elements from <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/batchfft"><code translate="no" dir="ltr">BatchFFT(...)</code></a></p> <p><a href="../../raw_ops/batchfft2d"><code translate="no" dir="ltr">BatchFFT2D(...)</code></a></p> <p><a href="../../raw_ops/batchfft3d"><code translate="no" dir="ltr">BatchFFT3D(...)</code></a></p> <p><a href="../../raw_ops/batchfunction"><code translate="no" dir="ltr">BatchFunction(...)</code></a>: Batches all the inputs tensors to the computation done by the function.</p> <p><a href="../../raw_ops/batchifft"><code translate="no" dir="ltr">BatchIFFT(...)</code></a></p> <p><a href="../../raw_ops/batchifft2d"><code translate="no" dir="ltr">BatchIFFT2D(...)</code></a></p> <p><a href="../../raw_ops/batchifft3d"><code translate="no" dir="ltr">BatchIFFT3D(...)</code></a></p> <p><a href="../../raw_ops/batchmatmul"><code translate="no" dir="ltr">BatchMatMul(...)</code></a>: Multiplies slices of two tensors in batches.</p> <p><a href="../../raw_ops/batchmatmulv2"><code translate="no" dir="ltr">BatchMatMulV2(...)</code></a>: Multiplies slices of two tensors in batches.</p> <p><a href="../../raw_ops/batchmatrixbandpart"><code translate="no" dir="ltr">BatchMatrixBandPart(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixdeterminant"><code translate="no" dir="ltr">BatchMatrixDeterminant(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixdiag"><code translate="no" dir="ltr">BatchMatrixDiag(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixdiagpart"><code translate="no" dir="ltr">BatchMatrixDiagPart(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixinverse"><code translate="no" dir="ltr">BatchMatrixInverse(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixsetdiag"><code translate="no" dir="ltr">BatchMatrixSetDiag(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixsolve"><code translate="no" dir="ltr">BatchMatrixSolve(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixsolvels"><code translate="no" dir="ltr">BatchMatrixSolveLs(...)</code></a></p> <p><a href="../../raw_ops/batchmatrixtriangularsolve"><code translate="no" dir="ltr">BatchMatrixTriangularSolve(...)</code></a></p> <p><a href="../../raw_ops/batchnormwithglobalnormalization"><code translate="no" dir="ltr">BatchNormWithGlobalNormalization(...)</code></a>: Batch normalization.</p> <p><a href="../../raw_ops/batchnormwithglobalnormalizationgrad"><code translate="no" dir="ltr">BatchNormWithGlobalNormalizationGrad(...)</code></a>: Gradients for batch normalization.</p> <p><a href="../../raw_ops/batchselfadjointeig"><code translate="no" dir="ltr">BatchSelfAdjointEig(...)</code></a></p> <p><a href="../../raw_ops/batchselfadjointeigv2"><code translate="no" dir="ltr">BatchSelfAdjointEigV2(...)</code></a></p> <p><a href="../../raw_ops/batchsvd"><code translate="no" dir="ltr">BatchSvd(...)</code></a></p> <p><a href="../../raw_ops/batchtospace"><code translate="no" dir="ltr">BatchToSpace(...)</code></a>: BatchToSpace for 4-D tensors of type T.</p> <p><a href="../../raw_ops/batchtospacend"><code translate="no" dir="ltr">BatchToSpaceND(...)</code></a>: BatchToSpace for N-D tensors of type T.</p> <p><a href="../../raw_ops/besseli0"><code translate="no" dir="ltr">BesselI0(...)</code></a></p> <p><a href="../../raw_ops/besseli0e"><code translate="no" dir="ltr">BesselI0e(...)</code></a></p> <p><a href="../../raw_ops/besseli1"><code translate="no" dir="ltr">BesselI1(...)</code></a></p> <p><a href="../../raw_ops/besseli1e"><code translate="no" dir="ltr">BesselI1e(...)</code></a></p> <p><a href="../../raw_ops/besselj0"><code translate="no" dir="ltr">BesselJ0(...)</code></a></p> <p><a href="../../raw_ops/besselj1"><code translate="no" dir="ltr">BesselJ1(...)</code></a></p> <p><a href="../../raw_ops/besselk0"><code translate="no" dir="ltr">BesselK0(...)</code></a></p> <p><a href="../../raw_ops/besselk0e"><code translate="no" dir="ltr">BesselK0e(...)</code></a></p> <p><a href="../../raw_ops/besselk1"><code translate="no" dir="ltr">BesselK1(...)</code></a></p> <p><a href="../../raw_ops/besselk1e"><code translate="no" dir="ltr">BesselK1e(...)</code></a></p> <p><a href="../../raw_ops/bessely0"><code translate="no" dir="ltr">BesselY0(...)</code></a></p> <p><a href="../../raw_ops/bessely1"><code translate="no" dir="ltr">BesselY1(...)</code></a></p> <p><a href="../../raw_ops/betainc"><code translate="no" dir="ltr">Betainc(...)</code></a>: Compute the regularized incomplete beta integral \(I_x(a, b)\).</p> <p><a href="../../raw_ops/biasadd"><code translate="no" dir="ltr">BiasAdd(...)</code></a>: Adds <code translate="no" dir="ltr">bias</code> to <code translate="no" dir="ltr">value</code>.</p> <p><a href="../../raw_ops/biasaddgrad"><code translate="no" dir="ltr">BiasAddGrad(...)</code></a>: The backward operation for "BiasAdd" on the "bias" tensor.</p> <p><a href="../../raw_ops/biasaddv1"><code translate="no" dir="ltr">BiasAddV1(...)</code></a>: Adds <code translate="no" dir="ltr">bias</code> to <code translate="no" dir="ltr">value</code>.</p> <p><a href="../../raw_ops/bincount"><code translate="no" dir="ltr">Bincount(...)</code></a>: Counts the number of occurrences of each value in an integer array.</p> <p><a href="../../raw_ops/bitcast"><code translate="no" dir="ltr">Bitcast(...)</code></a>: Bitcasts a tensor from one type to another without copying data.</p> <p><a href="../../raw_ops/bitwiseand"><code translate="no" dir="ltr">BitwiseAnd(...)</code></a>: Elementwise computes the bitwise AND of <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>.</p> <p><a href="../../raw_ops/bitwiseor"><code translate="no" dir="ltr">BitwiseOr(...)</code></a>: Elementwise computes the bitwise OR of <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>.</p> <p><a href="../../raw_ops/bitwisexor"><code translate="no" dir="ltr">BitwiseXor(...)</code></a>: Elementwise computes the bitwise XOR of <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>.</p> <p><a href="../../raw_ops/blocklstm"><code translate="no" dir="ltr">BlockLSTM(...)</code></a>: Computes the LSTM cell forward propagation for all the time steps.</p> <p><a href="../../raw_ops/blocklstmgrad"><code translate="no" dir="ltr">BlockLSTMGrad(...)</code></a>: Computes the LSTM cell backward propagation for the entire time sequence.</p> <p><a href="../../raw_ops/blocklstmgradv2"><code translate="no" dir="ltr">BlockLSTMGradV2(...)</code></a>: Computes the LSTM cell backward propagation for the entire time sequence.</p> <p><a href="../../raw_ops/blocklstmv2"><code translate="no" dir="ltr">BlockLSTMV2(...)</code></a>: Computes the LSTM cell forward propagation for all the time steps.</p> <p><a href="../../raw_ops/boostedtreesaggregatestats"><code translate="no" dir="ltr">BoostedTreesAggregateStats(...)</code></a>: Aggregates the summary of accumulated stats for the batch.</p> <p><a href="../../raw_ops/boostedtreesbucketize"><code translate="no" dir="ltr">BoostedTreesBucketize(...)</code></a>: Bucketize each feature based on bucket boundaries.</p> <p><a href="../../raw_ops/boostedtreescalculatebestfeaturesplit"><code translate="no" dir="ltr">BoostedTreesCalculateBestFeatureSplit(...)</code></a>: Calculates gains for each feature and returns the best possible split information for the feature.</p> <p><a href="../../raw_ops/boostedtreescalculatebestfeaturesplitv2"><code translate="no" dir="ltr">BoostedTreesCalculateBestFeatureSplitV2(...)</code></a>: Calculates gains for each feature and returns the best possible split information for each node. However, if no split is found, then no split information is returned for that node.</p> <p><a href="../../raw_ops/boostedtreescalculatebestgainsperfeature"><code translate="no" dir="ltr">BoostedTreesCalculateBestGainsPerFeature(...)</code></a>: Calculates gains for each feature and returns the best possible split information for the feature.</p> <p><a href="../../raw_ops/boostedtreescenterbias"><code translate="no" dir="ltr">BoostedTreesCenterBias(...)</code></a>: Calculates the prior from the training data (the bias) and fills in the first node with the logits' prior. Returns a boolean indicating whether to continue centering.</p> <p><a href="../../raw_ops/boostedtreescreateensemble"><code translate="no" dir="ltr">BoostedTreesCreateEnsemble(...)</code></a>: Creates a tree ensemble model and returns a handle to it.</p> <p><a href="../../raw_ops/boostedtreescreatequantilestreamresource"><code translate="no" dir="ltr">BoostedTreesCreateQuantileStreamResource(...)</code></a>: Create the Resource for Quantile Streams.</p> <p><a href="../../raw_ops/boostedtreesdeserializeensemble"><code translate="no" dir="ltr">BoostedTreesDeserializeEnsemble(...)</code></a>: Deserializes a serialized tree ensemble config and replaces current tree</p> <p><a href="../../raw_ops/boostedtreesensembleresourcehandleop"><code translate="no" dir="ltr">BoostedTreesEnsembleResourceHandleOp(...)</code></a>: Creates a handle to a BoostedTreesEnsembleResource</p> <p><a href="../../raw_ops/boostedtreesexampledebugoutputs"><code translate="no" dir="ltr">BoostedTreesExampleDebugOutputs(...)</code></a>: Debugging/model interpretability outputs for each example.</p> <p><a href="../../raw_ops/boostedtreesflushquantilesummaries"><code translate="no" dir="ltr">BoostedTreesFlushQuantileSummaries(...)</code></a>: Flush the quantile summaries from each quantile stream resource.</p> <p><a href="../../raw_ops/boostedtreesgetensemblestates"><code translate="no" dir="ltr">BoostedTreesGetEnsembleStates(...)</code></a>: Retrieves the tree ensemble resource stamp token, number of trees and growing statistics.</p> <p><a href="../../raw_ops/boostedtreesmakequantilesummaries"><code translate="no" dir="ltr">BoostedTreesMakeQuantileSummaries(...)</code></a>: Makes the summary of quantiles for the batch.</p> <p><a href="../../raw_ops/boostedtreesmakestatssummary"><code translate="no" dir="ltr">BoostedTreesMakeStatsSummary(...)</code></a>: Makes the summary of accumulated stats for the batch.</p> <p><a href="../../raw_ops/boostedtreespredict"><code translate="no" dir="ltr">BoostedTreesPredict(...)</code></a>: Runs multiple additive regression ensemble predictors on input instances and</p> <p><a href="../../raw_ops/boostedtreesquantilestreamresourceaddsummaries"><code translate="no" dir="ltr">BoostedTreesQuantileStreamResourceAddSummaries(...)</code></a>: Add the quantile summaries to each quantile stream resource.</p> <p><a href="../../raw_ops/boostedtreesquantilestreamresourcedeserialize"><code translate="no" dir="ltr">BoostedTreesQuantileStreamResourceDeserialize(...)</code></a>: Deserialize bucket boundaries and ready flag into current QuantileAccumulator.</p> <p><a href="../../raw_ops/boostedtreesquantilestreamresourceflush"><code translate="no" dir="ltr">BoostedTreesQuantileStreamResourceFlush(...)</code></a>: Flush the summaries for a quantile stream resource.</p> <p><a href="../../raw_ops/boostedtreesquantilestreamresourcegetbucketboundaries"><code translate="no" dir="ltr">BoostedTreesQuantileStreamResourceGetBucketBoundaries(...)</code></a>: Generate the bucket boundaries for each feature based on accumulated summaries.</p> <p><a href="../../raw_ops/boostedtreesquantilestreamresourcehandleop"><code translate="no" dir="ltr">BoostedTreesQuantileStreamResourceHandleOp(...)</code></a>: Creates a handle to a BoostedTreesQuantileStreamResource.</p> <p><a href="../../raw_ops/boostedtreesserializeensemble"><code translate="no" dir="ltr">BoostedTreesSerializeEnsemble(...)</code></a>: Serializes the tree ensemble to a proto.</p> <p><a href="../../raw_ops/boostedtreessparseaggregatestats"><code translate="no" dir="ltr">BoostedTreesSparseAggregateStats(...)</code></a>: Aggregates the summary of accumulated stats for the batch.</p> <p><a href="../../raw_ops/boostedtreessparsecalculatebestfeaturesplit"><code translate="no" dir="ltr">BoostedTreesSparseCalculateBestFeatureSplit(...)</code></a>: Calculates gains for each feature and returns the best possible split information for the feature.</p> <p><a href="../../raw_ops/boostedtreestrainingpredict"><code translate="no" dir="ltr">BoostedTreesTrainingPredict(...)</code></a>: Runs multiple additive regression ensemble predictors on input instances and</p> <p><a href="../../raw_ops/boostedtreesupdateensemble"><code translate="no" dir="ltr">BoostedTreesUpdateEnsemble(...)</code></a>: Updates the tree ensemble by either adding a layer to the last tree being grown</p> <p><a href="../../raw_ops/boostedtreesupdateensemblev2"><code translate="no" dir="ltr">BoostedTreesUpdateEnsembleV2(...)</code></a>: Updates the tree ensemble by adding a layer to the last tree being grown</p> <p><a href="../../raw_ops/broadcastargs"><code translate="no" dir="ltr">BroadcastArgs(...)</code></a>: Return the shape of s0 op s1 with broadcast.</p> <p><a href="../../raw_ops/broadcastgradientargs"><code translate="no" dir="ltr">BroadcastGradientArgs(...)</code></a>: Return the reduction indices for computing gradients of s0 op s1 with broadcast.</p> <p><a href="../../raw_ops/broadcastto"><code translate="no" dir="ltr">BroadcastTo(...)</code></a>: Broadcast an array for a compatible shape.</p> <p><a href="../../raw_ops/bucketize"><code translate="no" dir="ltr">Bucketize(...)</code></a>: Bucketizes 'input' based on 'boundaries'.</p> <p><a href="../../raw_ops/bytesproducedstatsdataset"><code translate="no" dir="ltr">BytesProducedStatsDataset(...)</code></a>: Records the bytes size of each element of <code translate="no" dir="ltr">input_dataset</code> in a StatsAggregator.</p> <p><a href="../../raw_ops/csrsparsematrixcomponents"><code translate="no" dir="ltr">CSRSparseMatrixComponents(...)</code></a>: Reads out the CSR components at batch <code translate="no" dir="ltr">index</code>.</p> <p><a href="../../raw_ops/csrsparsematrixtodense"><code translate="no" dir="ltr">CSRSparseMatrixToDense(...)</code></a>: Convert a (possibly batched) CSRSparseMatrix to dense.</p> <p><a href="../../raw_ops/csrsparsematrixtosparsetensor"><code translate="no" dir="ltr">CSRSparseMatrixToSparseTensor(...)</code></a>: Converts a (possibly batched) CSRSparesMatrix to a SparseTensor.</p> <p><a href="../../raw_ops/csvdataset"><code translate="no" dir="ltr">CSVDataset(...)</code></a></p> <p><a href="../../raw_ops/csvdatasetv2"><code translate="no" dir="ltr">CSVDatasetV2(...)</code></a></p> <p><a href="../../raw_ops/ctcbeamsearchdecoder"><code translate="no" dir="ltr">CTCBeamSearchDecoder(...)</code></a>: Performs beam search decoding on the logits given in input.</p> <p><a href="../../raw_ops/ctcgreedydecoder"><code translate="no" dir="ltr">CTCGreedyDecoder(...)</code></a>: Performs greedy decoding on the logits given in inputs.</p> <p><a href="../../raw_ops/ctcloss"><code translate="no" dir="ltr">CTCLoss(...)</code></a>: Calculates the CTC Loss (log probability) for each batch entry. Also calculates</p> <p><a href="../../raw_ops/ctclossv2"><code translate="no" dir="ltr">CTCLossV2(...)</code></a>: Calculates the CTC Loss (log probability) for each batch entry. Also calculates</p> <p><a href="../../raw_ops/cachedataset"><code translate="no" dir="ltr">CacheDataset(...)</code></a>: Creates a dataset that caches elements from <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/cachedatasetv2"><code translate="no" dir="ltr">CacheDatasetV2(...)</code></a></p> <p><a href="../../raw_ops/case"><code translate="no" dir="ltr">Case(...)</code></a>: An n-way switch statement which calls a single branch function.</p> <p><a href="../../raw_ops/cast"><code translate="no" dir="ltr">Cast(...)</code></a>: Cast x of type SrcT to y of DstT.</p> <p><a href="../../raw_ops/ceil"><code translate="no" dir="ltr">Ceil(...)</code></a>: Returns element-wise smallest integer not less than x.</p> <p><a href="../../raw_ops/checknumerics"><code translate="no" dir="ltr">CheckNumerics(...)</code></a>: Checks a tensor for NaN and Inf values.</p> <p><a href="../../raw_ops/checknumericsv2"><code translate="no" dir="ltr">CheckNumericsV2(...)</code></a>: Checks a tensor for NaN, -Inf and +Inf values.</p> <p><a href="../../raw_ops/cholesky"><code translate="no" dir="ltr">Cholesky(...)</code></a>: Computes the Cholesky decomposition of one or more square matrices.</p> <p><a href="../../raw_ops/choleskygrad"><code translate="no" dir="ltr">CholeskyGrad(...)</code></a>: Computes the reverse mode backpropagated gradient of the Cholesky algorithm.</p> <p><a href="../../raw_ops/choosefastestbranchdataset"><code translate="no" dir="ltr">ChooseFastestBranchDataset(...)</code></a></p> <p><a href="../../raw_ops/choosefastestdataset"><code translate="no" dir="ltr">ChooseFastestDataset(...)</code></a></p> <p><a href="../../raw_ops/clipbyvalue"><code translate="no" dir="ltr">ClipByValue(...)</code></a>: Clips tensor values to a specified min and max.</p> <p><a href="../../raw_ops/closesummarywriter"><code translate="no" dir="ltr">CloseSummaryWriter(...)</code></a></p> <p><a href="../../raw_ops/collectivebcastrecv"><code translate="no" dir="ltr">CollectiveBcastRecv(...)</code></a>: Receives a tensor value broadcast from another device.</p> <p><a href="../../raw_ops/collectivebcastsend"><code translate="no" dir="ltr">CollectiveBcastSend(...)</code></a>: Broadcasts a tensor value to one or more other devices.</p> <p><a href="../../raw_ops/collectivegather"><code translate="no" dir="ltr">CollectiveGather(...)</code></a>: Mutually accumulates multiple tensors of identical type and shape.</p> <p><a href="../../raw_ops/collectivegatherv2"><code translate="no" dir="ltr">CollectiveGatherV2(...)</code></a>: Mutually accumulates multiple tensors of identical type and shape.</p> <p><a href="../../raw_ops/collectivepermute"><code translate="no" dir="ltr">CollectivePermute(...)</code></a>: An Op to permute tensors across replicated TPU instances.</p> <p><a href="../../raw_ops/collectivereduce"><code translate="no" dir="ltr">CollectiveReduce(...)</code></a>: Mutually reduces multiple tensors of identical type and shape.</p> <p><a href="../../raw_ops/collectivereducev2"><code translate="no" dir="ltr">CollectiveReduceV2(...)</code></a>: Mutually reduces multiple tensors of identical type and shape.</p> <p><a href="../../raw_ops/combinednonmaxsuppression"><code translate="no" dir="ltr">CombinedNonMaxSuppression(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/compareandbitpack"><code translate="no" dir="ltr">CompareAndBitpack(...)</code></a>: Compare values of <code translate="no" dir="ltr">input</code> to <code translate="no" dir="ltr">threshold</code> and pack resulting bits into a <code translate="no" dir="ltr">uint8</code>.</p> <p><a href="../../raw_ops/complex"><code translate="no" dir="ltr">Complex(...)</code></a>: Converts two real numbers to a complex number.</p> <p><a href="../../raw_ops/complexabs"><code translate="no" dir="ltr">ComplexAbs(...)</code></a>: Computes the complex absolute value of a tensor.</p> <p><a href="../../raw_ops/compresselement"><code translate="no" dir="ltr">CompressElement(...)</code></a>: Compresses a dataset element.</p> <p><a href="../../raw_ops/computeaccidentalhits"><code translate="no" dir="ltr">ComputeAccidentalHits(...)</code></a>: Computes the ids of the positions in sampled_candidates that match true_labels.</p> <p><a href="../../raw_ops/computebatchsize"><code translate="no" dir="ltr">ComputeBatchSize(...)</code></a>: Computes the static batch size of a dataset sans partial batches.</p> <p><a href="../../raw_ops/concat"><code translate="no" dir="ltr">Concat(...)</code></a>: Concatenates tensors along one dimension.</p> <p><a href="../../raw_ops/concatoffset"><code translate="no" dir="ltr">ConcatOffset(...)</code></a>: Computes offsets of concat inputs within its output.</p> <p><a href="../../raw_ops/concatv2"><code translate="no" dir="ltr">ConcatV2(...)</code></a>: Concatenates tensors along one dimension.</p> <p><a href="../../raw_ops/concatenatedataset"><code translate="no" dir="ltr">ConcatenateDataset(...)</code></a>: Creates a dataset that concatenates <code translate="no" dir="ltr">input_dataset</code> with <code translate="no" dir="ltr">another_dataset</code>.</p> <p><a href="../../raw_ops/conditionalaccumulator"><code translate="no" dir="ltr">ConditionalAccumulator(...)</code></a>: A conditional accumulator for aggregating gradients.</p> <p><a href="../../raw_ops/configuredistributedtpu"><code translate="no" dir="ltr">ConfigureDistributedTPU(...)</code></a>: Sets up the centralized structures for a distributed TPU system.</p> <p><a href="../../raw_ops/configuretpuembedding"><code translate="no" dir="ltr">ConfigureTPUEmbedding(...)</code></a>: Sets up TPUEmbedding in a distributed TPU system.</p> <p><a href="../../raw_ops/conj"><code translate="no" dir="ltr">Conj(...)</code></a>: Returns the complex conjugate of a complex number.</p> <p><a href="../../raw_ops/conjugatetranspose"><code translate="no" dir="ltr">ConjugateTranspose(...)</code></a>: Shuffle dimensions of x according to a permutation and conjugate the result.</p> <p><a href="../../raw_ops/const"><code translate="no" dir="ltr">Const(...)</code></a>: Returns a constant tensor.</p> <p><a href="../../raw_ops/consumemutexlock"><code translate="no" dir="ltr">ConsumeMutexLock(...)</code></a>: This op consumes a lock created by <code translate="no" dir="ltr">MutexLock</code>.</p> <p><a href="../../raw_ops/controltrigger"><code translate="no" dir="ltr">ControlTrigger(...)</code></a>: Does nothing. Serves as a control trigger for scheduling.</p> <p><a href="../../raw_ops/conv2d"><code translate="no" dir="ltr">Conv2D(...)</code></a>: Computes a 2-D convolution given 4-D <code translate="no" dir="ltr">input</code> and <code translate="no" dir="ltr">filter</code> tensors.</p> <p><a href="../../raw_ops/conv2dbackpropfilter"><code translate="no" dir="ltr">Conv2DBackpropFilter(...)</code></a>: Computes the gradients of convolution with respect to the filter.</p> <p><a href="../../raw_ops/conv2dbackpropinput"><code translate="no" dir="ltr">Conv2DBackpropInput(...)</code></a>: Computes the gradients of convolution with respect to the input.</p> <p><a href="../../raw_ops/conv3d"><code translate="no" dir="ltr">Conv3D(...)</code></a>: Computes a 3-D convolution given 5-D <code translate="no" dir="ltr">input</code> and <code translate="no" dir="ltr">filter</code> tensors.</p> <p><a href="../../raw_ops/conv3dbackpropfilter"><code translate="no" dir="ltr">Conv3DBackpropFilter(...)</code></a>: Computes the gradients of 3-D convolution with respect to the filter.</p> <p><a href="../../raw_ops/conv3dbackpropfilterv2"><code translate="no" dir="ltr">Conv3DBackpropFilterV2(...)</code></a>: Computes the gradients of 3-D convolution with respect to the filter.</p> <p><a href="../../raw_ops/conv3dbackpropinput"><code translate="no" dir="ltr">Conv3DBackpropInput(...)</code></a>: Computes the gradients of 3-D convolution with respect to the input.</p> <p><a href="../../raw_ops/conv3dbackpropinputv2"><code translate="no" dir="ltr">Conv3DBackpropInputV2(...)</code></a>: Computes the gradients of 3-D convolution with respect to the input.</p> <p><a href="../../raw_ops/copy"><code translate="no" dir="ltr">Copy(...)</code></a>: Copy a tensor from CPU-to-CPU or GPU-to-GPU.</p> <p><a href="../../raw_ops/copyhost"><code translate="no" dir="ltr">CopyHost(...)</code></a>: Copy a tensor to host.</p> <p><a href="../../raw_ops/cos"><code translate="no" dir="ltr">Cos(...)</code></a>: Computes cos of x element-wise.</p> <p><a href="../../raw_ops/cosh"><code translate="no" dir="ltr">Cosh(...)</code></a>: Computes hyperbolic cosine of x element-wise.</p> <p><a href="../../raw_ops/countupto"><code translate="no" dir="ltr">CountUpTo(...)</code></a>: Increments 'ref' until it reaches 'limit'.</p> <p><a href="../../raw_ops/createsummarydbwriter"><code translate="no" dir="ltr">CreateSummaryDbWriter(...)</code></a></p> <p><a href="../../raw_ops/createsummaryfilewriter"><code translate="no" dir="ltr">CreateSummaryFileWriter(...)</code></a></p> <p><a href="../../raw_ops/cropandresize"><code translate="no" dir="ltr">CropAndResize(...)</code></a>: Extracts crops from the input image tensor and resizes them.</p> <p><a href="../../raw_ops/cropandresizegradboxes"><code translate="no" dir="ltr">CropAndResizeGradBoxes(...)</code></a>: Computes the gradient of the crop_and_resize op wrt the input boxes tensor.</p> <p><a href="../../raw_ops/cropandresizegradimage"><code translate="no" dir="ltr">CropAndResizeGradImage(...)</code></a>: Computes the gradient of the crop_and_resize op wrt the input image tensor.</p> <p><a href="../../raw_ops/cross"><code translate="no" dir="ltr">Cross(...)</code></a>: Compute the pairwise cross product.</p> <p><a href="../../raw_ops/crossreplicasum"><code translate="no" dir="ltr">CrossReplicaSum(...)</code></a>: An Op to sum inputs across replicated TPU instances.</p> <p><a href="../../raw_ops/cudnnrnn"><code translate="no" dir="ltr">CudnnRNN(...)</code></a>: A RNN backed by cuDNN.</p> <p><a href="../../raw_ops/cudnnrnnbackprop"><code translate="no" dir="ltr">CudnnRNNBackprop(...)</code></a>: Backprop step of CudnnRNN.</p> <p><a href="../../raw_ops/cudnnrnnbackpropv2"><code translate="no" dir="ltr">CudnnRNNBackpropV2(...)</code></a>: Backprop step of CudnnRNN.</p> <p><a href="../../raw_ops/cudnnrnnbackpropv3"><code translate="no" dir="ltr">CudnnRNNBackpropV3(...)</code></a>: Backprop step of CudnnRNNV3.</p> <p><a href="../../raw_ops/cudnnrnncanonicaltoparams"><code translate="no" dir="ltr">CudnnRNNCanonicalToParams(...)</code></a>: Converts CudnnRNN params from canonical form to usable form.</p> <p><a href="../../raw_ops/cudnnrnncanonicaltoparamsv2"><code translate="no" dir="ltr">CudnnRNNCanonicalToParamsV2(...)</code></a>: Converts CudnnRNN params from canonical form to usable form. It supports the projection in LSTM.</p> <p><a href="../../raw_ops/cudnnrnnparamssize"><code translate="no" dir="ltr">CudnnRNNParamsSize(...)</code></a>: Computes size of weights that can be used by a Cudnn RNN model.</p> <p><a href="../../raw_ops/cudnnrnnparamstocanonical"><code translate="no" dir="ltr">CudnnRNNParamsToCanonical(...)</code></a>: Retrieves CudnnRNN params in canonical form.</p> <p><a href="../../raw_ops/cudnnrnnparamstocanonicalv2"><code translate="no" dir="ltr">CudnnRNNParamsToCanonicalV2(...)</code></a>: Retrieves CudnnRNN params in canonical form. It supports the projection in LSTM.</p> <p><a href="../../raw_ops/cudnnrnnv2"><code translate="no" dir="ltr">CudnnRNNV2(...)</code></a>: A RNN backed by cuDNN.</p> <p><a href="../../raw_ops/cudnnrnnv3"><code translate="no" dir="ltr">CudnnRNNV3(...)</code></a>: A RNN backed by cuDNN.</p> <p><a href="../../raw_ops/cumprod"><code translate="no" dir="ltr">Cumprod(...)</code></a>: Compute the cumulative product of the tensor <code translate="no" dir="ltr">x</code> along <code translate="no" dir="ltr">axis</code>.</p> <p><a href="../../raw_ops/cumsum"><code translate="no" dir="ltr">Cumsum(...)</code></a>: Compute the cumulative sum of the tensor <code translate="no" dir="ltr">x</code> along <code translate="no" dir="ltr">axis</code>.</p> <p><a href="../../raw_ops/cumulativelogsumexp"><code translate="no" dir="ltr">CumulativeLogsumexp(...)</code></a>: Compute the cumulative product of the tensor <code translate="no" dir="ltr">x</code> along <code translate="no" dir="ltr">axis</code>.</p> <p><a href="../../raw_ops/dataformatdimmap"><code translate="no" dir="ltr">DataFormatDimMap(...)</code></a>: Returns the dimension index in the destination data format given the one in</p> <p><a href="../../raw_ops/dataformatvecpermute"><code translate="no" dir="ltr">DataFormatVecPermute(...)</code></a>: Permute input tensor from <code translate="no" dir="ltr">src_format</code> to <code translate="no" dir="ltr">dst_format</code>.</p> <p><a href="../../raw_ops/dataservicedataset"><code translate="no" dir="ltr">DataServiceDataset(...)</code></a>: Creates a dataset that reads data from the tf.data service.</p> <p><a href="../../raw_ops/datasetcardinality"><code translate="no" dir="ltr">DatasetCardinality(...)</code></a>: Returns the cardinality of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/datasetfromgraph"><code translate="no" dir="ltr">DatasetFromGraph(...)</code></a>: Creates a dataset from the given <code translate="no" dir="ltr">graph_def</code>.</p> <p><a href="../../raw_ops/datasettograph"><code translate="no" dir="ltr">DatasetToGraph(...)</code></a>: Returns a serialized GraphDef representing <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/datasettographv2"><code translate="no" dir="ltr">DatasetToGraphV2(...)</code></a>: Returns a serialized GraphDef representing <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/datasettosingleelement"><code translate="no" dir="ltr">DatasetToSingleElement(...)</code></a>: Outputs the single element from the given dataset.</p> <p><a href="../../raw_ops/datasettotfrecord"><code translate="no" dir="ltr">DatasetToTFRecord(...)</code></a>: Writes the given dataset to the given file using the TFRecord format.</p> <p><a href="../../raw_ops/dawsn"><code translate="no" dir="ltr">Dawsn(...)</code></a></p> <p><a href="../../raw_ops/debuggradientidentity"><code translate="no" dir="ltr">DebugGradientIdentity(...)</code></a>: Identity op for gradient debugging.</p> <p><a href="../../raw_ops/debuggradientrefidentity"><code translate="no" dir="ltr">DebugGradientRefIdentity(...)</code></a>: Identity op for gradient debugging.</p> <p><a href="../../raw_ops/debugidentity"><code translate="no" dir="ltr">DebugIdentity(...)</code></a>: Provides an identity mapping of the non-Ref type input tensor for debugging.</p> <p><a href="../../raw_ops/debugidentityv2"><code translate="no" dir="ltr">DebugIdentityV2(...)</code></a>: Debug Identity V2 Op.</p> <p><a href="../../raw_ops/debugnancount"><code translate="no" dir="ltr">DebugNanCount(...)</code></a>: Debug NaN Value Counter Op.</p> <p><a href="../../raw_ops/debugnumericsummary"><code translate="no" dir="ltr">DebugNumericSummary(...)</code></a>: Debug Numeric Summary Op.</p> <p><a href="../../raw_ops/debugnumericsummaryv2"><code translate="no" dir="ltr">DebugNumericSummaryV2(...)</code></a>: Debug Numeric Summary V2 Op.</p> <p><a href="../../raw_ops/decodeandcropjpeg"><code translate="no" dir="ltr">DecodeAndCropJpeg(...)</code></a>: Decode and Crop a JPEG-encoded image to a uint8 tensor.</p> <p><a href="../../raw_ops/decodebase64"><code translate="no" dir="ltr">DecodeBase64(...)</code></a>: Decode web-safe base64-encoded strings.</p> <p><a href="../../raw_ops/decodebmp"><code translate="no" dir="ltr">DecodeBmp(...)</code></a>: Decode the first frame of a BMP-encoded image to a uint8 tensor.</p> <p><a href="../../raw_ops/decodecsv"><code translate="no" dir="ltr">DecodeCSV(...)</code></a>: Convert CSV records to tensors. Each column maps to one tensor.</p> <p><a href="../../raw_ops/decodecompressed"><code translate="no" dir="ltr">DecodeCompressed(...)</code></a>: Decompress strings.</p> <p><a href="../../raw_ops/decodegif"><code translate="no" dir="ltr">DecodeGif(...)</code></a>: Decode the frame(s) of a GIF-encoded image to a uint8 tensor.</p> <p><a href="../../raw_ops/decodeimage"><code translate="no" dir="ltr">DecodeImage(...)</code></a>: Function for decode_bmp, decode_gif, decode_jpeg, and decode_png.</p> <p><a href="../../raw_ops/decodejsonexample"><code translate="no" dir="ltr">DecodeJSONExample(...)</code></a>: Convert JSON-encoded Example records to binary protocol buffer strings.</p> <p><a href="../../raw_ops/decodejpeg"><code translate="no" dir="ltr">DecodeJpeg(...)</code></a>: Decode a JPEG-encoded image to a uint8 tensor.</p> <p><a href="../../raw_ops/decodepaddedraw"><code translate="no" dir="ltr">DecodePaddedRaw(...)</code></a>: Reinterpret the bytes of a string as a vector of numbers.</p> <p><a href="../../raw_ops/decodepng"><code translate="no" dir="ltr">DecodePng(...)</code></a>: Decode a PNG-encoded image to a uint8 or uint16 tensor.</p> <p><a href="../../raw_ops/decodeprotov2"><code translate="no" dir="ltr">DecodeProtoV2(...)</code></a>: The op extracts fields from a serialized protocol buffers message into tensors.</p> <p><a href="../../raw_ops/decoderaw"><code translate="no" dir="ltr">DecodeRaw(...)</code></a>: Reinterpret the bytes of a string as a vector of numbers.</p> <p><a href="../../raw_ops/decodewav"><code translate="no" dir="ltr">DecodeWav(...)</code></a>: Decode a 16-bit PCM WAV file to a float tensor.</p> <p><a href="../../raw_ops/deepcopy"><code translate="no" dir="ltr">DeepCopy(...)</code></a>: Makes a copy of <code translate="no" dir="ltr">x</code>.</p> <p><a href="../../raw_ops/deleteiterator"><code translate="no" dir="ltr">DeleteIterator(...)</code></a>: A container for an iterator resource.</p> <p><a href="../../raw_ops/deletememorycache"><code translate="no" dir="ltr">DeleteMemoryCache(...)</code></a></p> <p><a href="../../raw_ops/deletemultideviceiterator"><code translate="no" dir="ltr">DeleteMultiDeviceIterator(...)</code></a>: A container for an iterator resource.</p> <p><a href="../../raw_ops/deleterandomseedgenerator"><code translate="no" dir="ltr">DeleteRandomSeedGenerator(...)</code></a></p> <p><a href="../../raw_ops/deleteseedgenerator"><code translate="no" dir="ltr">DeleteSeedGenerator(...)</code></a></p> <p><a href="../../raw_ops/deletesessiontensor"><code translate="no" dir="ltr">DeleteSessionTensor(...)</code></a>: Delete the tensor specified by its handle in the session.</p> <p><a href="../../raw_ops/densebincount"><code translate="no" dir="ltr">DenseBincount(...)</code></a>: Counts the number of occurrences of each value in an integer array.</p> <p><a href="../../raw_ops/densecountsparseoutput"><code translate="no" dir="ltr">DenseCountSparseOutput(...)</code></a>: Performs sparse-output bin counting for a tf.tensor input.</p> <p><a href="../../raw_ops/densetocsrsparsematrix"><code translate="no" dir="ltr">DenseToCSRSparseMatrix(...)</code></a>: Converts a dense tensor to a (possibly batched) CSRSparseMatrix.</p> <p><a href="../../raw_ops/densetodensesetoperation"><code translate="no" dir="ltr">DenseToDenseSetOperation(...)</code></a>: Applies set operation along last dimension of 2 <code translate="no" dir="ltr">Tensor</code> inputs.</p> <p><a href="../../raw_ops/densetosparsebatchdataset"><code translate="no" dir="ltr">DenseToSparseBatchDataset(...)</code></a>: Creates a dataset that batches input elements into a SparseTensor.</p> <p><a href="../../raw_ops/densetosparsesetoperation"><code translate="no" dir="ltr">DenseToSparseSetOperation(...)</code></a>: Applies set operation along last dimension of <code translate="no" dir="ltr">Tensor</code> and <code translate="no" dir="ltr">SparseTensor</code>.</p> <p><a href="../../raw_ops/depthtospace"><code translate="no" dir="ltr">DepthToSpace(...)</code></a>: DepthToSpace for tensors of type T.</p> <p><a href="../../raw_ops/depthwiseconv2dnative"><code translate="no" dir="ltr">DepthwiseConv2dNative(...)</code></a>: Computes a 2-D depthwise convolution given 4-D <code translate="no" dir="ltr">input</code> and <code translate="no" dir="ltr">filter</code> tensors.</p> <p><a href="../../raw_ops/depthwiseconv2dnativebackpropfilter"><code translate="no" dir="ltr">DepthwiseConv2dNativeBackpropFilter(...)</code></a>: Computes the gradients of depthwise convolution with respect to the filter.</p> <p><a href="../../raw_ops/depthwiseconv2dnativebackpropinput"><code translate="no" dir="ltr">DepthwiseConv2dNativeBackpropInput(...)</code></a>: Computes the gradients of depthwise convolution with respect to the input.</p> <p><a href="../../raw_ops/dequantize"><code translate="no" dir="ltr">Dequantize(...)</code></a>: Dequantize the 'input' tensor into a float or bfloat16 Tensor.</p> <p><a href="../../raw_ops/deserializeiterator"><code translate="no" dir="ltr">DeserializeIterator(...)</code></a>: Converts the given variant tensor to an iterator and stores it in the given resource.</p> <p><a href="../../raw_ops/deserializemanysparse"><code translate="no" dir="ltr">DeserializeManySparse(...)</code></a>: Deserialize and concatenate <code translate="no" dir="ltr">SparseTensors</code> from a serialized minibatch.</p> <p><a href="../../raw_ops/deserializesparse"><code translate="no" dir="ltr">DeserializeSparse(...)</code></a>: Deserialize <code translate="no" dir="ltr">SparseTensor</code> objects.</p> <p><a href="../../raw_ops/destroyresourceop"><code translate="no" dir="ltr">DestroyResourceOp(...)</code></a>: Deletes the resource specified by the handle.</p> <p><a href="../../raw_ops/destroytemporaryvariable"><code translate="no" dir="ltr">DestroyTemporaryVariable(...)</code></a>: Destroys the temporary variable and returns its final value.</p> <p><a href="../../raw_ops/deviceindex"><code translate="no" dir="ltr">DeviceIndex(...)</code></a>: Return the index of device the op runs.</p> <p><a href="../../raw_ops/diag"><code translate="no" dir="ltr">Diag(...)</code></a>: Returns a diagonal tensor with a given diagonal values.</p> <p><a href="../../raw_ops/diagpart"><code translate="no" dir="ltr">DiagPart(...)</code></a>: Returns the diagonal part of the tensor.</p> <p><a href="../../raw_ops/digamma"><code translate="no" dir="ltr">Digamma(...)</code></a>: Computes Psi, the derivative of Lgamma (the log of the absolute value of</p> <p><a href="../../raw_ops/dilation2d"><code translate="no" dir="ltr">Dilation2D(...)</code></a>: Computes the grayscale dilation of 4-D <code translate="no" dir="ltr">input</code> and 3-D <code translate="no" dir="ltr">filter</code> tensors.</p> <p><a href="../../raw_ops/dilation2dbackpropfilter"><code translate="no" dir="ltr">Dilation2DBackpropFilter(...)</code></a>: Computes the gradient of morphological 2-D dilation with respect to the filter.</p> <p><a href="../../raw_ops/dilation2dbackpropinput"><code translate="no" dir="ltr">Dilation2DBackpropInput(...)</code></a>: Computes the gradient of morphological 2-D dilation with respect to the input.</p> <p><a href="../../raw_ops/directedinterleavedataset"><code translate="no" dir="ltr">DirectedInterleaveDataset(...)</code></a>: A substitute for <code translate="no" dir="ltr">InterleaveDataset</code> on a fixed list of <code translate="no" dir="ltr">N</code> datasets.</p> <p><a href="../../raw_ops/div"><code translate="no" dir="ltr">Div(...)</code></a>: Returns x / y element-wise.</p> <p><a href="../../raw_ops/divnonan"><code translate="no" dir="ltr">DivNoNan(...)</code></a>: Returns 0 if the denominator is zero.</p> <p><a href="../../raw_ops/drawboundingboxes"><code translate="no" dir="ltr">DrawBoundingBoxes(...)</code></a>: Draw bounding boxes on a batch of images.</p> <p><a href="../../raw_ops/drawboundingboxesv2"><code translate="no" dir="ltr">DrawBoundingBoxesV2(...)</code></a>: Draw bounding boxes on a batch of images.</p> <p><a href="../../raw_ops/dummyiterationcounter"><code translate="no" dir="ltr">DummyIterationCounter(...)</code></a></p> <p><a href="../../raw_ops/dummymemorycache"><code translate="no" dir="ltr">DummyMemoryCache(...)</code></a></p> <p><a href="../../raw_ops/dummyseedgenerator"><code translate="no" dir="ltr">DummySeedGenerator(...)</code></a></p> <p><a href="../../raw_ops/dynamicpartition"><code translate="no" dir="ltr">DynamicPartition(...)</code></a>: Partitions <code translate="no" dir="ltr">data</code> into <code translate="no" dir="ltr">num_partitions</code> tensors using indices from <code translate="no" dir="ltr">partitions</code>.</p> <p><a href="../../raw_ops/dynamicstitch"><code translate="no" dir="ltr">DynamicStitch(...)</code></a>: Interleave the values from the <code translate="no" dir="ltr">data</code> tensors into a single tensor.</p> <p><a href="../../raw_ops/eagerpyfunc"><code translate="no" dir="ltr">EagerPyFunc(...)</code></a>: Eagerly executes a python function to compute func(input)-&gt;output. The</p> <p><a href="../../raw_ops/editdistance"><code translate="no" dir="ltr">EditDistance(...)</code></a>: Computes the (possibly normalized) Levenshtein Edit Distance.</p> <p><a href="../../raw_ops/eig"><code translate="no" dir="ltr">Eig(...)</code></a>: Computes the eigen decomposition of one or more square matrices.</p> <p><a href="../../raw_ops/einsum"><code translate="no" dir="ltr">Einsum(...)</code></a>: Tensor contraction according to Einstein summation convention.</p> <p><a href="../../raw_ops/elu"><code translate="no" dir="ltr">Elu(...)</code></a>: Computes exponential linear: <code translate="no" dir="ltr">exp(features) - 1</code> if &lt; 0, <code translate="no" dir="ltr">features</code> otherwise.</p> <p><a href="../../raw_ops/elugrad"><code translate="no" dir="ltr">EluGrad(...)</code></a>: Computes gradients for the exponential linear (Elu) operation.</p> <p><a href="../../raw_ops/empty"><code translate="no" dir="ltr">Empty(...)</code></a>: Creates a tensor with the given shape.</p> <p><a href="../../raw_ops/emptytensorlist"><code translate="no" dir="ltr">EmptyTensorList(...)</code></a>: Creates and returns an empty tensor list.</p> <p><a href="../../raw_ops/encodebase64"><code translate="no" dir="ltr">EncodeBase64(...)</code></a>: Encode strings into web-safe base64 format.</p> <p><a href="../../raw_ops/encodejpeg"><code translate="no" dir="ltr">EncodeJpeg(...)</code></a>: JPEG-encode an image.</p> <p><a href="../../raw_ops/encodejpegvariablequality"><code translate="no" dir="ltr">EncodeJpegVariableQuality(...)</code></a>: JPEG encode input image with provided compression quality.</p> <p><a href="../../raw_ops/encodepng"><code translate="no" dir="ltr">EncodePng(...)</code></a>: PNG-encode an image.</p> <p><a href="../../raw_ops/encodeproto"><code translate="no" dir="ltr">EncodeProto(...)</code></a>: The op serializes protobuf messages provided in the input tensors.</p> <p><a href="../../raw_ops/encodewav"><code translate="no" dir="ltr">EncodeWav(...)</code></a>: Encode audio data using the WAV file format.</p> <p><a href="../../raw_ops/enqueuetpuembeddingintegerbatch"><code translate="no" dir="ltr">EnqueueTPUEmbeddingIntegerBatch(...)</code></a>: An op that enqueues a list of input batch tensors to TPUEmbedding.</p> <p><a href="../../raw_ops/enqueuetpuembeddingraggedtensorbatch"><code translate="no" dir="ltr">EnqueueTPUEmbeddingRaggedTensorBatch(...)</code></a>: Eases the porting of code that uses tf.nn.embedding_lookup().</p> <p><a href="../../raw_ops/enqueuetpuembeddingsparsebatch"><code translate="no" dir="ltr">EnqueueTPUEmbeddingSparseBatch(...)</code></a>: An op that enqueues TPUEmbedding input indices from a SparseTensor.</p> <p><a href="../../raw_ops/enqueuetpuembeddingsparsetensorbatch"><code translate="no" dir="ltr">EnqueueTPUEmbeddingSparseTensorBatch(...)</code></a>: Eases the porting of code that uses tf.nn.embedding_lookup_sparse().</p> <p><a href="../../raw_ops/ensureshape"><code translate="no" dir="ltr">EnsureShape(...)</code></a>: Ensures that the tensor's shape matches the expected shape.</p> <p><a href="../../raw_ops/enter"><code translate="no" dir="ltr">Enter(...)</code></a>: Creates or finds a child frame, and makes <code translate="no" dir="ltr">data</code> available to the child frame.</p> <p><a href="../../raw_ops/equal"><code translate="no" dir="ltr">Equal(...)</code></a>: Returns the truth value of (x == y) element-wise.</p> <p><a href="../../raw_ops/erf"><code translate="no" dir="ltr">Erf(...)</code></a>: Computes the Gauss error function of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="../../raw_ops/erfc"><code translate="no" dir="ltr">Erfc(...)</code></a>: Computes the complementary error function of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="../../raw_ops/erfinv"><code translate="no" dir="ltr">Erfinv(...)</code></a></p> <p><a href="../../raw_ops/euclideannorm"><code translate="no" dir="ltr">EuclideanNorm(...)</code></a>: Computes the euclidean norm of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/exit"><code translate="no" dir="ltr">Exit(...)</code></a>: Exits the current frame to its parent frame.</p> <p><a href="../../raw_ops/exp"><code translate="no" dir="ltr">Exp(...)</code></a>: Computes exponential of x element-wise. \(y = e^x\).</p> <p><a href="../../raw_ops/expanddims"><code translate="no" dir="ltr">ExpandDims(...)</code></a>: Inserts a dimension of 1 into a tensor's shape.</p> <p><a href="../../raw_ops/experimentalassertnextdataset"><code translate="no" dir="ltr">ExperimentalAssertNextDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentalautosharddataset"><code translate="no" dir="ltr">ExperimentalAutoShardDataset(...)</code></a>: Creates a dataset that shards the input dataset.</p> <p><a href="../../raw_ops/experimentalbytesproducedstatsdataset"><code translate="no" dir="ltr">ExperimentalBytesProducedStatsDataset(...)</code></a>: Records the bytes size of each element of <code translate="no" dir="ltr">input_dataset</code> in a StatsAggregator.</p> <p><a href="../../raw_ops/experimentalcsvdataset"><code translate="no" dir="ltr">ExperimentalCSVDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentalchoosefastestdataset"><code translate="no" dir="ltr">ExperimentalChooseFastestDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentaldatasetcardinality"><code translate="no" dir="ltr">ExperimentalDatasetCardinality(...)</code></a>: Returns the cardinality of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentaldatasettotfrecord"><code translate="no" dir="ltr">ExperimentalDatasetToTFRecord(...)</code></a>: Writes the given dataset to the given file using the TFRecord format.</p> <p><a href="../../raw_ops/experimentaldensetosparsebatchdataset"><code translate="no" dir="ltr">ExperimentalDenseToSparseBatchDataset(...)</code></a>: Creates a dataset that batches input elements into a SparseTensor.</p> <p><a href="../../raw_ops/experimentaldirectedinterleavedataset"><code translate="no" dir="ltr">ExperimentalDirectedInterleaveDataset(...)</code></a>: A substitute for <code translate="no" dir="ltr">InterleaveDataset</code> on a fixed list of <code translate="no" dir="ltr">N</code> datasets.</p> <p><a href="../../raw_ops/experimentalgroupbyreducerdataset"><code translate="no" dir="ltr">ExperimentalGroupByReducerDataset(...)</code></a>: Creates a dataset that computes a group-by on <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalgroupbywindowdataset"><code translate="no" dir="ltr">ExperimentalGroupByWindowDataset(...)</code></a>: Creates a dataset that computes a windowed group-by on <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalignoreerrorsdataset"><code translate="no" dir="ltr">ExperimentalIgnoreErrorsDataset(...)</code></a>: Creates a dataset that contains the elements of <code translate="no" dir="ltr">input_dataset</code> ignoring errors.</p> <p><a href="../../raw_ops/experimentaliteratorgetdevice"><code translate="no" dir="ltr">ExperimentalIteratorGetDevice(...)</code></a>: Returns the name of the device on which <code translate="no" dir="ltr">resource</code> has been placed.</p> <p><a href="../../raw_ops/experimentallmdbdataset"><code translate="no" dir="ltr">ExperimentalLMDBDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentallatencystatsdataset"><code translate="no" dir="ltr">ExperimentalLatencyStatsDataset(...)</code></a>: Records the latency of producing <code translate="no" dir="ltr">input_dataset</code> elements in a StatsAggregator.</p> <p><a href="../../raw_ops/experimentalmapandbatchdataset"><code translate="no" dir="ltr">ExperimentalMapAndBatchDataset(...)</code></a>: Creates a dataset that fuses mapping with batching.</p> <p><a href="../../raw_ops/experimentalmapdataset"><code translate="no" dir="ltr">ExperimentalMapDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalmatchingfilesdataset"><code translate="no" dir="ltr">ExperimentalMatchingFilesDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentalmaxintraopparallelismdataset"><code translate="no" dir="ltr">ExperimentalMaxIntraOpParallelismDataset(...)</code></a>: Creates a dataset that overrides the maximum intra-op parallelism.</p> <p><a href="../../raw_ops/experimentalnonserializabledataset"><code translate="no" dir="ltr">ExperimentalNonSerializableDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentalparallelinterleavedataset"><code translate="no" dir="ltr">ExperimentalParallelInterleaveDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalparseexampledataset"><code translate="no" dir="ltr">ExperimentalParseExampleDataset(...)</code></a>: Transforms <code translate="no" dir="ltr">input_dataset</code> containing <code translate="no" dir="ltr">Example</code> protos as vectors of DT_STRING into a dataset of <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> objects representing the parsed features.</p> <p><a href="../../raw_ops/experimentalprivatethreadpooldataset"><code translate="no" dir="ltr">ExperimentalPrivateThreadPoolDataset(...)</code></a>: Creates a dataset that uses a custom thread pool to compute <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalrandomdataset"><code translate="no" dir="ltr">ExperimentalRandomDataset(...)</code></a>: Creates a Dataset that returns pseudorandom numbers.</p> <p><a href="../../raw_ops/experimentalrebatchdataset"><code translate="no" dir="ltr">ExperimentalRebatchDataset(...)</code></a>: Creates a dataset that changes the batch size.</p> <p><a href="../../raw_ops/experimentalscandataset"><code translate="no" dir="ltr">ExperimentalScanDataset(...)</code></a>: Creates a dataset successively reduces <code translate="no" dir="ltr">f</code> over the elements of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalsetstatsaggregatordataset"><code translate="no" dir="ltr">ExperimentalSetStatsAggregatorDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentalsleepdataset"><code translate="no" dir="ltr">ExperimentalSleepDataset(...)</code></a></p> <p><a href="../../raw_ops/experimentalslidingwindowdataset"><code translate="no" dir="ltr">ExperimentalSlidingWindowDataset(...)</code></a>: Creates a dataset that passes a sliding window over <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalsqldataset"><code translate="no" dir="ltr">ExperimentalSqlDataset(...)</code></a>: Creates a dataset that executes a SQL query and emits rows of the result set.</p> <p><a href="../../raw_ops/experimentalstatsaggregatorhandle"><code translate="no" dir="ltr">ExperimentalStatsAggregatorHandle(...)</code></a>: Creates a statistics manager resource.</p> <p><a href="../../raw_ops/experimentalstatsaggregatorsummary"><code translate="no" dir="ltr">ExperimentalStatsAggregatorSummary(...)</code></a>: Produces a summary of any statistics recorded by the given statistics manager.</p> <p><a href="../../raw_ops/experimentaltakewhiledataset"><code translate="no" dir="ltr">ExperimentalTakeWhileDataset(...)</code></a>: Creates a dataset that stops iteration when predicate` is false.</p> <p><a href="../../raw_ops/experimentalthreadpooldataset"><code translate="no" dir="ltr">ExperimentalThreadPoolDataset(...)</code></a>: Creates a dataset that uses a custom thread pool to compute <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalthreadpoolhandle"><code translate="no" dir="ltr">ExperimentalThreadPoolHandle(...)</code></a>: Creates a dataset that uses a custom thread pool to compute <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/experimentalunbatchdataset"><code translate="no" dir="ltr">ExperimentalUnbatchDataset(...)</code></a>: A dataset that splits the elements of its input into multiple elements.</p> <p><a href="../../raw_ops/experimentaluniquedataset"><code translate="no" dir="ltr">ExperimentalUniqueDataset(...)</code></a>: Creates a dataset that contains the unique elements of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/expint"><code translate="no" dir="ltr">Expint(...)</code></a></p> <p><a href="../../raw_ops/expm1"><code translate="no" dir="ltr">Expm1(...)</code></a>: Computes <code translate="no" dir="ltr">exp(x) - 1</code> element-wise.</p> <p><a href="../../raw_ops/extractglimpse"><code translate="no" dir="ltr">ExtractGlimpse(...)</code></a>: Extracts a glimpse from the input tensor.</p> <p><a href="../../raw_ops/extractglimpsev2"><code translate="no" dir="ltr">ExtractGlimpseV2(...)</code></a>: Extracts a glimpse from the input tensor.</p> <p><a href="../../raw_ops/extractimagepatches"><code translate="no" dir="ltr">ExtractImagePatches(...)</code></a>: Extract <code translate="no" dir="ltr">patches</code> from <code translate="no" dir="ltr">images</code> and put them in the "depth" output dimension.</p> <p><a href="../../raw_ops/extractjpegshape"><code translate="no" dir="ltr">ExtractJpegShape(...)</code></a>: Extract the shape information of a JPEG-encoded image.</p> <p><a href="../../raw_ops/extractvolumepatches"><code translate="no" dir="ltr">ExtractVolumePatches(...)</code></a>: Extract <code translate="no" dir="ltr">patches</code> from <code translate="no" dir="ltr">input</code> and put them in the <code translate="no" dir="ltr">"depth"</code> output dimension. 3D extension of <code translate="no" dir="ltr">extract_image_patches</code>.</p> <p><a href="../../raw_ops/fft"><code translate="no" dir="ltr">FFT(...)</code></a>: Fast Fourier transform.</p> <p><a href="../../raw_ops/fft2d"><code translate="no" dir="ltr">FFT2D(...)</code></a>: 2D fast Fourier transform.</p> <p><a href="../../raw_ops/fft3d"><code translate="no" dir="ltr">FFT3D(...)</code></a>: 3D fast Fourier transform.</p> <p><a href="../../raw_ops/fifoqueue"><code translate="no" dir="ltr">FIFOQueue(...)</code></a>: A queue that produces elements in first-in first-out order.</p> <p><a href="../../raw_ops/fifoqueuev2"><code translate="no" dir="ltr">FIFOQueueV2(...)</code></a>: A queue that produces elements in first-in first-out order.</p> <p><a href="../../raw_ops/fact"><code translate="no" dir="ltr">Fact(...)</code></a>: Output a fact about factorials.</p> <p><a href="../../raw_ops/fakeparam"><code translate="no" dir="ltr">FakeParam(...)</code></a>: This op is used as a placeholder in If branch functions. It doesn't provide a</p> <p><a href="../../raw_ops/fakequantwithminmaxargs"><code translate="no" dir="ltr">FakeQuantWithMinMaxArgs(...)</code></a>: Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.</p> <p><a href="../../raw_ops/fakequantwithminmaxargsgradient"><code translate="no" dir="ltr">FakeQuantWithMinMaxArgsGradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxArgs operation.</p> <p><a href="../../raw_ops/fakequantwithminmaxvars"><code translate="no" dir="ltr">FakeQuantWithMinMaxVars(...)</code></a>: Fake-quantize the 'inputs' tensor of type float via global float scalars</p> <p><a href="../../raw_ops/fakequantwithminmaxvarsgradient"><code translate="no" dir="ltr">FakeQuantWithMinMaxVarsGradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVars operation.</p> <p><a href="../../raw_ops/fakequantwithminmaxvarsperchannel"><code translate="no" dir="ltr">FakeQuantWithMinMaxVarsPerChannel(...)</code></a>: Fake-quantize the 'inputs' tensor of type float via per-channel floats</p> <p><a href="../../raw_ops/fakequantwithminmaxvarsperchannelgradient"><code translate="no" dir="ltr">FakeQuantWithMinMaxVarsPerChannelGradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.</p> <p><a href="../../raw_ops/fakequeue"><code translate="no" dir="ltr">FakeQueue(...)</code></a>: Deprecated. Do not use.</p> <p><a href="../../raw_ops/fill"><code translate="no" dir="ltr">Fill(...)</code></a>: Creates a tensor filled with a scalar value.</p> <p><a href="../../raw_ops/filterbylastcomponentdataset"><code translate="no" dir="ltr">FilterByLastComponentDataset(...)</code></a>: Creates a dataset containing elements of first component of <code translate="no" dir="ltr">input_dataset</code> having true in the last component.</p> <p><a href="../../raw_ops/filterdataset"><code translate="no" dir="ltr">FilterDataset(...)</code></a>: Creates a dataset containing elements of <code translate="no" dir="ltr">input_dataset</code> matching <code translate="no" dir="ltr">predicate</code>.</p> <p><a href="../../raw_ops/fingerprint"><code translate="no" dir="ltr">Fingerprint(...)</code></a>: Generates fingerprint values.</p> <p><a href="../../raw_ops/fixedlengthrecorddataset"><code translate="no" dir="ltr">FixedLengthRecordDataset(...)</code></a>: Creates a dataset that emits the records from one or more binary files.</p> <p><a href="../../raw_ops/fixedlengthrecorddatasetv2"><code translate="no" dir="ltr">FixedLengthRecordDatasetV2(...)</code></a></p> <p><a href="../../raw_ops/fixedlengthrecordreader"><code translate="no" dir="ltr">FixedLengthRecordReader(...)</code></a>: A Reader that outputs fixed-length records from a file.</p> <p><a href="../../raw_ops/fixedlengthrecordreaderv2"><code translate="no" dir="ltr">FixedLengthRecordReaderV2(...)</code></a>: A Reader that outputs fixed-length records from a file.</p> <p><a href="../../raw_ops/fixedunigramcandidatesampler"><code translate="no" dir="ltr">FixedUnigramCandidateSampler(...)</code></a>: Generates labels for candidate sampling with a learned unigram distribution.</p> <p><a href="../../raw_ops/flatmapdataset"><code translate="no" dir="ltr">FlatMapDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/floor"><code translate="no" dir="ltr">Floor(...)</code></a>: Returns element-wise largest integer not greater than x.</p> <p><a href="../../raw_ops/floordiv"><code translate="no" dir="ltr">FloorDiv(...)</code></a>: Returns x // y element-wise.</p> <p><a href="../../raw_ops/floormod"><code translate="no" dir="ltr">FloorMod(...)</code></a>: Returns element-wise remainder of division. When <code translate="no" dir="ltr">x &lt; 0</code> xor <code translate="no" dir="ltr">y &lt; 0</code> is</p> <p><a href="../../raw_ops/flushsummarywriter"><code translate="no" dir="ltr">FlushSummaryWriter(...)</code></a></p> <p><a href="../../raw_ops/for"><code translate="no" dir="ltr">For(...)</code></a>: ```python</p> <p><a href="../../raw_ops/fractionalavgpool"><code translate="no" dir="ltr">FractionalAvgPool(...)</code></a>: Performs fractional average pooling on the input.</p> <p><a href="../../raw_ops/fractionalavgpoolgrad"><code translate="no" dir="ltr">FractionalAvgPoolGrad(...)</code></a>: Computes gradient of the FractionalAvgPool function.</p> <p><a href="../../raw_ops/fractionalmaxpool"><code translate="no" dir="ltr">FractionalMaxPool(...)</code></a>: Performs fractional max pooling on the input.</p> <p><a href="../../raw_ops/fractionalmaxpoolgrad"><code translate="no" dir="ltr">FractionalMaxPoolGrad(...)</code></a>: Computes gradient of the FractionalMaxPool function.</p> <p><a href="../../raw_ops/fresnelcos"><code translate="no" dir="ltr">FresnelCos(...)</code></a></p> <p><a href="../../raw_ops/fresnelsin"><code translate="no" dir="ltr">FresnelSin(...)</code></a></p> <p><a href="../../raw_ops/fusedbatchnorm"><code translate="no" dir="ltr">FusedBatchNorm(...)</code></a>: Batch normalization.</p> <p><a href="../../raw_ops/fusedbatchnormgrad"><code translate="no" dir="ltr">FusedBatchNormGrad(...)</code></a>: Gradient for batch normalization.</p> <p><a href="../../raw_ops/fusedbatchnormgradv2"><code translate="no" dir="ltr">FusedBatchNormGradV2(...)</code></a>: Gradient for batch normalization.</p> <p><a href="../../raw_ops/fusedbatchnormgradv3"><code translate="no" dir="ltr">FusedBatchNormGradV3(...)</code></a>: Gradient for batch normalization.</p> <p><a href="../../raw_ops/fusedbatchnormv2"><code translate="no" dir="ltr">FusedBatchNormV2(...)</code></a>: Batch normalization.</p> <p><a href="../../raw_ops/fusedbatchnormv3"><code translate="no" dir="ltr">FusedBatchNormV3(...)</code></a>: Batch normalization.</p> <p><a href="../../raw_ops/fusedpadconv2d"><code translate="no" dir="ltr">FusedPadConv2D(...)</code></a>: Performs a padding as a preprocess during a convolution.</p> <p><a href="../../raw_ops/fusedresizeandpadconv2d"><code translate="no" dir="ltr">FusedResizeAndPadConv2D(...)</code></a>: Performs a resize and padding as a preprocess during a convolution.</p> <p><a href="../../raw_ops/grublockcell"><code translate="no" dir="ltr">GRUBlockCell(...)</code></a>: Computes the GRU cell forward propagation for 1 time step.</p> <p><a href="../../raw_ops/grublockcellgrad"><code translate="no" dir="ltr">GRUBlockCellGrad(...)</code></a>: Computes the GRU cell back-propagation for 1 time step.</p> <p><a href="../../raw_ops/gather"><code translate="no" dir="ltr">Gather(...)</code></a>: Gather slices from <code translate="no" dir="ltr">params</code> according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/gathernd"><code translate="no" dir="ltr">GatherNd(...)</code></a>: Gather slices from <code translate="no" dir="ltr">params</code> into a Tensor with shape specified by <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/gatherv2"><code translate="no" dir="ltr">GatherV2(...)</code></a>: Gather slices from <code translate="no" dir="ltr">params</code> axis <code translate="no" dir="ltr">axis</code> according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/generateboundingboxproposals"><code translate="no" dir="ltr">GenerateBoundingBoxProposals(...)</code></a>: This op produces Region of Interests from given bounding boxes(bbox_deltas) encoded wrt anchors according to eq.2 in arXiv:1506.01497</p> <p><a href="../../raw_ops/generatevocabremapping"><code translate="no" dir="ltr">GenerateVocabRemapping(...)</code></a>: Given a path to new and old vocabulary files, returns a remapping Tensor of</p> <p><a href="../../raw_ops/generatordataset"><code translate="no" dir="ltr">GeneratorDataset(...)</code></a>: Creates a dataset that invokes a function to generate elements.</p> <p><a href="../../raw_ops/getsessionhandle"><code translate="no" dir="ltr">GetSessionHandle(...)</code></a>: Store the input tensor in the state of the current session.</p> <p><a href="../../raw_ops/getsessionhandlev2"><code translate="no" dir="ltr">GetSessionHandleV2(...)</code></a>: Store the input tensor in the state of the current session.</p> <p><a href="../../raw_ops/getsessiontensor"><code translate="no" dir="ltr">GetSessionTensor(...)</code></a>: Get the value of the tensor specified by its handle.</p> <p><a href="../../raw_ops/greater"><code translate="no" dir="ltr">Greater(...)</code></a>: Returns the truth value of (x &gt; y) element-wise.</p> <p><a href="../../raw_ops/greaterequal"><code translate="no" dir="ltr">GreaterEqual(...)</code></a>: Returns the truth value of (x &gt;= y) element-wise.</p> <p><a href="../../raw_ops/groupbyreducerdataset"><code translate="no" dir="ltr">GroupByReducerDataset(...)</code></a>: Creates a dataset that computes a group-by on <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/groupbywindowdataset"><code translate="no" dir="ltr">GroupByWindowDataset(...)</code></a>: Creates a dataset that computes a windowed group-by on <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/guaranteeconst"><code translate="no" dir="ltr">GuaranteeConst(...)</code></a>: Gives a guarantee to the TF runtime that the input tensor is a constant.</p> <p><a href="../../raw_ops/hsvtorgb"><code translate="no" dir="ltr">HSVToRGB(...)</code></a>: Convert one or more images from HSV to RGB.</p> <p><a href="../../raw_ops/hashtable"><code translate="no" dir="ltr">HashTable(...)</code></a>: Creates a non-initialized hash table.</p> <p><a href="../../raw_ops/hashtablev2"><code translate="no" dir="ltr">HashTableV2(...)</code></a>: Creates a non-initialized hash table.</p> <p><a href="../../raw_ops/histogramfixedwidth"><code translate="no" dir="ltr">HistogramFixedWidth(...)</code></a>: Return histogram of values.</p> <p><a href="../../raw_ops/histogramsummary"><code translate="no" dir="ltr">HistogramSummary(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with a histogram.</p> <p><a href="../../raw_ops/ifft"><code translate="no" dir="ltr">IFFT(...)</code></a>: Inverse fast Fourier transform.</p> <p><a href="../../raw_ops/ifft2d"><code translate="no" dir="ltr">IFFT2D(...)</code></a>: Inverse 2D fast Fourier transform.</p> <p><a href="../../raw_ops/ifft3d"><code translate="no" dir="ltr">IFFT3D(...)</code></a>: Inverse 3D fast Fourier transform.</p> <p><a href="../../raw_ops/irfft"><code translate="no" dir="ltr">IRFFT(...)</code></a>: Inverse real-valued fast Fourier transform.</p> <p><a href="../../raw_ops/irfft2d"><code translate="no" dir="ltr">IRFFT2D(...)</code></a>: Inverse 2D real-valued fast Fourier transform.</p> <p><a href="../../raw_ops/irfft3d"><code translate="no" dir="ltr">IRFFT3D(...)</code></a>: Inverse 3D real-valued fast Fourier transform.</p> <p><a href="../../raw_ops/identity"><code translate="no" dir="ltr">Identity(...)</code></a>: Return a tensor with the same shape and contents as the input tensor or value.</p> <p><a href="../../raw_ops/identityn"><code translate="no" dir="ltr">IdentityN(...)</code></a>: Returns a list of tensors with the same shapes and contents as the input</p> <p><a href="../../raw_ops/identityreader"><code translate="no" dir="ltr">IdentityReader(...)</code></a>: A Reader that outputs the queued work as both the key and value.</p> <p><a href="../../raw_ops/identityreaderv2"><code translate="no" dir="ltr">IdentityReaderV2(...)</code></a>: A Reader that outputs the queued work as both the key and value.</p> <p><a href="../../raw_ops/if"><code translate="no" dir="ltr">If(...)</code></a>: output = cond ? then_branch(input) : else_branch(input)</p> <p><a href="../../raw_ops/igamma"><code translate="no" dir="ltr">Igamma(...)</code></a>: Compute the lower regularized incomplete Gamma function <code translate="no" dir="ltr">P(a, x)</code>.</p> <p><a href="../../raw_ops/igammagrada"><code translate="no" dir="ltr">IgammaGradA(...)</code></a>: Computes the gradient of <code translate="no" dir="ltr">igamma(a, x)</code> wrt <code translate="no" dir="ltr">a</code>.</p> <p><a href="../../raw_ops/igammac"><code translate="no" dir="ltr">Igammac(...)</code></a>: Compute the upper regularized incomplete Gamma function <code translate="no" dir="ltr">Q(a, x)</code>.</p> <p><a href="../../raw_ops/ignoreerrorsdataset"><code translate="no" dir="ltr">IgnoreErrorsDataset(...)</code></a>: Creates a dataset that contains the elements of <code translate="no" dir="ltr">input_dataset</code> ignoring errors.</p> <p><a href="../../raw_ops/imag"><code translate="no" dir="ltr">Imag(...)</code></a>: Returns the imaginary part of a complex number.</p> <p><a href="../../raw_ops/imageprojectivetransformv2"><code translate="no" dir="ltr">ImageProjectiveTransformV2(...)</code></a>: Applies the given transform to each of the images.</p> <p><a href="../../raw_ops/imageprojectivetransformv3"><code translate="no" dir="ltr">ImageProjectiveTransformV3(...)</code></a>: Applies the given transform to each of the images.</p> <p><a href="../../raw_ops/imagesummary"><code translate="no" dir="ltr">ImageSummary(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with images.</p> <p><a href="../../raw_ops/immutableconst"><code translate="no" dir="ltr">ImmutableConst(...)</code></a>: Returns immutable tensor from memory region.</p> <p><a href="../../raw_ops/importevent"><code translate="no" dir="ltr">ImportEvent(...)</code></a></p> <p><a href="../../raw_ops/intopk"><code translate="no" dir="ltr">InTopK(...)</code></a>: Says whether the targets are in the top <code translate="no" dir="ltr">K</code> predictions.</p> <p><a href="../../raw_ops/intopkv2"><code translate="no" dir="ltr">InTopKV2(...)</code></a>: Says whether the targets are in the top <code translate="no" dir="ltr">K</code> predictions.</p> <p><a href="../../raw_ops/infeeddequeue"><code translate="no" dir="ltr">InfeedDequeue(...)</code></a>: A placeholder op for a value that will be fed into the computation.</p> <p><a href="../../raw_ops/infeeddequeuetuple"><code translate="no" dir="ltr">InfeedDequeueTuple(...)</code></a>: Fetches multiple values from infeed as an XLA tuple.</p> <p><a href="../../raw_ops/infeedenqueue"><code translate="no" dir="ltr">InfeedEnqueue(...)</code></a>: An op which feeds a single Tensor value into the computation.</p> <p><a href="../../raw_ops/infeedenqueueprelinearizedbuffer"><code translate="no" dir="ltr">InfeedEnqueuePrelinearizedBuffer(...)</code></a>: An op which enqueues prelinearized buffer into TPU infeed.</p> <p><a href="../../raw_ops/infeedenqueuetuple"><code translate="no" dir="ltr">InfeedEnqueueTuple(...)</code></a>: Feeds multiple Tensor values into the computation as an XLA tuple.</p> <p><a href="../../raw_ops/initializetable"><code translate="no" dir="ltr">InitializeTable(...)</code></a>: Table initializer that takes two tensors for keys and values respectively.</p> <p><a href="../../raw_ops/initializetablefromdataset"><code translate="no" dir="ltr">InitializeTableFromDataset(...)</code></a></p> <p><a href="../../raw_ops/initializetablefromtextfile"><code translate="no" dir="ltr">InitializeTableFromTextFile(...)</code></a>: Initializes a table from a text file.</p> <p><a href="../../raw_ops/initializetablefromtextfilev2"><code translate="no" dir="ltr">InitializeTableFromTextFileV2(...)</code></a>: Initializes a table from a text file.</p> <p><a href="../../raw_ops/initializetablev2"><code translate="no" dir="ltr">InitializeTableV2(...)</code></a>: Table initializer that takes two tensors for keys and values respectively.</p> <p><a href="../../raw_ops/inplaceadd"><code translate="no" dir="ltr">InplaceAdd(...)</code></a>: Adds v into specified rows of x.</p> <p><a href="../../raw_ops/inplacesub"><code translate="no" dir="ltr">InplaceSub(...)</code></a>: Subtracts <code translate="no" dir="ltr">v</code> into specified rows of <code translate="no" dir="ltr">x</code>.</p> <p><a href="../../raw_ops/inplaceupdate"><code translate="no" dir="ltr">InplaceUpdate(...)</code></a>: Updates specified rows 'i' with values 'v'.</p> <p><a href="../../raw_ops/interleavedataset"><code translate="no" dir="ltr">InterleaveDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/inv"><code translate="no" dir="ltr">Inv(...)</code></a>: Computes the reciprocal of x element-wise.</p> <p><a href="../../raw_ops/invgrad"><code translate="no" dir="ltr">InvGrad(...)</code></a>: Computes the gradient for the inverse of <code translate="no" dir="ltr">x</code> wrt its input.</p> <p><a href="../../raw_ops/invert"><code translate="no" dir="ltr">Invert(...)</code></a>: Invert (flip) each bit of supported types; for example, type <code translate="no" dir="ltr">uint8</code> value 01010101 becomes 10101010.</p> <p><a href="../../raw_ops/invertpermutation"><code translate="no" dir="ltr">InvertPermutation(...)</code></a>: Computes the inverse permutation of a tensor.</p> <p><a href="../../raw_ops/isboostedtreesensembleinitialized"><code translate="no" dir="ltr">IsBoostedTreesEnsembleInitialized(...)</code></a>: Checks whether a tree ensemble has been initialized.</p> <p><a href="../../raw_ops/isboostedtreesquantilestreamresourceinitialized"><code translate="no" dir="ltr">IsBoostedTreesQuantileStreamResourceInitialized(...)</code></a>: Checks whether a quantile stream has been initialized.</p> <p><a href="../../raw_ops/isfinite"><code translate="no" dir="ltr">IsFinite(...)</code></a>: Returns which elements of x are finite.</p> <p><a href="../../raw_ops/isinf"><code translate="no" dir="ltr">IsInf(...)</code></a>: Returns which elements of x are Inf.</p> <p><a href="../../raw_ops/isnan"><code translate="no" dir="ltr">IsNan(...)</code></a>: Returns which elements of x are NaN.</p> <p><a href="../../raw_ops/isvariableinitialized"><code translate="no" dir="ltr">IsVariableInitialized(...)</code></a>: Checks whether a tensor has been initialized.</p> <p><a href="../../raw_ops/isotonicregression"><code translate="no" dir="ltr">IsotonicRegression(...)</code></a>: Solves a batch of isotonic regression problems.</p> <p><a href="../../raw_ops/iterator"><code translate="no" dir="ltr">Iterator(...)</code></a>: A container for an iterator resource.</p> <p><a href="../../raw_ops/iteratorfromstringhandle"><code translate="no" dir="ltr">IteratorFromStringHandle(...)</code></a>: Converts the given string representing a handle to an iterator to a resource.</p> <p><a href="../../raw_ops/iteratorfromstringhandlev2"><code translate="no" dir="ltr">IteratorFromStringHandleV2(...)</code></a></p> <p><a href="../../raw_ops/iteratorgetdevice"><code translate="no" dir="ltr">IteratorGetDevice(...)</code></a>: Returns the name of the device on which <code translate="no" dir="ltr">resource</code> has been placed.</p> <p><a href="../../raw_ops/iteratorgetnext"><code translate="no" dir="ltr">IteratorGetNext(...)</code></a>: Gets the next output from the given iterator .</p> <p><a href="../../raw_ops/iteratorgetnextasoptional"><code translate="no" dir="ltr">IteratorGetNextAsOptional(...)</code></a>: Gets the next output from the given iterator as an Optional variant.</p> <p><a href="../../raw_ops/iteratorgetnextsync"><code translate="no" dir="ltr">IteratorGetNextSync(...)</code></a>: Gets the next output from the given iterator.</p> <p><a href="../../raw_ops/iteratortostringhandle"><code translate="no" dir="ltr">IteratorToStringHandle(...)</code></a>: Converts the given <code translate="no" dir="ltr">resource_handle</code> representing an iterator to a string.</p> <p><a href="../../raw_ops/iteratorv2"><code translate="no" dir="ltr">IteratorV2(...)</code></a></p> <p><a href="../../raw_ops/l2loss"><code translate="no" dir="ltr">L2Loss(...)</code></a>: L2 Loss.</p> <p><a href="../../raw_ops/lmdbdataset"><code translate="no" dir="ltr">LMDBDataset(...)</code></a>: Creates a dataset that emits the key-value pairs in one or more LMDB files.</p> <p><a href="../../raw_ops/lmdbreader"><code translate="no" dir="ltr">LMDBReader(...)</code></a>: A Reader that outputs the records from a LMDB file.</p> <p><a href="../../raw_ops/lrn"><code translate="no" dir="ltr">LRN(...)</code></a>: Local Response Normalization.</p> <p><a href="../../raw_ops/lrngrad"><code translate="no" dir="ltr">LRNGrad(...)</code></a>: Gradients for Local Response Normalization.</p> <p><a href="../../raw_ops/lstmblockcell"><code translate="no" dir="ltr">LSTMBlockCell(...)</code></a>: Computes the LSTM cell forward propagation for 1 time step.</p> <p><a href="../../raw_ops/lstmblockcellgrad"><code translate="no" dir="ltr">LSTMBlockCellGrad(...)</code></a>: Computes the LSTM cell backward propagation for 1 timestep.</p> <p><a href="../../raw_ops/latencystatsdataset"><code translate="no" dir="ltr">LatencyStatsDataset(...)</code></a>: Records the latency of producing <code translate="no" dir="ltr">input_dataset</code> elements in a StatsAggregator.</p> <p><a href="../../raw_ops/leakyrelu"><code translate="no" dir="ltr">LeakyRelu(...)</code></a>: Computes rectified linear: <code translate="no" dir="ltr">max(features, features * alpha)</code>.</p> <p><a href="../../raw_ops/leakyrelugrad"><code translate="no" dir="ltr">LeakyReluGrad(...)</code></a>: Computes rectified linear gradients for a LeakyRelu operation.</p> <p><a href="../../raw_ops/learnedunigramcandidatesampler"><code translate="no" dir="ltr">LearnedUnigramCandidateSampler(...)</code></a>: Generates labels for candidate sampling with a learned unigram distribution.</p> <p><a href="../../raw_ops/leftshift"><code translate="no" dir="ltr">LeftShift(...)</code></a>: Elementwise computes the bitwise left-shift of <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>.</p> <p><a href="../../raw_ops/legacyparallelinterleavedatasetv2"><code translate="no" dir="ltr">LegacyParallelInterleaveDatasetV2(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/less"><code translate="no" dir="ltr">Less(...)</code></a>: Returns the truth value of (x &lt; y) element-wise.</p> <p><a href="../../raw_ops/lessequal"><code translate="no" dir="ltr">LessEqual(...)</code></a>: Returns the truth value of (x &lt;= y) element-wise.</p> <p><a href="../../raw_ops/lgamma"><code translate="no" dir="ltr">Lgamma(...)</code></a>: Computes the log of the absolute value of <code translate="no" dir="ltr">Gamma(x)</code> element-wise.</p> <p><a href="../../raw_ops/linspace"><code translate="no" dir="ltr">LinSpace(...)</code></a>: Generates values in an interval.</p> <p><a href="../../raw_ops/listdiff"><code translate="no" dir="ltr">ListDiff(...)</code></a>: Computes the difference between two lists of numbers or strings.</p> <p><a href="../../raw_ops/loadandremapmatrix"><code translate="no" dir="ltr">LoadAndRemapMatrix(...)</code></a>: Loads a 2-D (matrix) <code translate="no" dir="ltr">Tensor</code> with name <code translate="no" dir="ltr">old_tensor_name</code> from the checkpoint</p> <p><a href="../../raw_ops/loaddataset"><code translate="no" dir="ltr">LoadDataset(...)</code></a></p> <p><a href="../../raw_ops/loadtpuembeddingadamparameters"><code translate="no" dir="ltr">LoadTPUEmbeddingADAMParameters(...)</code></a>: Load ADAM embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingadamparametersgradaccumdebug"><code translate="no" dir="ltr">LoadTPUEmbeddingADAMParametersGradAccumDebug(...)</code></a>: Load ADAM embedding parameters with debug support.</p> <p><a href="../../raw_ops/loadtpuembeddingadadeltaparameters"><code translate="no" dir="ltr">LoadTPUEmbeddingAdadeltaParameters(...)</code></a>: Load Adadelta embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingadadeltaparametersgradaccumdebug"><code translate="no" dir="ltr">LoadTPUEmbeddingAdadeltaParametersGradAccumDebug(...)</code></a>: Load Adadelta parameters with debug support.</p> <p><a href="../../raw_ops/loadtpuembeddingadagradparameters"><code translate="no" dir="ltr">LoadTPUEmbeddingAdagradParameters(...)</code></a>: Load Adagrad embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingadagradparametersgradaccumdebug"><code translate="no" dir="ltr">LoadTPUEmbeddingAdagradParametersGradAccumDebug(...)</code></a>: Load Adagrad embedding parameters with debug support.</p> <p><a href="../../raw_ops/loadtpuembeddingcenteredrmspropparameters"><code translate="no" dir="ltr">LoadTPUEmbeddingCenteredRMSPropParameters(...)</code></a>: Load centered RMSProp embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingftrlparameters"><code translate="no" dir="ltr">LoadTPUEmbeddingFTRLParameters(...)</code></a>: Load FTRL embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingftrlparametersgradaccumdebug"><code translate="no" dir="ltr">LoadTPUEmbeddingFTRLParametersGradAccumDebug(...)</code></a>: Load FTRL embedding parameters with debug support.</p> <p><a href="../../raw_ops/loadtpuembeddingmdladagradlightparameters"><code translate="no" dir="ltr">LoadTPUEmbeddingMDLAdagradLightParameters(...)</code></a>: Load MDL Adagrad Light embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingmomentumparameters"><code translate="no" dir="ltr">LoadTPUEmbeddingMomentumParameters(...)</code></a>: Load Momentum embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingmomentumparametersgradaccumdebug"><code translate="no" dir="ltr">LoadTPUEmbeddingMomentumParametersGradAccumDebug(...)</code></a>: Load Momentum embedding parameters with debug support.</p> <p><a href="../../raw_ops/loadtpuembeddingproximaladagradparameters"><code translate="no" dir="ltr">LoadTPUEmbeddingProximalAdagradParameters(...)</code></a>: Load proximal Adagrad embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingproximaladagradparametersgradaccumdebug"><code translate="no" dir="ltr">LoadTPUEmbeddingProximalAdagradParametersGradAccumDebug(...)</code></a>: Load proximal Adagrad embedding parameters with debug support.</p> <p><a href="../../raw_ops/loadtpuembeddingproximalyogiparameters"><code translate="no" dir="ltr">LoadTPUEmbeddingProximalYogiParameters(...)</code></a></p> <p><a href="../../raw_ops/loadtpuembeddingproximalyogiparametersgradaccumdebug"><code translate="no" dir="ltr">LoadTPUEmbeddingProximalYogiParametersGradAccumDebug(...)</code></a></p> <p><a href="../../raw_ops/loadtpuembeddingrmspropparameters"><code translate="no" dir="ltr">LoadTPUEmbeddingRMSPropParameters(...)</code></a>: Load RMSProp embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingrmspropparametersgradaccumdebug"><code translate="no" dir="ltr">LoadTPUEmbeddingRMSPropParametersGradAccumDebug(...)</code></a>: Load RMSProp embedding parameters with debug support.</p> <p><a href="../../raw_ops/loadtpuembeddingstochasticgradientdescentparameters"><code translate="no" dir="ltr">LoadTPUEmbeddingStochasticGradientDescentParameters(...)</code></a>: Load SGD embedding parameters.</p> <p><a href="../../raw_ops/loadtpuembeddingstochasticgradientdescentparametersgradaccumdebug"><code translate="no" dir="ltr">LoadTPUEmbeddingStochasticGradientDescentParametersGradAccumDebug(...)</code></a>: Load SGD embedding parameters.</p> <p><a href="../../raw_ops/log"><code translate="no" dir="ltr">Log(...)</code></a>: Computes natural logarithm of x element-wise.</p> <p><a href="../../raw_ops/log1p"><code translate="no" dir="ltr">Log1p(...)</code></a>: Computes natural logarithm of (1 + x) element-wise.</p> <p><a href="../../raw_ops/logmatrixdeterminant"><code translate="no" dir="ltr">LogMatrixDeterminant(...)</code></a>: Computes the sign and the log of the absolute value of the determinant of</p> <p><a href="../../raw_ops/logsoftmax"><code translate="no" dir="ltr">LogSoftmax(...)</code></a>: Computes log softmax activations.</p> <p><a href="../../raw_ops/loguniformcandidatesampler"><code translate="no" dir="ltr">LogUniformCandidateSampler(...)</code></a>: Generates labels for candidate sampling with a log-uniform distribution.</p> <p><a href="../../raw_ops/logicaland"><code translate="no" dir="ltr">LogicalAnd(...)</code></a>: Returns the truth value of x AND y element-wise.</p> <p><a href="../../raw_ops/logicalnot"><code translate="no" dir="ltr">LogicalNot(...)</code></a>: Returns the truth value of <code translate="no" dir="ltr">NOT x</code> element-wise.</p> <p><a href="../../raw_ops/logicalor"><code translate="no" dir="ltr">LogicalOr(...)</code></a>: Returns the truth value of x OR y element-wise.</p> <p><a href="../../raw_ops/lookuptableexport"><code translate="no" dir="ltr">LookupTableExport(...)</code></a>: Outputs all keys and values in the table.</p> <p><a href="../../raw_ops/lookuptableexportv2"><code translate="no" dir="ltr">LookupTableExportV2(...)</code></a>: Outputs all keys and values in the table.</p> <p><a href="../../raw_ops/lookuptablefind"><code translate="no" dir="ltr">LookupTableFind(...)</code></a>: Looks up keys in a table, outputs the corresponding values.</p> <p><a href="../../raw_ops/lookuptablefindv2"><code translate="no" dir="ltr">LookupTableFindV2(...)</code></a>: Looks up keys in a table, outputs the corresponding values.</p> <p><a href="../../raw_ops/lookuptableimport"><code translate="no" dir="ltr">LookupTableImport(...)</code></a>: Replaces the contents of the table with the specified keys and values.</p> <p><a href="../../raw_ops/lookuptableimportv2"><code translate="no" dir="ltr">LookupTableImportV2(...)</code></a>: Replaces the contents of the table with the specified keys and values.</p> <p><a href="../../raw_ops/lookuptableinsert"><code translate="no" dir="ltr">LookupTableInsert(...)</code></a>: Updates the table to associates keys with values.</p> <p><a href="../../raw_ops/lookuptableinsertv2"><code translate="no" dir="ltr">LookupTableInsertV2(...)</code></a>: Updates the table to associates keys with values.</p> <p><a href="../../raw_ops/lookuptableremovev2"><code translate="no" dir="ltr">LookupTableRemoveV2(...)</code></a>: Removes keys and its associated values from a table.</p> <p><a href="../../raw_ops/lookuptablesize"><code translate="no" dir="ltr">LookupTableSize(...)</code></a>: Computes the number of elements in the given table.</p> <p><a href="../../raw_ops/lookuptablesizev2"><code translate="no" dir="ltr">LookupTableSizeV2(...)</code></a>: Computes the number of elements in the given table.</p> <p><a href="../../raw_ops/loopcond"><code translate="no" dir="ltr">LoopCond(...)</code></a>: Forwards the input to the output.</p> <p><a href="../../raw_ops/lowerbound"><code translate="no" dir="ltr">LowerBound(...)</code></a>: Applies lower_bound(sorted_search_values, values) along each row.</p> <p><a href="../../raw_ops/lu"><code translate="no" dir="ltr">Lu(...)</code></a>: Computes the LU decomposition of one or more square matrices.</p> <p><a href="../../raw_ops/makeiterator"><code translate="no" dir="ltr">MakeIterator(...)</code></a>: Makes a new iterator from the given <code translate="no" dir="ltr">dataset</code> and stores it in <code translate="no" dir="ltr">iterator</code>.</p> <p><a href="../../raw_ops/mapandbatchdataset"><code translate="no" dir="ltr">MapAndBatchDataset(...)</code></a>: Creates a dataset that fuses mapping with batching.</p> <p><a href="../../raw_ops/mapclear"><code translate="no" dir="ltr">MapClear(...)</code></a>: Op removes all elements in the underlying container.</p> <p><a href="../../raw_ops/mapdataset"><code translate="no" dir="ltr">MapDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/mapdefun"><code translate="no" dir="ltr">MapDefun(...)</code></a>: Maps a function on the list of tensors unpacked from arguments on dimension 0.</p> <p><a href="../../raw_ops/mapincompletesize"><code translate="no" dir="ltr">MapIncompleteSize(...)</code></a>: Op returns the number of incomplete elements in the underlying container.</p> <p><a href="../../raw_ops/mappeek"><code translate="no" dir="ltr">MapPeek(...)</code></a>: Op peeks at the values at the specified key. If the</p> <p><a href="../../raw_ops/mapsize"><code translate="no" dir="ltr">MapSize(...)</code></a>: Op returns the number of elements in the underlying container.</p> <p><a href="../../raw_ops/mapstage"><code translate="no" dir="ltr">MapStage(...)</code></a>: Stage (key, values) in the underlying container which behaves like a hashtable.</p> <p><a href="../../raw_ops/mapunstage"><code translate="no" dir="ltr">MapUnstage(...)</code></a>: Op removes and returns the values associated with the key</p> <p><a href="../../raw_ops/mapunstagenokey"><code translate="no" dir="ltr">MapUnstageNoKey(...)</code></a>: Op removes and returns a random (key, value)</p> <p><a href="../../raw_ops/matmul"><code translate="no" dir="ltr">MatMul(...)</code></a>: Multiply the matrix "a" by the matrix "b".</p> <p><a href="../../raw_ops/matchingfiles"><code translate="no" dir="ltr">MatchingFiles(...)</code></a>: Returns the set of files matching one or more glob patterns.</p> <p><a href="../../raw_ops/matchingfilesdataset"><code translate="no" dir="ltr">MatchingFilesDataset(...)</code></a></p> <p><a href="../../raw_ops/matrixbandpart"><code translate="no" dir="ltr">MatrixBandPart(...)</code></a>: Copy a tensor setting everything outside a central band in each innermost matrix to zero.</p> <p><a href="../../raw_ops/matrixdeterminant"><code translate="no" dir="ltr">MatrixDeterminant(...)</code></a>: Computes the determinant of one or more square matrices.</p> <p><a href="../../raw_ops/matrixdiag"><code translate="no" dir="ltr">MatrixDiag(...)</code></a>: Returns a batched diagonal tensor with a given batched diagonal values.</p> <p><a href="../../raw_ops/matrixdiagpart"><code translate="no" dir="ltr">MatrixDiagPart(...)</code></a>: Returns the batched diagonal part of a batched tensor.</p> <p><a href="../../raw_ops/matrixdiagpartv2"><code translate="no" dir="ltr">MatrixDiagPartV2(...)</code></a>: Returns the batched diagonal part of a batched tensor.</p> <p><a href="../../raw_ops/matrixdiagpartv3"><code translate="no" dir="ltr">MatrixDiagPartV3(...)</code></a>: Returns the batched diagonal part of a batched tensor.</p> <p><a href="../../raw_ops/matrixdiagv2"><code translate="no" dir="ltr">MatrixDiagV2(...)</code></a>: Returns a batched diagonal tensor with given batched diagonal values.</p> <p><a href="../../raw_ops/matrixdiagv3"><code translate="no" dir="ltr">MatrixDiagV3(...)</code></a>: Returns a batched diagonal tensor with given batched diagonal values.</p> <p><a href="../../raw_ops/matrixexponential"><code translate="no" dir="ltr">MatrixExponential(...)</code></a>: Deprecated, use python implementation tf.linalg.matrix_exponential.</p> <p><a href="../../raw_ops/matrixinverse"><code translate="no" dir="ltr">MatrixInverse(...)</code></a>: Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).</p> <p><a href="../../raw_ops/matrixlogarithm"><code translate="no" dir="ltr">MatrixLogarithm(...)</code></a>: Computes the matrix logarithm of one or more square matrices:</p> <p><a href="../../raw_ops/matrixsetdiag"><code translate="no" dir="ltr">MatrixSetDiag(...)</code></a>: Returns a batched matrix tensor with new batched diagonal values.</p> <p><a href="../../raw_ops/matrixsetdiagv2"><code translate="no" dir="ltr">MatrixSetDiagV2(...)</code></a>: Returns a batched matrix tensor with new batched diagonal values.</p> <p><a href="../../raw_ops/matrixsetdiagv3"><code translate="no" dir="ltr">MatrixSetDiagV3(...)</code></a>: Returns a batched matrix tensor with new batched diagonal values.</p> <p><a href="../../raw_ops/matrixsolve"><code translate="no" dir="ltr">MatrixSolve(...)</code></a>: Solves systems of linear equations.</p> <p><a href="../../raw_ops/matrixsolvels"><code translate="no" dir="ltr">MatrixSolveLs(...)</code></a>: Solves one or more linear least-squares problems.</p> <p><a href="../../raw_ops/matrixsquareroot"><code translate="no" dir="ltr">MatrixSquareRoot(...)</code></a>: Computes the matrix square root of one or more square matrices:</p> <p><a href="../../raw_ops/matrixtriangularsolve"><code translate="no" dir="ltr">MatrixTriangularSolve(...)</code></a>: Solves systems of linear equations with upper or lower triangular matrices by backsubstitution.</p> <p><a href="../../raw_ops/max"><code translate="no" dir="ltr">Max(...)</code></a>: Computes the maximum of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/maxintraopparallelismdataset"><code translate="no" dir="ltr">MaxIntraOpParallelismDataset(...)</code></a>: Creates a dataset that overrides the maximum intra-op parallelism.</p> <p><a href="../../raw_ops/maxpool"><code translate="no" dir="ltr">MaxPool(...)</code></a>: Performs max pooling on the input.</p> <p><a href="../../raw_ops/maxpool3d"><code translate="no" dir="ltr">MaxPool3D(...)</code></a>: Performs 3D max pooling on the input.</p> <p><a href="../../raw_ops/maxpool3dgrad"><code translate="no" dir="ltr">MaxPool3DGrad(...)</code></a>: Computes gradients of 3D max pooling function.</p> <p><a href="../../raw_ops/maxpool3dgradgrad"><code translate="no" dir="ltr">MaxPool3DGradGrad(...)</code></a>: Computes second-order gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolgrad"><code translate="no" dir="ltr">MaxPoolGrad(...)</code></a>: Computes gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolgradgrad"><code translate="no" dir="ltr">MaxPoolGradGrad(...)</code></a>: Computes second-order gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolgradgradv2"><code translate="no" dir="ltr">MaxPoolGradGradV2(...)</code></a>: Computes second-order gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolgradgradwithargmax"><code translate="no" dir="ltr">MaxPoolGradGradWithArgmax(...)</code></a>: Computes second-order gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolgradv2"><code translate="no" dir="ltr">MaxPoolGradV2(...)</code></a>: Computes gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolgradwithargmax"><code translate="no" dir="ltr">MaxPoolGradWithArgmax(...)</code></a>: Computes gradients of the maxpooling function.</p> <p><a href="../../raw_ops/maxpoolv2"><code translate="no" dir="ltr">MaxPoolV2(...)</code></a>: Performs max pooling on the input.</p> <p><a href="../../raw_ops/maxpoolwithargmax"><code translate="no" dir="ltr">MaxPoolWithArgmax(...)</code></a>: Performs max pooling on the input and outputs both max values and indices.</p> <p><a href="../../raw_ops/maximum"><code translate="no" dir="ltr">Maximum(...)</code></a>: Returns the max of x and y (i.e. x &gt; y ? x : y) element-wise.</p> <p><a href="../../raw_ops/mean"><code translate="no" dir="ltr">Mean(...)</code></a>: Computes the mean of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/merge"><code translate="no" dir="ltr">Merge(...)</code></a>: Forwards the value of an available tensor from <code translate="no" dir="ltr">inputs</code> to <code translate="no" dir="ltr">output</code>.</p> <p><a href="../../raw_ops/mergesummary"><code translate="no" dir="ltr">MergeSummary(...)</code></a>: Merges summaries.</p> <p><a href="../../raw_ops/mergev2checkpoints"><code translate="no" dir="ltr">MergeV2Checkpoints(...)</code></a>: V2 format specific: merges the metadata files of sharded checkpoints. The</p> <p><a href="../../raw_ops/mfcc"><code translate="no" dir="ltr">Mfcc(...)</code></a>: Transforms a spectrogram into a form that's useful for speech recognition.</p> <p><a href="../../raw_ops/min"><code translate="no" dir="ltr">Min(...)</code></a>: Computes the minimum of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/minimum"><code translate="no" dir="ltr">Minimum(...)</code></a>: Returns the min of x and y (i.e. x &lt; y ? x : y) element-wise.</p> <p><a href="../../raw_ops/mirrorpad"><code translate="no" dir="ltr">MirrorPad(...)</code></a>: Pads a tensor with mirrored values.</p> <p><a href="../../raw_ops/mirrorpadgrad"><code translate="no" dir="ltr">MirrorPadGrad(...)</code></a>: Gradient op for <code translate="no" dir="ltr">MirrorPad</code> op. This op folds a mirror-padded tensor.</p> <p><a href="../../raw_ops/mod"><code translate="no" dir="ltr">Mod(...)</code></a>: Returns element-wise remainder of division. This emulates C semantics in that</p> <p><a href="../../raw_ops/modeldataset"><code translate="no" dir="ltr">ModelDataset(...)</code></a>: Identity transformation that models performance.</p> <p><a href="../../raw_ops/mul"><code translate="no" dir="ltr">Mul(...)</code></a>: Returns x * y element-wise.</p> <p><a href="../../raw_ops/mulnonan"><code translate="no" dir="ltr">MulNoNan(...)</code></a>: Returns x * y element-wise. Returns zero if y is zero, even if x if infinite or NaN.</p> <p><a href="../../raw_ops/multideviceiterator"><code translate="no" dir="ltr">MultiDeviceIterator(...)</code></a>: Creates a MultiDeviceIterator resource.</p> <p><a href="../../raw_ops/multideviceiteratorfromstringhandle"><code translate="no" dir="ltr">MultiDeviceIteratorFromStringHandle(...)</code></a>: Generates a MultiDeviceIterator resource from its provided string handle.</p> <p><a href="../../raw_ops/multideviceiteratorgetnextfromshard"><code translate="no" dir="ltr">MultiDeviceIteratorGetNextFromShard(...)</code></a>: Gets next element for the provided shard number.</p> <p><a href="../../raw_ops/multideviceiteratorinit"><code translate="no" dir="ltr">MultiDeviceIteratorInit(...)</code></a>: Initializes the multi device iterator with the given dataset.</p> <p><a href="../../raw_ops/multideviceiteratortostringhandle"><code translate="no" dir="ltr">MultiDeviceIteratorToStringHandle(...)</code></a>: Produces a string handle for the given MultiDeviceIterator.</p> <p><a href="../../raw_ops/multinomial"><code translate="no" dir="ltr">Multinomial(...)</code></a>: Draws samples from a multinomial distribution.</p> <p><a href="../../raw_ops/mutabledensehashtable"><code translate="no" dir="ltr">MutableDenseHashTable(...)</code></a>: Creates an empty hash table that uses tensors as the backing store.</p> <p><a href="../../raw_ops/mutabledensehashtablev2"><code translate="no" dir="ltr">MutableDenseHashTableV2(...)</code></a>: Creates an empty hash table that uses tensors as the backing store.</p> <p><a href="../../raw_ops/mutablehashtable"><code translate="no" dir="ltr">MutableHashTable(...)</code></a>: Creates an empty hash table.</p> <p><a href="../../raw_ops/mutablehashtableoftensors"><code translate="no" dir="ltr">MutableHashTableOfTensors(...)</code></a>: Creates an empty hash table.</p> <p><a href="../../raw_ops/mutablehashtableoftensorsv2"><code translate="no" dir="ltr">MutableHashTableOfTensorsV2(...)</code></a>: Creates an empty hash table.</p> <p><a href="../../raw_ops/mutablehashtablev2"><code translate="no" dir="ltr">MutableHashTableV2(...)</code></a>: Creates an empty hash table.</p> <p><a href="../../raw_ops/mutexlock"><code translate="no" dir="ltr">MutexLock(...)</code></a>: Locks a mutex resource. The output is the lock. So long as the lock tensor</p> <p><a href="../../raw_ops/mutexv2"><code translate="no" dir="ltr">MutexV2(...)</code></a>: Creates a Mutex resource that can be locked by <code translate="no" dir="ltr">MutexLock</code>.</p> <p><a href="../../raw_ops/ncclallreduce"><code translate="no" dir="ltr">NcclAllReduce(...)</code></a>: Outputs a tensor containing the reduction across all input tensors.</p> <p><a href="../../raw_ops/ncclbroadcast"><code translate="no" dir="ltr">NcclBroadcast(...)</code></a>: Sends <code translate="no" dir="ltr">input</code> to all devices that are connected to the output.</p> <p><a href="../../raw_ops/ncclreduce"><code translate="no" dir="ltr">NcclReduce(...)</code></a>: Reduces <code translate="no" dir="ltr">input</code> from <code translate="no" dir="ltr">num_devices</code> using <code translate="no" dir="ltr">reduction</code> to a single device.</p> <p><a href="../../raw_ops/ndtri"><code translate="no" dir="ltr">Ndtri(...)</code></a></p> <p><a href="../../raw_ops/neg"><code translate="no" dir="ltr">Neg(...)</code></a>: Computes numerical negative value element-wise.</p> <p><a href="../../raw_ops/nextafter"><code translate="no" dir="ltr">NextAfter(...)</code></a>: Returns the next representable value of <code translate="no" dir="ltr">x1</code> in the direction of <code translate="no" dir="ltr">x2</code>, element-wise.</p> <p><a href="../../raw_ops/nextiteration"><code translate="no" dir="ltr">NextIteration(...)</code></a>: Makes its input available to the next iteration.</p> <p><a href="../../raw_ops/noop"><code translate="no" dir="ltr">NoOp(...)</code></a>: Does nothing. Only useful as a placeholder for control edges.</p> <p><a href="../../raw_ops/nondeterministicints"><code translate="no" dir="ltr">NonDeterministicInts(...)</code></a>: Non-deterministically generates some integers.</p> <p><a href="../../raw_ops/nonmaxsuppression"><code translate="no" dir="ltr">NonMaxSuppression(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/nonmaxsuppressionv2"><code translate="no" dir="ltr">NonMaxSuppressionV2(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/nonmaxsuppressionv3"><code translate="no" dir="ltr">NonMaxSuppressionV3(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/nonmaxsuppressionv4"><code translate="no" dir="ltr">NonMaxSuppressionV4(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/nonmaxsuppressionv5"><code translate="no" dir="ltr">NonMaxSuppressionV5(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/nonmaxsuppressionwithoverlaps"><code translate="no" dir="ltr">NonMaxSuppressionWithOverlaps(...)</code></a>: Greedily selects a subset of bounding boxes in descending order of score,</p> <p><a href="../../raw_ops/nonserializabledataset"><code translate="no" dir="ltr">NonSerializableDataset(...)</code></a></p> <p><a href="../../raw_ops/notequal"><code translate="no" dir="ltr">NotEqual(...)</code></a>: Returns the truth value of (x != y) element-wise.</p> <p><a href="../../raw_ops/nthelement"><code translate="no" dir="ltr">NthElement(...)</code></a>: Finds values of the <code translate="no" dir="ltr">n</code>-th order statistic for the last dimension.</p> <p><a href="../../raw_ops/onehot"><code translate="no" dir="ltr">OneHot(...)</code></a>: Returns a one-hot tensor.</p> <p><a href="../../raw_ops/oneshotiterator"><code translate="no" dir="ltr">OneShotIterator(...)</code></a>: Makes a "one-shot" iterator that can be iterated only once.</p> <p><a href="../../raw_ops/oneslike"><code translate="no" dir="ltr">OnesLike(...)</code></a>: Returns a tensor of ones with the same shape and type as x.</p> <p><a href="../../raw_ops/optimizedataset"><code translate="no" dir="ltr">OptimizeDataset(...)</code></a>: Creates a dataset by applying optimizations to <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/optimizedatasetv2"><code translate="no" dir="ltr">OptimizeDatasetV2(...)</code></a>: Creates a dataset by applying related optimizations to <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/optionalfromvalue"><code translate="no" dir="ltr">OptionalFromValue(...)</code></a>: Constructs an Optional variant from a tuple of tensors.</p> <p><a href="../../raw_ops/optionalgetvalue"><code translate="no" dir="ltr">OptionalGetValue(...)</code></a>: Returns the value stored in an Optional variant or raises an error if none exists.</p> <p><a href="../../raw_ops/optionalhasvalue"><code translate="no" dir="ltr">OptionalHasValue(...)</code></a>: Returns true if and only if the given Optional variant has a value.</p> <p><a href="../../raw_ops/optionalnone"><code translate="no" dir="ltr">OptionalNone(...)</code></a>: Creates an Optional variant with no value.</p> <p><a href="../../raw_ops/orderedmapclear"><code translate="no" dir="ltr">OrderedMapClear(...)</code></a>: Op removes all elements in the underlying container.</p> <p><a href="../../raw_ops/orderedmapincompletesize"><code translate="no" dir="ltr">OrderedMapIncompleteSize(...)</code></a>: Op returns the number of incomplete elements in the underlying container.</p> <p><a href="../../raw_ops/orderedmappeek"><code translate="no" dir="ltr">OrderedMapPeek(...)</code></a>: Op peeks at the values at the specified key. If the</p> <p><a href="../../raw_ops/orderedmapsize"><code translate="no" dir="ltr">OrderedMapSize(...)</code></a>: Op returns the number of elements in the underlying container.</p> <p><a href="../../raw_ops/orderedmapstage"><code translate="no" dir="ltr">OrderedMapStage(...)</code></a>: Stage (key, values) in the underlying container which behaves like a ordered</p> <p><a href="../../raw_ops/orderedmapunstage"><code translate="no" dir="ltr">OrderedMapUnstage(...)</code></a>: Op removes and returns the values associated with the key</p> <p><a href="../../raw_ops/orderedmapunstagenokey"><code translate="no" dir="ltr">OrderedMapUnstageNoKey(...)</code></a>: Op removes and returns the (key, value) element with the smallest</p> <p><a href="../../raw_ops/outfeeddequeue"><code translate="no" dir="ltr">OutfeedDequeue(...)</code></a>: Retrieves a single tensor from the computation outfeed.</p> <p><a href="../../raw_ops/outfeeddequeuetuple"><code translate="no" dir="ltr">OutfeedDequeueTuple(...)</code></a>: Retrieve multiple values from the computation outfeed.</p> <p><a href="../../raw_ops/outfeeddequeuetuplev2"><code translate="no" dir="ltr">OutfeedDequeueTupleV2(...)</code></a>: Retrieve multiple values from the computation outfeed. Device ordinal is a</p> <p><a href="../../raw_ops/outfeeddequeuev2"><code translate="no" dir="ltr">OutfeedDequeueV2(...)</code></a>: Retrieves a single tensor from the computation outfeed. Device ordinal is a</p> <p><a href="../../raw_ops/outfeedenqueue"><code translate="no" dir="ltr">OutfeedEnqueue(...)</code></a>: Enqueue a Tensor on the computation outfeed.</p> <p><a href="../../raw_ops/outfeedenqueuetuple"><code translate="no" dir="ltr">OutfeedEnqueueTuple(...)</code></a>: Enqueue multiple Tensor values on the computation outfeed.</p> <p><a href="../../raw_ops/pack"><code translate="no" dir="ltr">Pack(...)</code></a>: Packs a list of <code translate="no" dir="ltr">N</code> rank-<code translate="no" dir="ltr">R</code> tensors into one rank-<code translate="no" dir="ltr">(R+1)</code> tensor.</p> <p><a href="../../raw_ops/pad"><code translate="no" dir="ltr">Pad(...)</code></a>: Pads a tensor with zeros.</p> <p><a href="../../raw_ops/padv2"><code translate="no" dir="ltr">PadV2(...)</code></a>: Pads a tensor.</p> <p><a href="../../raw_ops/paddedbatchdataset"><code translate="no" dir="ltr">PaddedBatchDataset(...)</code></a>: Creates a dataset that batches and pads <code translate="no" dir="ltr">batch_size</code> elements from the input.</p> <p><a href="../../raw_ops/paddedbatchdatasetv2"><code translate="no" dir="ltr">PaddedBatchDatasetV2(...)</code></a>: Creates a dataset that batches and pads <code translate="no" dir="ltr">batch_size</code> elements from the input.</p> <p><a href="../../raw_ops/paddingfifoqueue"><code translate="no" dir="ltr">PaddingFIFOQueue(...)</code></a>: A queue that produces elements in first-in first-out order.</p> <p><a href="../../raw_ops/paddingfifoqueuev2"><code translate="no" dir="ltr">PaddingFIFOQueueV2(...)</code></a>: A queue that produces elements in first-in first-out order.</p> <p><a href="../../raw_ops/parallelconcat"><code translate="no" dir="ltr">ParallelConcat(...)</code></a>: Concatenates a list of <code translate="no" dir="ltr">N</code> tensors along the first dimension.</p> <p><a href="../../raw_ops/paralleldynamicstitch"><code translate="no" dir="ltr">ParallelDynamicStitch(...)</code></a>: Interleave the values from the <code translate="no" dir="ltr">data</code> tensors into a single tensor.</p> <p><a href="../../raw_ops/parallelinterleavedataset"><code translate="no" dir="ltr">ParallelInterleaveDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/parallelinterleavedatasetv2"><code translate="no" dir="ltr">ParallelInterleaveDatasetV2(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/parallelinterleavedatasetv3"><code translate="no" dir="ltr">ParallelInterleaveDatasetV3(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/parallelinterleavedatasetv4"><code translate="no" dir="ltr">ParallelInterleaveDatasetV4(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/parallelmapdataset"><code translate="no" dir="ltr">ParallelMapDataset(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/parallelmapdatasetv2"><code translate="no" dir="ltr">ParallelMapDatasetV2(...)</code></a>: Creates a dataset that applies <code translate="no" dir="ltr">f</code> to the outputs of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/parameterizedtruncatednormal"><code translate="no" dir="ltr">ParameterizedTruncatedNormal(...)</code></a>: Outputs random values from a normal distribution. The parameters may each be a</p> <p><a href="../../raw_ops/parseexample"><code translate="no" dir="ltr">ParseExample(...)</code></a>: Transforms a vector of brain.Example protos (as strings) into typed tensors.</p> <p><a href="../../raw_ops/parseexampledataset"><code translate="no" dir="ltr">ParseExampleDataset(...)</code></a>: Transforms <code translate="no" dir="ltr">input_dataset</code> containing <code translate="no" dir="ltr">Example</code> protos as vectors of DT_STRING into a dataset of <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> objects representing the parsed features.</p> <p><a href="../../raw_ops/parseexampledatasetv2"><code translate="no" dir="ltr">ParseExampleDatasetV2(...)</code></a>: Transforms <code translate="no" dir="ltr">input_dataset</code> containing <code translate="no" dir="ltr">Example</code> protos as vectors of DT_STRING into a dataset of <code translate="no" dir="ltr">Tensor</code> or <code translate="no" dir="ltr">SparseTensor</code> objects representing the parsed features.</p> <p><a href="../../raw_ops/parseexamplev2"><code translate="no" dir="ltr">ParseExampleV2(...)</code></a>: Transforms a vector of tf.Example protos (as strings) into typed tensors.</p> <p><a href="../../raw_ops/parsesequenceexample"><code translate="no" dir="ltr">ParseSequenceExample(...)</code></a>: Transforms a vector of brain.SequenceExample protos (as strings) into typed tensors.</p> <p><a href="../../raw_ops/parsesequenceexamplev2"><code translate="no" dir="ltr">ParseSequenceExampleV2(...)</code></a>: Transforms a vector of tf.io.SequenceExample protos (as strings) into</p> <p><a href="../../raw_ops/parsesingleexample"><code translate="no" dir="ltr">ParseSingleExample(...)</code></a>: Transforms a tf.Example proto (as a string) into typed tensors.</p> <p><a href="../../raw_ops/parsesinglesequenceexample"><code translate="no" dir="ltr">ParseSingleSequenceExample(...)</code></a>: Transforms a scalar brain.SequenceExample proto (as strings) into typed tensors.</p> <p><a href="../../raw_ops/parsetensor"><code translate="no" dir="ltr">ParseTensor(...)</code></a>: Transforms a serialized tensorflow.TensorProto proto into a Tensor.</p> <p><a href="../../raw_ops/partitionedcall"><code translate="no" dir="ltr">PartitionedCall(...)</code></a>: returns <code translate="no" dir="ltr">f(inputs)</code>, where <code translate="no" dir="ltr">f</code>'s body is placed and partitioned.</p> <p><a href="../../raw_ops/placeholder"><code translate="no" dir="ltr">Placeholder(...)</code></a>: A placeholder op for a value that will be fed into the computation.</p> <p><a href="../../raw_ops/placeholderv2"><code translate="no" dir="ltr">PlaceholderV2(...)</code></a>: A placeholder op for a value that will be fed into the computation.</p> <p><a href="../../raw_ops/placeholderwithdefault"><code translate="no" dir="ltr">PlaceholderWithDefault(...)</code></a>: A placeholder op that passes through <code translate="no" dir="ltr">input</code> when its output is not fed.</p> <p><a href="../../raw_ops/polygamma"><code translate="no" dir="ltr">Polygamma(...)</code></a>: Compute the polygamma function \(\psi^{(n)}(x)\).</p> <p><a href="../../raw_ops/populationcount"><code translate="no" dir="ltr">PopulationCount(...)</code></a>: Computes element-wise population count (a.k.a. popcount, bitsum, bitcount).</p> <p><a href="../../raw_ops/pow"><code translate="no" dir="ltr">Pow(...)</code></a>: Computes the power of one value to another.</p> <p><a href="../../raw_ops/prefetchdataset"><code translate="no" dir="ltr">PrefetchDataset(...)</code></a>: Creates a dataset that asynchronously prefetches elements from <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/prelinearize"><code translate="no" dir="ltr">Prelinearize(...)</code></a>: An op which linearizes one Tensor value to an opaque variant tensor.</p> <p><a href="../../raw_ops/prelinearizetuple"><code translate="no" dir="ltr">PrelinearizeTuple(...)</code></a>: An op which linearizes multiple Tensor values to an opaque variant tensor.</p> <p><a href="../../raw_ops/preventgradient"><code translate="no" dir="ltr">PreventGradient(...)</code></a>: An identity op that triggers an error if a gradient is requested.</p> <p><a href="../../raw_ops/print"><code translate="no" dir="ltr">Print(...)</code></a>: Prints a list of tensors.</p> <p><a href="../../raw_ops/printv2"><code translate="no" dir="ltr">PrintV2(...)</code></a>: Prints a string scalar.</p> <p><a href="../../raw_ops/priorityqueue"><code translate="no" dir="ltr">PriorityQueue(...)</code></a>: A queue that produces elements sorted by the first component value.</p> <p><a href="../../raw_ops/priorityqueuev2"><code translate="no" dir="ltr">PriorityQueueV2(...)</code></a>: A queue that produces elements sorted by the first component value.</p> <p><a href="../../raw_ops/privatethreadpooldataset"><code translate="no" dir="ltr">PrivateThreadPoolDataset(...)</code></a>: Creates a dataset that uses a custom thread pool to compute <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/prod"><code translate="no" dir="ltr">Prod(...)</code></a>: Computes the product of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/pyfunc"><code translate="no" dir="ltr">PyFunc(...)</code></a>: Invokes a python function to compute func(input)-&gt;output.</p> <p><a href="../../raw_ops/pyfuncstateless"><code translate="no" dir="ltr">PyFuncStateless(...)</code></a>: A stateless version of PyFunc.</p> <p><a href="../../raw_ops/qr"><code translate="no" dir="ltr">Qr(...)</code></a>: Computes the QR decompositions of one or more matrices.</p> <p><a href="../../raw_ops/quantizeanddequantize"><code translate="no" dir="ltr">QuantizeAndDequantize(...)</code></a>: Use QuantizeAndDequantizeV2 instead.</p> <p><a href="../../raw_ops/quantizeanddequantizev2"><code translate="no" dir="ltr">QuantizeAndDequantizeV2(...)</code></a>: Quantizes then dequantizes a tensor.</p> <p><a href="../../raw_ops/quantizeanddequantizev3"><code translate="no" dir="ltr">QuantizeAndDequantizeV3(...)</code></a>: Quantizes then dequantizes a tensor.</p> <p><a href="../../raw_ops/quantizeanddequantizev4"><code translate="no" dir="ltr">QuantizeAndDequantizeV4(...)</code></a>: Returns the gradient of <code translate="no" dir="ltr">QuantizeAndDequantizeV4</code>.</p> <p><a href="../../raw_ops/quantizeanddequantizev4grad"><code translate="no" dir="ltr">QuantizeAndDequantizeV4Grad(...)</code></a>: Returns the gradient of <code translate="no" dir="ltr">QuantizeAndDequantizeV4</code>.</p> <p><a href="../../raw_ops/quantizedownandshrinkrange"><code translate="no" dir="ltr">QuantizeDownAndShrinkRange(...)</code></a>: Convert the quantized 'input' tensor into a lower-precision 'output', using the</p> <p><a href="../../raw_ops/quantizev2"><code translate="no" dir="ltr">QuantizeV2(...)</code></a>: Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.</p> <p><a href="../../raw_ops/quantizedadd"><code translate="no" dir="ltr">QuantizedAdd(...)</code></a>: Returns x + y element-wise, working on quantized buffers.</p> <p><a href="../../raw_ops/quantizedavgpool"><code translate="no" dir="ltr">QuantizedAvgPool(...)</code></a>: Produces the average pool of the input tensor for quantized types.</p> <p><a href="../../raw_ops/quantizedbatchnormwithglobalnormalization"><code translate="no" dir="ltr">QuantizedBatchNormWithGlobalNormalization(...)</code></a>: Quantized Batch normalization.</p> <p><a href="../../raw_ops/quantizedbiasadd"><code translate="no" dir="ltr">QuantizedBiasAdd(...)</code></a>: Adds Tensor 'bias' to Tensor 'input' for Quantized types.</p> <p><a href="../../raw_ops/quantizedconcat"><code translate="no" dir="ltr">QuantizedConcat(...)</code></a>: Concatenates quantized tensors along one dimension.</p> <p><a href="../../raw_ops/quantizedconv2d"><code translate="no" dir="ltr">QuantizedConv2D(...)</code></a>: Computes a 2D convolution given quantized 4D input and filter tensors.</p> <p><a href="../../raw_ops/quantizedconv2dandrelu"><code translate="no" dir="ltr">QuantizedConv2DAndRelu(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dandreluandrequantize"><code translate="no" dir="ltr">QuantizedConv2DAndReluAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dandrequantize"><code translate="no" dir="ltr">QuantizedConv2DAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dperchannel"><code translate="no" dir="ltr">QuantizedConv2DPerChannel(...)</code></a>: Computes QuantizedConv2D per channel.</p> <p><a href="../../raw_ops/quantizedconv2dwithbias"><code translate="no" dir="ltr">QuantizedConv2DWithBias(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dwithbiasandrelu"><code translate="no" dir="ltr">QuantizedConv2DWithBiasAndRelu(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dwithbiasandreluandrequantize"><code translate="no" dir="ltr">QuantizedConv2DWithBiasAndReluAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dwithbiasandrequantize"><code translate="no" dir="ltr">QuantizedConv2DWithBiasAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dwithbiassignedsumandreluandrequantize"><code translate="no" dir="ltr">QuantizedConv2DWithBiasSignedSumAndReluAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dwithbiassumandrelu"><code translate="no" dir="ltr">QuantizedConv2DWithBiasSumAndRelu(...)</code></a></p> <p><a href="../../raw_ops/quantizedconv2dwithbiassumandreluandrequantize"><code translate="no" dir="ltr">QuantizedConv2DWithBiasSumAndReluAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizeddepthwiseconv2d"><code translate="no" dir="ltr">QuantizedDepthwiseConv2D(...)</code></a>: Computes quantized depthwise Conv2D.</p> <p><a href="../../raw_ops/quantizeddepthwiseconv2dwithbias"><code translate="no" dir="ltr">QuantizedDepthwiseConv2DWithBias(...)</code></a>: Computes quantized depthwise Conv2D with Bias.</p> <p><a href="../../raw_ops/quantizeddepthwiseconv2dwithbiasandrelu"><code translate="no" dir="ltr">QuantizedDepthwiseConv2DWithBiasAndRelu(...)</code></a>: Computes quantized depthwise Conv2D with Bias and Relu.</p> <p><a href="../../raw_ops/quantizeddepthwiseconv2dwithbiasandreluandrequantize"><code translate="no" dir="ltr">QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize(...)</code></a>: Computes quantized depthwise Conv2D with Bias, Relu and Requantize.</p> <p><a href="../../raw_ops/quantizedinstancenorm"><code translate="no" dir="ltr">QuantizedInstanceNorm(...)</code></a>: Quantized Instance normalization.</p> <p><a href="../../raw_ops/quantizedmatmul"><code translate="no" dir="ltr">QuantizedMatMul(...)</code></a>: Perform a quantized matrix multiplication of <code translate="no" dir="ltr">a</code> by the matrix <code translate="no" dir="ltr">b</code>.</p> <p><a href="../../raw_ops/quantizedmatmulwithbias"><code translate="no" dir="ltr">QuantizedMatMulWithBias(...)</code></a>: Performs a quantized matrix multiplication of <code translate="no" dir="ltr">a</code> by the matrix <code translate="no" dir="ltr">b</code> with bias</p> <p><a href="../../raw_ops/quantizedmatmulwithbiasanddequantize"><code translate="no" dir="ltr">QuantizedMatMulWithBiasAndDequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedmatmulwithbiasandrelu"><code translate="no" dir="ltr">QuantizedMatMulWithBiasAndRelu(...)</code></a>: Perform a quantized matrix multiplication of <code translate="no" dir="ltr">a</code> by the matrix <code translate="no" dir="ltr">b</code> with bias</p> <p><a href="../../raw_ops/quantizedmatmulwithbiasandreluandrequantize"><code translate="no" dir="ltr">QuantizedMatMulWithBiasAndReluAndRequantize(...)</code></a>: Perform a quantized matrix multiplication of <code translate="no" dir="ltr">a</code> by the matrix <code translate="no" dir="ltr">b</code> with bias</p> <p><a href="../../raw_ops/quantizedmatmulwithbiasandrequantize"><code translate="no" dir="ltr">QuantizedMatMulWithBiasAndRequantize(...)</code></a></p> <p><a href="../../raw_ops/quantizedmaxpool"><code translate="no" dir="ltr">QuantizedMaxPool(...)</code></a>: Produces the max pool of the input tensor for quantized types.</p> <p><a href="../../raw_ops/quantizedmul"><code translate="no" dir="ltr">QuantizedMul(...)</code></a>: Returns x * y element-wise, working on quantized buffers.</p> <p><a href="../../raw_ops/quantizedrelu"><code translate="no" dir="ltr">QuantizedRelu(...)</code></a>: Computes Quantized Rectified Linear: <code translate="no" dir="ltr">max(features, 0)</code></p> <p><a href="../../raw_ops/quantizedrelu6"><code translate="no" dir="ltr">QuantizedRelu6(...)</code></a>: Computes Quantized Rectified Linear 6: <code translate="no" dir="ltr">min(max(features, 0), 6)</code></p> <p><a href="../../raw_ops/quantizedrelux"><code translate="no" dir="ltr">QuantizedReluX(...)</code></a>: Computes Quantized Rectified Linear X: <code translate="no" dir="ltr">min(max(features, 0), max_value)</code></p> <p><a href="../../raw_ops/quantizedreshape"><code translate="no" dir="ltr">QuantizedReshape(...)</code></a>: Reshapes a quantized tensor as per the Reshape op.</p> <p><a href="../../raw_ops/quantizedresizebilinear"><code translate="no" dir="ltr">QuantizedResizeBilinear(...)</code></a>: Resize quantized <code translate="no" dir="ltr">images</code> to <code translate="no" dir="ltr">size</code> using quantized bilinear interpolation.</p> <p><a href="../../raw_ops/queueclose"><code translate="no" dir="ltr">QueueClose(...)</code></a>: Closes the given queue.</p> <p><a href="../../raw_ops/queueclosev2"><code translate="no" dir="ltr">QueueCloseV2(...)</code></a>: Closes the given queue.</p> <p><a href="../../raw_ops/queuedequeue"><code translate="no" dir="ltr">QueueDequeue(...)</code></a>: Dequeues a tuple of one or more tensors from the given queue.</p> <p><a href="../../raw_ops/queuedequeuemany"><code translate="no" dir="ltr">QueueDequeueMany(...)</code></a>: Dequeues <code translate="no" dir="ltr">n</code> tuples of one or more tensors from the given queue.</p> <p><a href="../../raw_ops/queuedequeuemanyv2"><code translate="no" dir="ltr">QueueDequeueManyV2(...)</code></a>: Dequeues <code translate="no" dir="ltr">n</code> tuples of one or more tensors from the given queue.</p> <p><a href="../../raw_ops/queuedequeueupto"><code translate="no" dir="ltr">QueueDequeueUpTo(...)</code></a>: Dequeues <code translate="no" dir="ltr">n</code> tuples of one or more tensors from the given queue.</p> <p><a href="../../raw_ops/queuedequeueuptov2"><code translate="no" dir="ltr">QueueDequeueUpToV2(...)</code></a>: Dequeues <code translate="no" dir="ltr">n</code> tuples of one or more tensors from the given queue.</p> <p><a href="../../raw_ops/queuedequeuev2"><code translate="no" dir="ltr">QueueDequeueV2(...)</code></a>: Dequeues a tuple of one or more tensors from the given queue.</p> <p><a href="../../raw_ops/queueenqueue"><code translate="no" dir="ltr">QueueEnqueue(...)</code></a>: Enqueues a tuple of one or more tensors in the given queue.</p> <p><a href="../../raw_ops/queueenqueuemany"><code translate="no" dir="ltr">QueueEnqueueMany(...)</code></a>: Enqueues zero or more tuples of one or more tensors in the given queue.</p> <p><a href="../../raw_ops/queueenqueuemanyv2"><code translate="no" dir="ltr">QueueEnqueueManyV2(...)</code></a>: Enqueues zero or more tuples of one or more tensors in the given queue.</p> <p><a href="../../raw_ops/queueenqueuev2"><code translate="no" dir="ltr">QueueEnqueueV2(...)</code></a>: Enqueues a tuple of one or more tensors in the given queue.</p> <p><a href="../../raw_ops/queueisclosed"><code translate="no" dir="ltr">QueueIsClosed(...)</code></a>: Returns true if queue is closed.</p> <p><a href="../../raw_ops/queueisclosedv2"><code translate="no" dir="ltr">QueueIsClosedV2(...)</code></a>: Returns true if queue is closed.</p> <p><a href="../../raw_ops/queuesize"><code translate="no" dir="ltr">QueueSize(...)</code></a>: Computes the number of elements in the given queue.</p> <p><a href="../../raw_ops/queuesizev2"><code translate="no" dir="ltr">QueueSizeV2(...)</code></a>: Computes the number of elements in the given queue.</p> <p><a href="../../raw_ops/rfft"><code translate="no" dir="ltr">RFFT(...)</code></a>: Real-valued fast Fourier transform.</p> <p><a href="../../raw_ops/rfft2d"><code translate="no" dir="ltr">RFFT2D(...)</code></a>: 2D real-valued fast Fourier transform.</p> <p><a href="../../raw_ops/rfft3d"><code translate="no" dir="ltr">RFFT3D(...)</code></a>: 3D real-valued fast Fourier transform.</p> <p><a href="../../raw_ops/rgbtohsv"><code translate="no" dir="ltr">RGBToHSV(...)</code></a>: Converts one or more images from RGB to HSV.</p> <p><a href="../../raw_ops/raggedbincount"><code translate="no" dir="ltr">RaggedBincount(...)</code></a>: Counts the number of occurrences of each value in an integer array.</p> <p><a href="../../raw_ops/raggedcountsparseoutput"><code translate="no" dir="ltr">RaggedCountSparseOutput(...)</code></a>: Performs sparse-output bin counting for a ragged tensor input.</p> <p><a href="../../raw_ops/raggedcross"><code translate="no" dir="ltr">RaggedCross(...)</code></a>: Generates a feature cross from a list of tensors, and returns it as a</p> <p><a href="../../raw_ops/raggedgather"><code translate="no" dir="ltr">RaggedGather(...)</code></a>: Gather ragged slices from <code translate="no" dir="ltr">params</code> axis <code translate="no" dir="ltr">0</code> according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/raggedrange"><code translate="no" dir="ltr">RaggedRange(...)</code></a>: Returns a <code translate="no" dir="ltr">RaggedTensor</code> containing the specified sequences of numbers.</p> <p><a href="../../raw_ops/raggedtensorfromvariant"><code translate="no" dir="ltr">RaggedTensorFromVariant(...)</code></a>: Decodes a <code translate="no" dir="ltr">variant</code> Tensor into a <code translate="no" dir="ltr">RaggedTensor</code>.</p> <p><a href="../../raw_ops/raggedtensortosparse"><code translate="no" dir="ltr">RaggedTensorToSparse(...)</code></a>: Converts a <code translate="no" dir="ltr">RaggedTensor</code> into a <code translate="no" dir="ltr">SparseTensor</code> with the same values.</p> <p><a href="../../raw_ops/raggedtensortotensor"><code translate="no" dir="ltr">RaggedTensorToTensor(...)</code></a>: Create a dense tensor from a ragged tensor, possibly altering its shape.</p> <p><a href="../../raw_ops/raggedtensortovariant"><code translate="no" dir="ltr">RaggedTensorToVariant(...)</code></a>: Encodes a <code translate="no" dir="ltr">RaggedTensor</code> into a <code translate="no" dir="ltr">variant</code> Tensor.</p> <p><a href="../../raw_ops/raggedtensortovariantgradient"><code translate="no" dir="ltr">RaggedTensorToVariantGradient(...)</code></a>: Helper used to compute the gradient for <code translate="no" dir="ltr">RaggedTensorToVariant</code>.</p> <p><a href="../../raw_ops/randomcrop"><code translate="no" dir="ltr">RandomCrop(...)</code></a>: Randomly crop <code translate="no" dir="ltr">image</code>.</p> <p><a href="../../raw_ops/randomdataset"><code translate="no" dir="ltr">RandomDataset(...)</code></a>: Creates a Dataset that returns pseudorandom numbers.</p> <p><a href="../../raw_ops/randomgamma"><code translate="no" dir="ltr">RandomGamma(...)</code></a>: Outputs random values from the Gamma distribution(s) described by alpha.</p> <p><a href="../../raw_ops/randomgammagrad"><code translate="no" dir="ltr">RandomGammaGrad(...)</code></a>: Computes the derivative of a Gamma random sample w.r.t. <code translate="no" dir="ltr">alpha</code>.</p> <p><a href="../../raw_ops/randompoisson"><code translate="no" dir="ltr">RandomPoisson(...)</code></a>: Use RandomPoissonV2 instead.</p> <p><a href="../../raw_ops/randompoissonv2"><code translate="no" dir="ltr">RandomPoissonV2(...)</code></a>: Outputs random values from the Poisson distribution(s) described by rate.</p> <p><a href="../../raw_ops/randomshuffle"><code translate="no" dir="ltr">RandomShuffle(...)</code></a>: Randomly shuffles a tensor along its first dimension.</p> <p><a href="../../raw_ops/randomshufflequeue"><code translate="no" dir="ltr">RandomShuffleQueue(...)</code></a>: A queue that randomizes the order of elements.</p> <p><a href="../../raw_ops/randomshufflequeuev2"><code translate="no" dir="ltr">RandomShuffleQueueV2(...)</code></a>: A queue that randomizes the order of elements.</p> <p><a href="../../raw_ops/randomstandardnormal"><code translate="no" dir="ltr">RandomStandardNormal(...)</code></a>: Outputs random values from a normal distribution.</p> <p><a href="../../raw_ops/randomuniform"><code translate="no" dir="ltr">RandomUniform(...)</code></a>: Outputs random values from a uniform distribution.</p> <p><a href="../../raw_ops/randomuniformint"><code translate="no" dir="ltr">RandomUniformInt(...)</code></a>: Outputs random integers from a uniform distribution.</p> <p><a href="../../raw_ops/range"><code translate="no" dir="ltr">Range(...)</code></a>: Creates a sequence of numbers.</p> <p><a href="../../raw_ops/rangedataset"><code translate="no" dir="ltr">RangeDataset(...)</code></a>: Creates a dataset with a range of values. Corresponds to python's xrange.</p> <p><a href="../../raw_ops/rank"><code translate="no" dir="ltr">Rank(...)</code></a>: Returns the rank of a tensor.</p> <p><a href="../../raw_ops/readfile"><code translate="no" dir="ltr">ReadFile(...)</code></a>: Reads and outputs the entire contents of the input filename.</p> <p><a href="../../raw_ops/readvariableop"><code translate="no" dir="ltr">ReadVariableOp(...)</code></a>: Reads the value of a variable.</p> <p><a href="../../raw_ops/readernumrecordsproduced"><code translate="no" dir="ltr">ReaderNumRecordsProduced(...)</code></a>: Returns the number of records this Reader has produced.</p> <p><a href="../../raw_ops/readernumrecordsproducedv2"><code translate="no" dir="ltr">ReaderNumRecordsProducedV2(...)</code></a>: Returns the number of records this Reader has produced.</p> <p><a href="../../raw_ops/readernumworkunitscompleted"><code translate="no" dir="ltr">ReaderNumWorkUnitsCompleted(...)</code></a>: Returns the number of work units this Reader has finished processing.</p> <p><a href="../../raw_ops/readernumworkunitscompletedv2"><code translate="no" dir="ltr">ReaderNumWorkUnitsCompletedV2(...)</code></a>: Returns the number of work units this Reader has finished processing.</p> <p><a href="../../raw_ops/readerread"><code translate="no" dir="ltr">ReaderRead(...)</code></a>: Returns the next record (key, value pair) produced by a Reader.</p> <p><a href="../../raw_ops/readerreadupto"><code translate="no" dir="ltr">ReaderReadUpTo(...)</code></a>: Returns up to <code translate="no" dir="ltr">num_records</code> (key, value) pairs produced by a Reader.</p> <p><a href="../../raw_ops/readerreaduptov2"><code translate="no" dir="ltr">ReaderReadUpToV2(...)</code></a>: Returns up to <code translate="no" dir="ltr">num_records</code> (key, value) pairs produced by a Reader.</p> <p><a href="../../raw_ops/readerreadv2"><code translate="no" dir="ltr">ReaderReadV2(...)</code></a>: Returns the next record (key, value pair) produced by a Reader.</p> <p><a href="../../raw_ops/readerreset"><code translate="no" dir="ltr">ReaderReset(...)</code></a>: Restore a Reader to its initial clean state.</p> <p><a href="../../raw_ops/readerresetv2"><code translate="no" dir="ltr">ReaderResetV2(...)</code></a>: Restore a Reader to its initial clean state.</p> <p><a href="../../raw_ops/readerrestorestate"><code translate="no" dir="ltr">ReaderRestoreState(...)</code></a>: Restore a reader to a previously saved state.</p> <p><a href="../../raw_ops/readerrestorestatev2"><code translate="no" dir="ltr">ReaderRestoreStateV2(...)</code></a>: Restore a reader to a previously saved state.</p> <p><a href="../../raw_ops/readerserializestate"><code translate="no" dir="ltr">ReaderSerializeState(...)</code></a>: Produce a string tensor that encodes the state of a Reader.</p> <p><a href="../../raw_ops/readerserializestatev2"><code translate="no" dir="ltr">ReaderSerializeStateV2(...)</code></a>: Produce a string tensor that encodes the state of a Reader.</p> <p><a href="../../raw_ops/real"><code translate="no" dir="ltr">Real(...)</code></a>: Returns the real part of a complex number.</p> <p><a href="../../raw_ops/realdiv"><code translate="no" dir="ltr">RealDiv(...)</code></a>: Returns x / y element-wise for real types.</p> <p><a href="../../raw_ops/rebatchdataset"><code translate="no" dir="ltr">RebatchDataset(...)</code></a>: Creates a dataset that changes the batch size.</p> <p><a href="../../raw_ops/rebatchdatasetv2"><code translate="no" dir="ltr">RebatchDatasetV2(...)</code></a>: Creates a dataset that changes the batch size.</p> <p><a href="../../raw_ops/reciprocal"><code translate="no" dir="ltr">Reciprocal(...)</code></a>: Computes the reciprocal of x element-wise.</p> <p><a href="../../raw_ops/reciprocalgrad"><code translate="no" dir="ltr">ReciprocalGrad(...)</code></a>: Computes the gradient for the inverse of <code translate="no" dir="ltr">x</code> wrt its input.</p> <p><a href="../../raw_ops/recordinput"><code translate="no" dir="ltr">RecordInput(...)</code></a>: Emits randomized records.</p> <p><a href="../../raw_ops/recv"><code translate="no" dir="ltr">Recv(...)</code></a>: Receives the named tensor from send_device on recv_device.</p> <p><a href="../../raw_ops/recvtpuembeddingactivations"><code translate="no" dir="ltr">RecvTPUEmbeddingActivations(...)</code></a>: An op that receives embedding activations on the TPU.</p> <p><a href="../../raw_ops/reducedataset"><code translate="no" dir="ltr">ReduceDataset(...)</code></a>: Reduces the input dataset to a singleton using a reduce function.</p> <p><a href="../../raw_ops/reducejoin"><code translate="no" dir="ltr">ReduceJoin(...)</code></a>: Joins a string Tensor across the given dimensions.</p> <p><a href="../../raw_ops/refenter"><code translate="no" dir="ltr">RefEnter(...)</code></a>: Creates or finds a child frame, and makes <code translate="no" dir="ltr">data</code> available to the child frame.</p> <p><a href="../../raw_ops/refexit"><code translate="no" dir="ltr">RefExit(...)</code></a>: Exits the current frame to its parent frame.</p> <p><a href="../../raw_ops/refidentity"><code translate="no" dir="ltr">RefIdentity(...)</code></a>: Return the same ref tensor as the input ref tensor.</p> <p><a href="../../raw_ops/refmerge"><code translate="no" dir="ltr">RefMerge(...)</code></a>: Forwards the value of an available tensor from <code translate="no" dir="ltr">inputs</code> to <code translate="no" dir="ltr">output</code>.</p> <p><a href="../../raw_ops/refnextiteration"><code translate="no" dir="ltr">RefNextIteration(...)</code></a>: Makes its input available to the next iteration.</p> <p><a href="../../raw_ops/refselect"><code translate="no" dir="ltr">RefSelect(...)</code></a>: Forwards the <code translate="no" dir="ltr">index</code>th element of <code translate="no" dir="ltr">inputs</code> to <code translate="no" dir="ltr">output</code>.</p> <p><a href="../../raw_ops/refswitch"><code translate="no" dir="ltr">RefSwitch(...)</code></a>: Forwards the ref tensor <code translate="no" dir="ltr">data</code> to the output port determined by <code translate="no" dir="ltr">pred</code>.</p> <p><a href="../../raw_ops/regexfullmatch"><code translate="no" dir="ltr">RegexFullMatch(...)</code></a>: Check if the input matches the regex pattern.</p> <p><a href="../../raw_ops/regexreplace"><code translate="no" dir="ltr">RegexReplace(...)</code></a>: Replaces matches of the <code translate="no" dir="ltr">pattern</code> regular expression in <code translate="no" dir="ltr">input</code> with the</p> <p><a href="../../raw_ops/registerdataset"><code translate="no" dir="ltr">RegisterDataset(...)</code></a>: Registers a dataset with the tf.data service.</p> <p><a href="../../raw_ops/relu"><code translate="no" dir="ltr">Relu(...)</code></a>: Computes rectified linear: <code translate="no" dir="ltr">max(features, 0)</code>.</p> <p><a href="../../raw_ops/relu6"><code translate="no" dir="ltr">Relu6(...)</code></a>: Computes rectified linear 6: <code translate="no" dir="ltr">min(max(features, 0), 6)</code>.</p> <p><a href="../../raw_ops/relu6grad"><code translate="no" dir="ltr">Relu6Grad(...)</code></a>: Computes rectified linear 6 gradients for a Relu6 operation.</p> <p><a href="../../raw_ops/relugrad"><code translate="no" dir="ltr">ReluGrad(...)</code></a>: Computes rectified linear gradients for a Relu operation.</p> <p><a href="../../raw_ops/remotecall"><code translate="no" dir="ltr">RemoteCall(...)</code></a>: Runs function <code translate="no" dir="ltr">f</code> on a remote device indicated by <code translate="no" dir="ltr">target</code>.</p> <p><a href="../../raw_ops/repeatdataset"><code translate="no" dir="ltr">RepeatDataset(...)</code></a>: Creates a dataset that emits the outputs of <code translate="no" dir="ltr">input_dataset</code> <code translate="no" dir="ltr">count</code> times.</p> <p><a href="../../raw_ops/requantizationrange"><code translate="no" dir="ltr">RequantizationRange(...)</code></a>: Computes a range that covers the actual values present in a quantized tensor.</p> <p><a href="../../raw_ops/requantizationrangeperchannel"><code translate="no" dir="ltr">RequantizationRangePerChannel(...)</code></a>: Computes requantization range per channel.</p> <p><a href="../../raw_ops/requantize"><code translate="no" dir="ltr">Requantize(...)</code></a>: Converts the quantized <code translate="no" dir="ltr">input</code> tensor into a lower-precision <code translate="no" dir="ltr">output</code>.</p> <p><a href="../../raw_ops/requantizeperchannel"><code translate="no" dir="ltr">RequantizePerChannel(...)</code></a>: Requantizes input with min and max values known per channel.</p> <p><a href="../../raw_ops/reshape"><code translate="no" dir="ltr">Reshape(...)</code></a>: Reshapes a tensor.</p> <p><a href="../../raw_ops/resizearea"><code translate="no" dir="ltr">ResizeArea(...)</code></a>: Resize <code translate="no" dir="ltr">images</code> to <code translate="no" dir="ltr">size</code> using area interpolation.</p> <p><a href="../../raw_ops/resizebicubic"><code translate="no" dir="ltr">ResizeBicubic(...)</code></a>: Resize <code translate="no" dir="ltr">images</code> to <code translate="no" dir="ltr">size</code> using bicubic interpolation.</p> <p><a href="../../raw_ops/resizebicubicgrad"><code translate="no" dir="ltr">ResizeBicubicGrad(...)</code></a>: Computes the gradient of bicubic interpolation.</p> <p><a href="../../raw_ops/resizebilinear"><code translate="no" dir="ltr">ResizeBilinear(...)</code></a>: Resize <code translate="no" dir="ltr">images</code> to <code translate="no" dir="ltr">size</code> using bilinear interpolation.</p> <p><a href="../../raw_ops/resizebilineargrad"><code translate="no" dir="ltr">ResizeBilinearGrad(...)</code></a>: Computes the gradient of bilinear interpolation.</p> <p><a href="../../raw_ops/resizenearestneighbor"><code translate="no" dir="ltr">ResizeNearestNeighbor(...)</code></a>: Resize <code translate="no" dir="ltr">images</code> to <code translate="no" dir="ltr">size</code> using nearest neighbor interpolation.</p> <p><a href="../../raw_ops/resizenearestneighborgrad"><code translate="no" dir="ltr">ResizeNearestNeighborGrad(...)</code></a>: Computes the gradient of nearest neighbor interpolation.</p> <p><a href="../../raw_ops/resourceaccumulatorapplygradient"><code translate="no" dir="ltr">ResourceAccumulatorApplyGradient(...)</code></a>: Applies a gradient to a given accumulator.</p> <p><a href="../../raw_ops/resourceaccumulatornumaccumulated"><code translate="no" dir="ltr">ResourceAccumulatorNumAccumulated(...)</code></a>: Returns the number of gradients aggregated in the given accumulators.</p> <p><a href="../../raw_ops/resourceaccumulatorsetglobalstep"><code translate="no" dir="ltr">ResourceAccumulatorSetGlobalStep(...)</code></a>: Updates the accumulator with a new value for global_step.</p> <p><a href="../../raw_ops/resourceaccumulatortakegradient"><code translate="no" dir="ltr">ResourceAccumulatorTakeGradient(...)</code></a>: Extracts the average gradient in the given ConditionalAccumulator.</p> <p><a href="../../raw_ops/resourceapplyadamax"><code translate="no" dir="ltr">ResourceApplyAdaMax(...)</code></a>: Update '*var' according to the AdaMax algorithm.</p> <p><a href="../../raw_ops/resourceapplyadadelta"><code translate="no" dir="ltr">ResourceApplyAdadelta(...)</code></a>: Update '*var' according to the adadelta scheme.</p> <p><a href="../../raw_ops/resourceapplyadagrad"><code translate="no" dir="ltr">ResourceApplyAdagrad(...)</code></a>: Update '*var' according to the adagrad scheme.</p> <p><a href="../../raw_ops/resourceapplyadagradda"><code translate="no" dir="ltr">ResourceApplyAdagradDA(...)</code></a>: Update '*var' according to the proximal adagrad scheme.</p> <p><a href="../../raw_ops/resourceapplyadagradv2"><code translate="no" dir="ltr">ResourceApplyAdagradV2(...)</code></a>: Update '*var' according to the adagrad scheme.</p> <p><a href="../../raw_ops/resourceapplyadam"><code translate="no" dir="ltr">ResourceApplyAdam(...)</code></a>: Update '*var' according to the Adam algorithm.</p> <p><a href="../../raw_ops/resourceapplyadamwithamsgrad"><code translate="no" dir="ltr">ResourceApplyAdamWithAmsgrad(...)</code></a>: Update '*var' according to the Adam algorithm.</p> <p><a href="../../raw_ops/resourceapplyaddsign"><code translate="no" dir="ltr">ResourceApplyAddSign(...)</code></a>: Update '*var' according to the AddSign update.</p> <p><a href="../../raw_ops/resourceapplycenteredrmsprop"><code translate="no" dir="ltr">ResourceApplyCenteredRMSProp(...)</code></a>: Update '*var' according to the centered RMSProp algorithm.</p> <p><a href="../../raw_ops/resourceapplyftrl"><code translate="no" dir="ltr">ResourceApplyFtrl(...)</code></a>: Update '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/resourceapplyftrlv2"><code translate="no" dir="ltr">ResourceApplyFtrlV2(...)</code></a>: Update '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/resourceapplygradientdescent"><code translate="no" dir="ltr">ResourceApplyGradientDescent(...)</code></a>: Update '*var' by subtracting 'alpha' * 'delta' from it.</p> <p><a href="../../raw_ops/resourceapplykerasmomentum"><code translate="no" dir="ltr">ResourceApplyKerasMomentum(...)</code></a>: Update '*var' according to the momentum scheme.</p> <p><a href="../../raw_ops/resourceapplymomentum"><code translate="no" dir="ltr">ResourceApplyMomentum(...)</code></a>: Update '*var' according to the momentum scheme.</p> <p><a href="../../raw_ops/resourceapplypowersign"><code translate="no" dir="ltr">ResourceApplyPowerSign(...)</code></a>: Update '*var' according to the AddSign update.</p> <p><a href="../../raw_ops/resourceapplyproximaladagrad"><code translate="no" dir="ltr">ResourceApplyProximalAdagrad(...)</code></a>: Update '<em>var' and '</em>accum' according to FOBOS with Adagrad learning rate.</p> <p><a href="../../raw_ops/resourceapplyproximalgradientdescent"><code translate="no" dir="ltr">ResourceApplyProximalGradientDescent(...)</code></a>: Update '*var' as FOBOS algorithm with fixed learning rate.</p> <p><a href="../../raw_ops/resourceapplyrmsprop"><code translate="no" dir="ltr">ResourceApplyRMSProp(...)</code></a>: Update '*var' according to the RMSProp algorithm.</p> <p><a href="../../raw_ops/resourceconditionalaccumulator"><code translate="no" dir="ltr">ResourceConditionalAccumulator(...)</code></a>: A conditional accumulator for aggregating gradients.</p> <p><a href="../../raw_ops/resourcecountupto"><code translate="no" dir="ltr">ResourceCountUpTo(...)</code></a>: Increments variable pointed to by 'resource' until it reaches 'limit'.</p> <p><a href="../../raw_ops/resourcegather"><code translate="no" dir="ltr">ResourceGather(...)</code></a>: Gather slices from the variable pointed to by <code translate="no" dir="ltr">resource</code> according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/resourcegathernd"><code translate="no" dir="ltr">ResourceGatherNd(...)</code></a></p> <p><a href="../../raw_ops/resourcescatteradd"><code translate="no" dir="ltr">ResourceScatterAdd(...)</code></a>: Adds sparse updates to the variable referenced by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="../../raw_ops/resourcescatterdiv"><code translate="no" dir="ltr">ResourceScatterDiv(...)</code></a>: Divides sparse updates into the variable referenced by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="../../raw_ops/resourcescattermax"><code translate="no" dir="ltr">ResourceScatterMax(...)</code></a>: Reduces sparse updates into the variable referenced by <code translate="no" dir="ltr">resource</code> using the <code translate="no" dir="ltr">max</code> operation.</p> <p><a href="../../raw_ops/resourcescattermin"><code translate="no" dir="ltr">ResourceScatterMin(...)</code></a>: Reduces sparse updates into the variable referenced by <code translate="no" dir="ltr">resource</code> using the <code translate="no" dir="ltr">min</code> operation.</p> <p><a href="../../raw_ops/resourcescattermul"><code translate="no" dir="ltr">ResourceScatterMul(...)</code></a>: Multiplies sparse updates into the variable referenced by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="../../raw_ops/resourcescatterndadd"><code translate="no" dir="ltr">ResourceScatterNdAdd(...)</code></a>: Applies sparse addition to individual values or slices in a Variable.</p> <p><a href="../../raw_ops/resourcescatterndmax"><code translate="no" dir="ltr">ResourceScatterNdMax(...)</code></a></p> <p><a href="../../raw_ops/resourcescatterndmin"><code translate="no" dir="ltr">ResourceScatterNdMin(...)</code></a></p> <p><a href="../../raw_ops/resourcescatterndsub"><code translate="no" dir="ltr">ResourceScatterNdSub(...)</code></a>: Applies sparse subtraction to individual values or slices in a Variable.</p> <p><a href="../../raw_ops/resourcescatterndupdate"><code translate="no" dir="ltr">ResourceScatterNdUpdate(...)</code></a>: Applies sparse <code translate="no" dir="ltr">updates</code> to individual values or slices within a given</p> <p><a href="../../raw_ops/resourcescattersub"><code translate="no" dir="ltr">ResourceScatterSub(...)</code></a>: Subtracts sparse updates from the variable referenced by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="../../raw_ops/resourcescatterupdate"><code translate="no" dir="ltr">ResourceScatterUpdate(...)</code></a>: Assigns sparse updates to the variable referenced by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="../../raw_ops/resourcesparseapplyadadelta"><code translate="no" dir="ltr">ResourceSparseApplyAdadelta(...)</code></a>: var: Should be from a Variable().</p> <p><a href="../../raw_ops/resourcesparseapplyadagrad"><code translate="no" dir="ltr">ResourceSparseApplyAdagrad(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the adagrad scheme.</p> <p><a href="../../raw_ops/resourcesparseapplyadagradda"><code translate="no" dir="ltr">ResourceSparseApplyAdagradDA(...)</code></a>: Update entries in '<em>var' and '</em>accum' according to the proximal adagrad scheme.</p> <p><a href="../../raw_ops/resourcesparseapplyadagradv2"><code translate="no" dir="ltr">ResourceSparseApplyAdagradV2(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the adagrad scheme.</p> <p><a href="../../raw_ops/resourcesparseapplycenteredrmsprop"><code translate="no" dir="ltr">ResourceSparseApplyCenteredRMSProp(...)</code></a>: Update '*var' according to the centered RMSProp algorithm.</p> <p><a href="../../raw_ops/resourcesparseapplyftrl"><code translate="no" dir="ltr">ResourceSparseApplyFtrl(...)</code></a>: Update relevant entries in '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/resourcesparseapplyftrlv2"><code translate="no" dir="ltr">ResourceSparseApplyFtrlV2(...)</code></a>: Update relevant entries in '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/resourcesparseapplykerasmomentum"><code translate="no" dir="ltr">ResourceSparseApplyKerasMomentum(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the momentum scheme.</p> <p><a href="../../raw_ops/resourcesparseapplymomentum"><code translate="no" dir="ltr">ResourceSparseApplyMomentum(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the momentum scheme.</p> <p><a href="../../raw_ops/resourcesparseapplyproximaladagrad"><code translate="no" dir="ltr">ResourceSparseApplyProximalAdagrad(...)</code></a>: Sparse update entries in '<em>var' and '</em>accum' according to FOBOS algorithm.</p> <p><a href="../../raw_ops/resourcesparseapplyproximalgradientdescent"><code translate="no" dir="ltr">ResourceSparseApplyProximalGradientDescent(...)</code></a>: Sparse update '*var' as FOBOS algorithm with fixed learning rate.</p> <p><a href="../../raw_ops/resourcesparseapplyrmsprop"><code translate="no" dir="ltr">ResourceSparseApplyRMSProp(...)</code></a>: Update '*var' according to the RMSProp algorithm.</p> <p><a href="../../raw_ops/resourcestridedsliceassign"><code translate="no" dir="ltr">ResourceStridedSliceAssign(...)</code></a>: Assign <code translate="no" dir="ltr">value</code> to the sliced l-value reference of <code translate="no" dir="ltr">ref</code>.</p> <p><a href="../../raw_ops/restore"><code translate="no" dir="ltr">Restore(...)</code></a>: Restores a tensor from checkpoint files.</p> <p><a href="../../raw_ops/restoreslice"><code translate="no" dir="ltr">RestoreSlice(...)</code></a>: Restores a tensor from checkpoint files.</p> <p><a href="../../raw_ops/restorev2"><code translate="no" dir="ltr">RestoreV2(...)</code></a>: Restores tensors from a V2 checkpoint.</p> <p><a href="../../raw_ops/retrievetpuembeddingadamparameters"><code translate="no" dir="ltr">RetrieveTPUEmbeddingADAMParameters(...)</code></a>: Retrieve ADAM embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingadamparametersgradaccumdebug"><code translate="no" dir="ltr">RetrieveTPUEmbeddingADAMParametersGradAccumDebug(...)</code></a>: Retrieve ADAM embedding parameters with debug support.</p> <p><a href="../../raw_ops/retrievetpuembeddingadadeltaparameters"><code translate="no" dir="ltr">RetrieveTPUEmbeddingAdadeltaParameters(...)</code></a>: Retrieve Adadelta embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingadadeltaparametersgradaccumdebug"><code translate="no" dir="ltr">RetrieveTPUEmbeddingAdadeltaParametersGradAccumDebug(...)</code></a>: Retrieve Adadelta embedding parameters with debug support.</p> <p><a href="../../raw_ops/retrievetpuembeddingadagradparameters"><code translate="no" dir="ltr">RetrieveTPUEmbeddingAdagradParameters(...)</code></a>: Retrieve Adagrad embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingadagradparametersgradaccumdebug"><code translate="no" dir="ltr">RetrieveTPUEmbeddingAdagradParametersGradAccumDebug(...)</code></a>: Retrieve Adagrad embedding parameters with debug support.</p> <p><a href="../../raw_ops/retrievetpuembeddingcenteredrmspropparameters"><code translate="no" dir="ltr">RetrieveTPUEmbeddingCenteredRMSPropParameters(...)</code></a>: Retrieve centered RMSProp embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingftrlparameters"><code translate="no" dir="ltr">RetrieveTPUEmbeddingFTRLParameters(...)</code></a>: Retrieve FTRL embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingftrlparametersgradaccumdebug"><code translate="no" dir="ltr">RetrieveTPUEmbeddingFTRLParametersGradAccumDebug(...)</code></a>: Retrieve FTRL embedding parameters with debug support.</p> <p><a href="../../raw_ops/retrievetpuembeddingmdladagradlightparameters"><code translate="no" dir="ltr">RetrieveTPUEmbeddingMDLAdagradLightParameters(...)</code></a>: Retrieve MDL Adagrad Light embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingmomentumparameters"><code translate="no" dir="ltr">RetrieveTPUEmbeddingMomentumParameters(...)</code></a>: Retrieve Momentum embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingmomentumparametersgradaccumdebug"><code translate="no" dir="ltr">RetrieveTPUEmbeddingMomentumParametersGradAccumDebug(...)</code></a>: Retrieve Momentum embedding parameters with debug support.</p> <p><a href="../../raw_ops/retrievetpuembeddingproximaladagradparameters"><code translate="no" dir="ltr">RetrieveTPUEmbeddingProximalAdagradParameters(...)</code></a>: Retrieve proximal Adagrad embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingproximaladagradparametersgradaccumdebug"><code translate="no" dir="ltr">RetrieveTPUEmbeddingProximalAdagradParametersGradAccumDebug(...)</code></a>: Retrieve proximal Adagrad embedding parameters with debug support.</p> <p><a href="../../raw_ops/retrievetpuembeddingproximalyogiparameters"><code translate="no" dir="ltr">RetrieveTPUEmbeddingProximalYogiParameters(...)</code></a></p> <p><a href="../../raw_ops/retrievetpuembeddingproximalyogiparametersgradaccumdebug"><code translate="no" dir="ltr">RetrieveTPUEmbeddingProximalYogiParametersGradAccumDebug(...)</code></a></p> <p><a href="../../raw_ops/retrievetpuembeddingrmspropparameters"><code translate="no" dir="ltr">RetrieveTPUEmbeddingRMSPropParameters(...)</code></a>: Retrieve RMSProp embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingrmspropparametersgradaccumdebug"><code translate="no" dir="ltr">RetrieveTPUEmbeddingRMSPropParametersGradAccumDebug(...)</code></a>: Retrieve RMSProp embedding parameters with debug support.</p> <p><a href="../../raw_ops/retrievetpuembeddingstochasticgradientdescentparameters"><code translate="no" dir="ltr">RetrieveTPUEmbeddingStochasticGradientDescentParameters(...)</code></a>: Retrieve SGD embedding parameters.</p> <p><a href="../../raw_ops/retrievetpuembeddingstochasticgradientdescentparametersgradaccumdebug"><code translate="no" dir="ltr">RetrieveTPUEmbeddingStochasticGradientDescentParametersGradAccumDebug(...)</code></a>: Retrieve SGD embedding parameters with debug support.</p> <p><a href="../../raw_ops/reverse"><code translate="no" dir="ltr">Reverse(...)</code></a>: Reverses specific dimensions of a tensor.</p> <p><a href="../../raw_ops/reversesequence"><code translate="no" dir="ltr">ReverseSequence(...)</code></a>: Reverses variable length slices.</p> <p><a href="../../raw_ops/reversev2"><code translate="no" dir="ltr">ReverseV2(...)</code></a>: Reverses specific dimensions of a tensor.</p> <p><a href="../../raw_ops/rightshift"><code translate="no" dir="ltr">RightShift(...)</code></a>: Elementwise computes the bitwise right-shift of <code translate="no" dir="ltr">x</code> and <code translate="no" dir="ltr">y</code>.</p> <p><a href="../../raw_ops/rint"><code translate="no" dir="ltr">Rint(...)</code></a>: Returns element-wise integer closest to x.</p> <p><a href="../../raw_ops/rngreadandskip"><code translate="no" dir="ltr">RngReadAndSkip(...)</code></a>: Advance the counter of a counter-based RNG.</p> <p><a href="../../raw_ops/rngskip"><code translate="no" dir="ltr">RngSkip(...)</code></a>: Advance the counter of a counter-based RNG.</p> <p><a href="../../raw_ops/roll"><code translate="no" dir="ltr">Roll(...)</code></a>: Rolls the elements of a tensor along an axis.</p> <p><a href="../../raw_ops/round"><code translate="no" dir="ltr">Round(...)</code></a>: Rounds the values of a tensor to the nearest integer, element-wise.</p> <p><a href="../../raw_ops/rsqrt"><code translate="no" dir="ltr">Rsqrt(...)</code></a>: Computes reciprocal of square root of x element-wise.</p> <p><a href="../../raw_ops/rsqrtgrad"><code translate="no" dir="ltr">RsqrtGrad(...)</code></a>: Computes the gradient for the rsqrt of <code translate="no" dir="ltr">x</code> wrt its input.</p> <p><a href="../../raw_ops/sampledistortedboundingbox"><code translate="no" dir="ltr">SampleDistortedBoundingBox(...)</code></a>: Generate a single randomly distorted bounding box for an image.</p> <p><a href="../../raw_ops/sampledistortedboundingboxv2"><code translate="no" dir="ltr">SampleDistortedBoundingBoxV2(...)</code></a>: Generate a single randomly distorted bounding box for an image.</p> <p><a href="../../raw_ops/samplingdataset"><code translate="no" dir="ltr">SamplingDataset(...)</code></a>: Creates a dataset that takes a Bernoulli sample of the contents of another dataset.</p> <p><a href="../../raw_ops/save"><code translate="no" dir="ltr">Save(...)</code></a>: Saves the input tensors to disk.</p> <p><a href="../../raw_ops/savedataset"><code translate="no" dir="ltr">SaveDataset(...)</code></a></p> <p><a href="../../raw_ops/saveslices"><code translate="no" dir="ltr">SaveSlices(...)</code></a>: Saves input tensors slices to disk.</p> <p><a href="../../raw_ops/savev2"><code translate="no" dir="ltr">SaveV2(...)</code></a>: Saves tensors in V2 checkpoint format.</p> <p><a href="../../raw_ops/scalarsummary"><code translate="no" dir="ltr">ScalarSummary(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with scalar values.</p> <p><a href="../../raw_ops/scaleandtranslate"><code translate="no" dir="ltr">ScaleAndTranslate(...)</code></a></p> <p><a href="../../raw_ops/scaleandtranslategrad"><code translate="no" dir="ltr">ScaleAndTranslateGrad(...)</code></a></p> <p><a href="../../raw_ops/scandataset"><code translate="no" dir="ltr">ScanDataset(...)</code></a>: Creates a dataset successively reduces <code translate="no" dir="ltr">f</code> over the elements of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/scatteradd"><code translate="no" dir="ltr">ScatterAdd(...)</code></a>: Adds sparse updates to a variable reference.</p> <p><a href="../../raw_ops/scatterdiv"><code translate="no" dir="ltr">ScatterDiv(...)</code></a>: Divides a variable reference by sparse updates.</p> <p><a href="../../raw_ops/scattermax"><code translate="no" dir="ltr">ScatterMax(...)</code></a>: Reduces sparse updates into a variable reference using the <code translate="no" dir="ltr">max</code> operation.</p> <p><a href="../../raw_ops/scattermin"><code translate="no" dir="ltr">ScatterMin(...)</code></a>: Reduces sparse updates into a variable reference using the <code translate="no" dir="ltr">min</code> operation.</p> <p><a href="../../raw_ops/scattermul"><code translate="no" dir="ltr">ScatterMul(...)</code></a>: Multiplies sparse updates into a variable reference.</p> <p><a href="../../raw_ops/scatternd"><code translate="no" dir="ltr">ScatterNd(...)</code></a>: Scatter <code translate="no" dir="ltr">updates</code> into a new tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/scatterndadd"><code translate="no" dir="ltr">ScatterNdAdd(...)</code></a>: Applies sparse addition to individual values or slices in a Variable.</p> <p><a href="../../raw_ops/scatterndmax"><code translate="no" dir="ltr">ScatterNdMax(...)</code></a>: Computes element-wise maximum.</p> <p><a href="../../raw_ops/scatterndmin"><code translate="no" dir="ltr">ScatterNdMin(...)</code></a>: Computes element-wise minimum.</p> <p><a href="../../raw_ops/scatterndnonaliasingadd"><code translate="no" dir="ltr">ScatterNdNonAliasingAdd(...)</code></a>: Applies sparse addition to <code translate="no" dir="ltr">input</code> using individual values or slices</p> <p><a href="../../raw_ops/scatterndsub"><code translate="no" dir="ltr">ScatterNdSub(...)</code></a>: Applies sparse subtraction to individual values or slices in a Variable.</p> <p><a href="../../raw_ops/scatterndupdate"><code translate="no" dir="ltr">ScatterNdUpdate(...)</code></a>: Applies sparse <code translate="no" dir="ltr">updates</code> to individual values or slices within a given</p> <p><a href="../../raw_ops/scattersub"><code translate="no" dir="ltr">ScatterSub(...)</code></a>: Subtracts sparse updates to a variable reference.</p> <p><a href="../../raw_ops/scatterupdate"><code translate="no" dir="ltr">ScatterUpdate(...)</code></a>: Applies sparse updates to a variable reference.</p> <p><a href="../../raw_ops/sdcafprint"><code translate="no" dir="ltr">SdcaFprint(...)</code></a>: Computes fingerprints of the input strings.</p> <p><a href="../../raw_ops/sdcaoptimizer"><code translate="no" dir="ltr">SdcaOptimizer(...)</code></a>: Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for</p> <p><a href="../../raw_ops/sdcaoptimizerv2"><code translate="no" dir="ltr">SdcaOptimizerV2(...)</code></a>: Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for</p> <p><a href="../../raw_ops/sdcashrinkl1"><code translate="no" dir="ltr">SdcaShrinkL1(...)</code></a>: Applies L1 regularization shrink step on the parameters.</p> <p><a href="../../raw_ops/segmentmax"><code translate="no" dir="ltr">SegmentMax(...)</code></a>: Computes the maximum along segments of a tensor.</p> <p><a href="../../raw_ops/segmentmean"><code translate="no" dir="ltr">SegmentMean(...)</code></a>: Computes the mean along segments of a tensor.</p> <p><a href="../../raw_ops/segmentmin"><code translate="no" dir="ltr">SegmentMin(...)</code></a>: Computes the minimum along segments of a tensor.</p> <p><a href="../../raw_ops/segmentprod"><code translate="no" dir="ltr">SegmentProd(...)</code></a>: Computes the product along segments of a tensor.</p> <p><a href="../../raw_ops/segmentsum"><code translate="no" dir="ltr">SegmentSum(...)</code></a>: Computes the sum along segments of a tensor.</p> <p><a href="../../raw_ops/select"><code translate="no" dir="ltr">Select(...)</code></a>: Selects elements from <code translate="no" dir="ltr">x</code> or <code translate="no" dir="ltr">y</code>, depending on <code translate="no" dir="ltr">condition</code>.</p> <p><a href="../../raw_ops/selectv2"><code translate="no" dir="ltr">SelectV2(...)</code></a></p> <p><a href="../../raw_ops/selfadjointeig"><code translate="no" dir="ltr">SelfAdjointEig(...)</code></a>: Computes the Eigen Decomposition of a batch of square self-adjoint matrices.</p> <p><a href="../../raw_ops/selfadjointeigv2"><code translate="no" dir="ltr">SelfAdjointEigV2(...)</code></a>: Computes the eigen decomposition of one or more square self-adjoint matrices.</p> <p><a href="../../raw_ops/selu"><code translate="no" dir="ltr">Selu(...)</code></a>: Computes scaled exponential linear: <code translate="no" dir="ltr">scale * alpha * (exp(features) - 1)</code></p> <p><a href="../../raw_ops/selugrad"><code translate="no" dir="ltr">SeluGrad(...)</code></a>: Computes gradients for the scaled exponential linear (Selu) operation.</p> <p><a href="../../raw_ops/send"><code translate="no" dir="ltr">Send(...)</code></a>: Sends the named tensor from send_device to recv_device.</p> <p><a href="../../raw_ops/sendtpuembeddinggradients"><code translate="no" dir="ltr">SendTPUEmbeddingGradients(...)</code></a>: Performs gradient updates of embedding tables.</p> <p><a href="../../raw_ops/serializeiterator"><code translate="no" dir="ltr">SerializeIterator(...)</code></a>: Converts the given <code translate="no" dir="ltr">resource_handle</code> representing an iterator to a variant tensor.</p> <p><a href="../../raw_ops/serializemanysparse"><code translate="no" dir="ltr">SerializeManySparse(...)</code></a>: Serialize an <code translate="no" dir="ltr">N</code>-minibatch <code translate="no" dir="ltr">SparseTensor</code> into an <code translate="no" dir="ltr">[N, 3]</code> <code translate="no" dir="ltr">Tensor</code> object.</p> <p><a href="../../raw_ops/serializesparse"><code translate="no" dir="ltr">SerializeSparse(...)</code></a>: Serialize a <code translate="no" dir="ltr">SparseTensor</code> into a <code translate="no" dir="ltr">[3]</code> <code translate="no" dir="ltr">Tensor</code> object.</p> <p><a href="../../raw_ops/serializetensor"><code translate="no" dir="ltr">SerializeTensor(...)</code></a>: Transforms a Tensor into a serialized TensorProto proto.</p> <p><a href="../../raw_ops/setsize"><code translate="no" dir="ltr">SetSize(...)</code></a>: Number of unique elements along last dimension of input <code translate="no" dir="ltr">set</code>.</p> <p><a href="../../raw_ops/setstatsaggregatordataset"><code translate="no" dir="ltr">SetStatsAggregatorDataset(...)</code></a></p> <p><a href="../../raw_ops/shape"><code translate="no" dir="ltr">Shape(...)</code></a>: Returns the shape of a tensor.</p> <p><a href="../../raw_ops/shapen"><code translate="no" dir="ltr">ShapeN(...)</code></a>: Returns shape of tensors.</p> <p><a href="../../raw_ops/sharddataset"><code translate="no" dir="ltr">ShardDataset(...)</code></a>: Creates a <code translate="no" dir="ltr">Dataset</code> that includes only 1/<code translate="no" dir="ltr">num_shards</code> of this dataset.</p> <p><a href="../../raw_ops/shardedfilename"><code translate="no" dir="ltr">ShardedFilename(...)</code></a>: Generate a sharded filename. The filename is printf formatted as</p> <p><a href="../../raw_ops/shardedfilespec"><code translate="no" dir="ltr">ShardedFilespec(...)</code></a>: Generate a glob pattern matching all sharded file names.</p> <p><a href="../../raw_ops/shuffleandrepeatdataset"><code translate="no" dir="ltr">ShuffleAndRepeatDataset(...)</code></a>: Creates a dataset that shuffles and repeats elements from <code translate="no" dir="ltr">input_dataset</code></p> <p><a href="../../raw_ops/shuffleandrepeatdatasetv2"><code translate="no" dir="ltr">ShuffleAndRepeatDatasetV2(...)</code></a></p> <p><a href="../../raw_ops/shuffledataset"><code translate="no" dir="ltr">ShuffleDataset(...)</code></a>: Creates a dataset that shuffles elements from <code translate="no" dir="ltr">input_dataset</code> pseudorandomly.</p> <p><a href="../../raw_ops/shuffledatasetv2"><code translate="no" dir="ltr">ShuffleDatasetV2(...)</code></a></p> <p><a href="../../raw_ops/shuffledatasetv3"><code translate="no" dir="ltr">ShuffleDatasetV3(...)</code></a></p> <p><a href="../../raw_ops/shutdowndistributedtpu"><code translate="no" dir="ltr">ShutdownDistributedTPU(...)</code></a>: Shuts down a running distributed TPU system.</p> <p><a href="../../raw_ops/sigmoid"><code translate="no" dir="ltr">Sigmoid(...)</code></a>: Computes sigmoid of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="../../raw_ops/sigmoidgrad"><code translate="no" dir="ltr">SigmoidGrad(...)</code></a>: Computes the gradient of the sigmoid of <code translate="no" dir="ltr">x</code> wrt its input.</p> <p><a href="../../raw_ops/sign"><code translate="no" dir="ltr">Sign(...)</code></a>: Returns an element-wise indication of the sign of a number.</p> <p><a href="../../raw_ops/sin"><code translate="no" dir="ltr">Sin(...)</code></a>: Computes sine of x element-wise.</p> <p><a href="../../raw_ops/sinh"><code translate="no" dir="ltr">Sinh(...)</code></a>: Computes hyperbolic sine of x element-wise.</p> <p><a href="../../raw_ops/size"><code translate="no" dir="ltr">Size(...)</code></a>: Returns the size of a tensor.</p> <p><a href="../../raw_ops/skipdataset"><code translate="no" dir="ltr">SkipDataset(...)</code></a>: Creates a dataset that skips <code translate="no" dir="ltr">count</code> elements from the <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/sleepdataset"><code translate="no" dir="ltr">SleepDataset(...)</code></a></p> <p><a href="../../raw_ops/slice"><code translate="no" dir="ltr">Slice(...)</code></a>: Return a slice from 'input'.</p> <p><a href="../../raw_ops/slidingwindowdataset"><code translate="no" dir="ltr">SlidingWindowDataset(...)</code></a>: Creates a dataset that passes a sliding window over <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/snapshot"><code translate="no" dir="ltr">Snapshot(...)</code></a>: Returns a copy of the input tensor.</p> <p><a href="../../raw_ops/snapshotdataset"><code translate="no" dir="ltr">SnapshotDataset(...)</code></a>: Creates a dataset that will write to / read from a snapshot.</p> <p><a href="../../raw_ops/snapshotdatasetv2"><code translate="no" dir="ltr">SnapshotDatasetV2(...)</code></a>: Creates a dataset that will write to / read from a snapshot.</p> <p><a href="../../raw_ops/sobolsample"><code translate="no" dir="ltr">SobolSample(...)</code></a>: Generates points from the Sobol sequence.</p> <p><a href="../../raw_ops/softmax"><code translate="no" dir="ltr">Softmax(...)</code></a>: Computes softmax activations.</p> <p><a href="../../raw_ops/softmaxcrossentropywithlogits"><code translate="no" dir="ltr">SoftmaxCrossEntropyWithLogits(...)</code></a>: Computes softmax cross entropy cost and gradients to backpropagate.</p> <p><a href="../../raw_ops/softplus"><code translate="no" dir="ltr">Softplus(...)</code></a>: Computes softplus: <code translate="no" dir="ltr">log(exp(features) + 1)</code>.</p> <p><a href="../../raw_ops/softplusgrad"><code translate="no" dir="ltr">SoftplusGrad(...)</code></a>: Computes softplus gradients for a softplus operation.</p> <p><a href="../../raw_ops/softsign"><code translate="no" dir="ltr">Softsign(...)</code></a>: Computes softsign: <code translate="no" dir="ltr">features / (abs(features) + 1)</code>.</p> <p><a href="../../raw_ops/softsigngrad"><code translate="no" dir="ltr">SoftsignGrad(...)</code></a>: Computes softsign gradients for a softsign operation.</p> <p><a href="../../raw_ops/spacetobatch"><code translate="no" dir="ltr">SpaceToBatch(...)</code></a>: SpaceToBatch for 4-D tensors of type T.</p> <p><a href="../../raw_ops/spacetobatchnd"><code translate="no" dir="ltr">SpaceToBatchND(...)</code></a>: SpaceToBatch for N-D tensors of type T.</p> <p><a href="../../raw_ops/spacetodepth"><code translate="no" dir="ltr">SpaceToDepth(...)</code></a>: SpaceToDepth for tensors of type T.</p> <p><a href="../../raw_ops/sparseaccumulatorapplygradient"><code translate="no" dir="ltr">SparseAccumulatorApplyGradient(...)</code></a>: Applies a sparse gradient to a given accumulator.</p> <p><a href="../../raw_ops/sparseaccumulatortakegradient"><code translate="no" dir="ltr">SparseAccumulatorTakeGradient(...)</code></a>: Extracts the average sparse gradient in a SparseConditionalAccumulator.</p> <p><a href="../../raw_ops/sparseadd"><code translate="no" dir="ltr">SparseAdd(...)</code></a>: Adds two <code translate="no" dir="ltr">SparseTensor</code> objects to produce another <code translate="no" dir="ltr">SparseTensor</code>.</p> <p><a href="../../raw_ops/sparseaddgrad"><code translate="no" dir="ltr">SparseAddGrad(...)</code></a>: The gradient operator for the SparseAdd op.</p> <p><a href="../../raw_ops/sparseapplyadadelta"><code translate="no" dir="ltr">SparseApplyAdadelta(...)</code></a>: var: Should be from a Variable().</p> <p><a href="../../raw_ops/sparseapplyadagrad"><code translate="no" dir="ltr">SparseApplyAdagrad(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the adagrad scheme.</p> <p><a href="../../raw_ops/sparseapplyadagradda"><code translate="no" dir="ltr">SparseApplyAdagradDA(...)</code></a>: Update entries in '<em>var' and '</em>accum' according to the proximal adagrad scheme.</p> <p><a href="../../raw_ops/sparseapplyadagradv2"><code translate="no" dir="ltr">SparseApplyAdagradV2(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the adagrad scheme.</p> <p><a href="../../raw_ops/sparseapplycenteredrmsprop"><code translate="no" dir="ltr">SparseApplyCenteredRMSProp(...)</code></a>: Update '*var' according to the centered RMSProp algorithm.</p> <p><a href="../../raw_ops/sparseapplyftrl"><code translate="no" dir="ltr">SparseApplyFtrl(...)</code></a>: Update relevant entries in '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/sparseapplyftrlv2"><code translate="no" dir="ltr">SparseApplyFtrlV2(...)</code></a>: Update relevant entries in '*var' according to the Ftrl-proximal scheme.</p> <p><a href="../../raw_ops/sparseapplymomentum"><code translate="no" dir="ltr">SparseApplyMomentum(...)</code></a>: Update relevant entries in '<em>var' and '</em>accum' according to the momentum scheme.</p> <p><a href="../../raw_ops/sparseapplyproximaladagrad"><code translate="no" dir="ltr">SparseApplyProximalAdagrad(...)</code></a>: Sparse update entries in '<em>var' and '</em>accum' according to FOBOS algorithm.</p> <p><a href="../../raw_ops/sparseapplyproximalgradientdescent"><code translate="no" dir="ltr">SparseApplyProximalGradientDescent(...)</code></a>: Sparse update '*var' as FOBOS algorithm with fixed learning rate.</p> <p><a href="../../raw_ops/sparseapplyrmsprop"><code translate="no" dir="ltr">SparseApplyRMSProp(...)</code></a>: Update '*var' according to the RMSProp algorithm.</p> <p><a href="../../raw_ops/sparsebincount"><code translate="no" dir="ltr">SparseBincount(...)</code></a>: Counts the number of occurrences of each value in an integer array.</p> <p><a href="../../raw_ops/sparseconcat"><code translate="no" dir="ltr">SparseConcat(...)</code></a>: Concatenates a list of <code translate="no" dir="ltr">SparseTensor</code> along the specified dimension.</p> <p><a href="../../raw_ops/sparseconditionalaccumulator"><code translate="no" dir="ltr">SparseConditionalAccumulator(...)</code></a>: A conditional accumulator for aggregating sparse gradients.</p> <p><a href="../../raw_ops/sparsecountsparseoutput"><code translate="no" dir="ltr">SparseCountSparseOutput(...)</code></a>: Performs sparse-output bin counting for a sparse tensor input.</p> <p><a href="../../raw_ops/sparsecross"><code translate="no" dir="ltr">SparseCross(...)</code></a>: Generates sparse cross from a list of sparse and dense tensors.</p> <p><a href="../../raw_ops/sparsecrosshashed"><code translate="no" dir="ltr">SparseCrossHashed(...)</code></a>: Generates sparse cross from a list of sparse and dense tensors.</p> <p><a href="../../raw_ops/sparsecrossv2"><code translate="no" dir="ltr">SparseCrossV2(...)</code></a>: Generates sparse cross from a list of sparse and dense tensors.</p> <p><a href="../../raw_ops/sparsedensecwiseadd"><code translate="no" dir="ltr">SparseDenseCwiseAdd(...)</code></a>: Adds up a SparseTensor and a dense Tensor, using these special rules:</p> <p><a href="../../raw_ops/sparsedensecwisediv"><code translate="no" dir="ltr">SparseDenseCwiseDiv(...)</code></a>: Component-wise divides a SparseTensor by a dense Tensor.</p> <p><a href="../../raw_ops/sparsedensecwisemul"><code translate="no" dir="ltr">SparseDenseCwiseMul(...)</code></a>: Component-wise multiplies a SparseTensor by a dense Tensor.</p> <p><a href="../../raw_ops/sparsefillemptyrows"><code translate="no" dir="ltr">SparseFillEmptyRows(...)</code></a>: Fills empty rows in the input 2-D <code translate="no" dir="ltr">SparseTensor</code> with a default value.</p> <p><a href="../../raw_ops/sparsefillemptyrowsgrad"><code translate="no" dir="ltr">SparseFillEmptyRowsGrad(...)</code></a>: The gradient of SparseFillEmptyRows.</p> <p><a href="../../raw_ops/sparsematmul"><code translate="no" dir="ltr">SparseMatMul(...)</code></a>: Multiply matrix "a" by matrix "b".</p> <p><a href="../../raw_ops/sparsematrixadd"><code translate="no" dir="ltr">SparseMatrixAdd(...)</code></a>: Sparse addition of two CSR matrices, C = alpha * A + beta * B.</p> <p><a href="../../raw_ops/sparsematrixmatmul"><code translate="no" dir="ltr">SparseMatrixMatMul(...)</code></a>: Matrix-multiplies a sparse matrix with a dense matrix.</p> <p><a href="../../raw_ops/sparsematrixmul"><code translate="no" dir="ltr">SparseMatrixMul(...)</code></a>: Element-wise multiplication of a sparse matrix with a dense tensor.</p> <p><a href="../../raw_ops/sparsematrixnnz"><code translate="no" dir="ltr">SparseMatrixNNZ(...)</code></a>: Returns the number of nonzeroes of <code translate="no" dir="ltr">sparse_matrix</code>.</p> <p><a href="../../raw_ops/sparsematrixorderingamd"><code translate="no" dir="ltr">SparseMatrixOrderingAMD(...)</code></a>: Computes the Approximate Minimum Degree (AMD) ordering of <code translate="no" dir="ltr">input</code>.</p> <p><a href="../../raw_ops/sparsematrixsoftmax"><code translate="no" dir="ltr">SparseMatrixSoftmax(...)</code></a>: Calculates the softmax of a CSRSparseMatrix.</p> <p><a href="../../raw_ops/sparsematrixsoftmaxgrad"><code translate="no" dir="ltr">SparseMatrixSoftmaxGrad(...)</code></a>: Calculates the gradient of the SparseMatrixSoftmax op.</p> <p><a href="../../raw_ops/sparsematrixsparsecholesky"><code translate="no" dir="ltr">SparseMatrixSparseCholesky(...)</code></a>: Computes the sparse Cholesky decomposition of <code translate="no" dir="ltr">input</code>.</p> <p><a href="../../raw_ops/sparsematrixsparsematmul"><code translate="no" dir="ltr">SparseMatrixSparseMatMul(...)</code></a>: Sparse-matrix-multiplies two CSR matrices <code translate="no" dir="ltr">a</code> and <code translate="no" dir="ltr">b</code>.</p> <p><a href="../../raw_ops/sparsematrixtranspose"><code translate="no" dir="ltr">SparseMatrixTranspose(...)</code></a>: Transposes the inner (matrix) dimensions of a CSRSparseMatrix.</p> <p><a href="../../raw_ops/sparsematrixzeros"><code translate="no" dir="ltr">SparseMatrixZeros(...)</code></a>: Creates an all-zeros CSRSparseMatrix with shape <code translate="no" dir="ltr">dense_shape</code>.</p> <p><a href="../../raw_ops/sparsereducemax"><code translate="no" dir="ltr">SparseReduceMax(...)</code></a>: Computes the max of elements across dimensions of a SparseTensor.</p> <p><a href="../../raw_ops/sparsereducemaxsparse"><code translate="no" dir="ltr">SparseReduceMaxSparse(...)</code></a>: Computes the max of elements across dimensions of a SparseTensor.</p> <p><a href="../../raw_ops/sparsereducesum"><code translate="no" dir="ltr">SparseReduceSum(...)</code></a>: Computes the sum of elements across dimensions of a SparseTensor.</p> <p><a href="../../raw_ops/sparsereducesumsparse"><code translate="no" dir="ltr">SparseReduceSumSparse(...)</code></a>: Computes the sum of elements across dimensions of a SparseTensor.</p> <p><a href="../../raw_ops/sparsereorder"><code translate="no" dir="ltr">SparseReorder(...)</code></a>: Reorders a SparseTensor into the canonical, row-major ordering.</p> <p><a href="../../raw_ops/sparsereshape"><code translate="no" dir="ltr">SparseReshape(...)</code></a>: Reshapes a SparseTensor to represent values in a new dense shape.</p> <p><a href="../../raw_ops/sparsesegmentmean"><code translate="no" dir="ltr">SparseSegmentMean(...)</code></a>: Computes the mean along sparse segments of a tensor.</p> <p><a href="../../raw_ops/sparsesegmentmeangrad"><code translate="no" dir="ltr">SparseSegmentMeanGrad(...)</code></a>: Computes gradients for SparseSegmentMean.</p> <p><a href="../../raw_ops/sparsesegmentmeanwithnumsegments"><code translate="no" dir="ltr">SparseSegmentMeanWithNumSegments(...)</code></a>: Computes the mean along sparse segments of a tensor.</p> <p><a href="../../raw_ops/sparsesegmentsqrtn"><code translate="no" dir="ltr">SparseSegmentSqrtN(...)</code></a>: Computes the sum along sparse segments of a tensor divided by the sqrt of N.</p> <p><a href="../../raw_ops/sparsesegmentsqrtngrad"><code translate="no" dir="ltr">SparseSegmentSqrtNGrad(...)</code></a>: Computes gradients for SparseSegmentSqrtN.</p> <p><a href="../../raw_ops/sparsesegmentsqrtnwithnumsegments"><code translate="no" dir="ltr">SparseSegmentSqrtNWithNumSegments(...)</code></a>: Computes the sum along sparse segments of a tensor divided by the sqrt of N.</p> <p><a href="../../raw_ops/sparsesegmentsum"><code translate="no" dir="ltr">SparseSegmentSum(...)</code></a>: Computes the sum along sparse segments of a tensor.</p> <p><a href="../../raw_ops/sparsesegmentsumwithnumsegments"><code translate="no" dir="ltr">SparseSegmentSumWithNumSegments(...)</code></a>: Computes the sum along sparse segments of a tensor.</p> <p><a href="../../raw_ops/sparseslice"><code translate="no" dir="ltr">SparseSlice(...)</code></a>: Slice a <code translate="no" dir="ltr">SparseTensor</code> based on the <code translate="no" dir="ltr">start</code> and <code translate="no" dir="ltr">size</code>.</p> <p><a href="../../raw_ops/sparseslicegrad"><code translate="no" dir="ltr">SparseSliceGrad(...)</code></a>: The gradient operator for the SparseSlice op.</p> <p><a href="../../raw_ops/sparsesoftmax"><code translate="no" dir="ltr">SparseSoftmax(...)</code></a>: Applies softmax to a batched N-D <code translate="no" dir="ltr">SparseTensor</code>.</p> <p><a href="../../raw_ops/sparsesoftmaxcrossentropywithlogits"><code translate="no" dir="ltr">SparseSoftmaxCrossEntropyWithLogits(...)</code></a>: Computes softmax cross entropy cost and gradients to backpropagate.</p> <p><a href="../../raw_ops/sparsesparsemaximum"><code translate="no" dir="ltr">SparseSparseMaximum(...)</code></a>: Returns the element-wise max of two SparseTensors.</p> <p><a href="../../raw_ops/sparsesparseminimum"><code translate="no" dir="ltr">SparseSparseMinimum(...)</code></a>: Returns the element-wise min of two SparseTensors.</p> <p><a href="../../raw_ops/sparsesplit"><code translate="no" dir="ltr">SparseSplit(...)</code></a>: Split a <code translate="no" dir="ltr">SparseTensor</code> into <code translate="no" dir="ltr">num_split</code> tensors along one dimension.</p> <p><a href="../../raw_ops/sparsetensordenseadd"><code translate="no" dir="ltr">SparseTensorDenseAdd(...)</code></a>: Adds up a <code translate="no" dir="ltr">SparseTensor</code> and a dense <code translate="no" dir="ltr">Tensor</code>, producing a dense <code translate="no" dir="ltr">Tensor</code>.</p> <p><a href="../../raw_ops/sparsetensordensematmul"><code translate="no" dir="ltr">SparseTensorDenseMatMul(...)</code></a>: Multiply SparseTensor (of rank 2) "A" by dense matrix "B".</p> <p><a href="../../raw_ops/sparsetensorslicedataset"><code translate="no" dir="ltr">SparseTensorSliceDataset(...)</code></a>: Creates a dataset that splits a SparseTensor into elements row-wise.</p> <p><a href="../../raw_ops/sparsetensortocsrsparsematrix"><code translate="no" dir="ltr">SparseTensorToCSRSparseMatrix(...)</code></a>: Converts a SparseTensor to a (possibly batched) CSRSparseMatrix.</p> <p><a href="../../raw_ops/sparsetodense"><code translate="no" dir="ltr">SparseToDense(...)</code></a>: Converts a sparse representation into a dense tensor.</p> <p><a href="../../raw_ops/sparsetosparsesetoperation"><code translate="no" dir="ltr">SparseToSparseSetOperation(...)</code></a>: Applies set operation along last dimension of 2 <code translate="no" dir="ltr">SparseTensor</code> inputs.</p> <p><a href="../../raw_ops/spence"><code translate="no" dir="ltr">Spence(...)</code></a></p> <p><a href="../../raw_ops/split"><code translate="no" dir="ltr">Split(...)</code></a>: Splits a tensor into <code translate="no" dir="ltr">num_split</code> tensors along one dimension.</p> <p><a href="../../raw_ops/splitv"><code translate="no" dir="ltr">SplitV(...)</code></a>: Splits a tensor into <code translate="no" dir="ltr">num_split</code> tensors along one dimension.</p> <p><a href="../../raw_ops/sqldataset"><code translate="no" dir="ltr">SqlDataset(...)</code></a>: Creates a dataset that executes a SQL query and emits rows of the result set.</p> <p><a href="../../raw_ops/sqrt"><code translate="no" dir="ltr">Sqrt(...)</code></a>: Computes square root of x element-wise.</p> <p><a href="../../raw_ops/sqrtgrad"><code translate="no" dir="ltr">SqrtGrad(...)</code></a>: Computes the gradient for the sqrt of <code translate="no" dir="ltr">x</code> wrt its input.</p> <p><a href="../../raw_ops/square"><code translate="no" dir="ltr">Square(...)</code></a>: Computes square of x element-wise.</p> <p><a href="../../raw_ops/squareddifference"><code translate="no" dir="ltr">SquaredDifference(...)</code></a>: Returns conj(x - y)(x - y) element-wise.</p> <p><a href="../../raw_ops/squeeze"><code translate="no" dir="ltr">Squeeze(...)</code></a>: Removes dimensions of size 1 from the shape of a tensor.</p> <p><a href="../../raw_ops/stack"><code translate="no" dir="ltr">Stack(...)</code></a>: Deprecated, use StackV2.</p> <p><a href="../../raw_ops/stackclose"><code translate="no" dir="ltr">StackClose(...)</code></a>: Deprecated, use StackCloseV2.</p> <p><a href="../../raw_ops/stackclosev2"><code translate="no" dir="ltr">StackCloseV2(...)</code></a>: Delete the stack from its resource container.</p> <p><a href="../../raw_ops/stackpop"><code translate="no" dir="ltr">StackPop(...)</code></a>: Deprecated, use StackPopV2.</p> <p><a href="../../raw_ops/stackpopv2"><code translate="no" dir="ltr">StackPopV2(...)</code></a>: Pop the element at the top of the stack.</p> <p><a href="../../raw_ops/stackpush"><code translate="no" dir="ltr">StackPush(...)</code></a>: Deprecated, use StackPushV2.</p> <p><a href="../../raw_ops/stackpushv2"><code translate="no" dir="ltr">StackPushV2(...)</code></a>: Push an element onto the stack.</p> <p><a href="../../raw_ops/stackv2"><code translate="no" dir="ltr">StackV2(...)</code></a>: A stack that produces elements in first-in last-out order.</p> <p><a href="../../raw_ops/stage"><code translate="no" dir="ltr">Stage(...)</code></a>: Stage values similar to a lightweight Enqueue.</p> <p><a href="../../raw_ops/stageclear"><code translate="no" dir="ltr">StageClear(...)</code></a>: Op removes all elements in the underlying container.</p> <p><a href="../../raw_ops/stagepeek"><code translate="no" dir="ltr">StagePeek(...)</code></a>: Op peeks at the values at the specified index. If the</p> <p><a href="../../raw_ops/stagesize"><code translate="no" dir="ltr">StageSize(...)</code></a>: Op returns the number of elements in the underlying container.</p> <p><a href="../../raw_ops/statefulpartitionedcall"><code translate="no" dir="ltr">StatefulPartitionedCall(...)</code></a>: returns <code translate="no" dir="ltr">f(inputs)</code>, where <code translate="no" dir="ltr">f</code>'s body is placed and partitioned.</p> <p><a href="../../raw_ops/statefulrandombinomial"><code translate="no" dir="ltr">StatefulRandomBinomial(...)</code></a></p> <p><a href="../../raw_ops/statefulstandardnormal"><code translate="no" dir="ltr">StatefulStandardNormal(...)</code></a>: Outputs random values from a normal distribution. This op is deprecated in favor of op 'StatefulStandardNormalV2'</p> <p><a href="../../raw_ops/statefulstandardnormalv2"><code translate="no" dir="ltr">StatefulStandardNormalV2(...)</code></a>: Outputs random values from a normal distribution.</p> <p><a href="../../raw_ops/statefultruncatednormal"><code translate="no" dir="ltr">StatefulTruncatedNormal(...)</code></a>: Outputs random values from a truncated normal distribution.</p> <p><a href="../../raw_ops/statefuluniform"><code translate="no" dir="ltr">StatefulUniform(...)</code></a>: Outputs random values from a uniform distribution.</p> <p><a href="../../raw_ops/statefuluniformfullint"><code translate="no" dir="ltr">StatefulUniformFullInt(...)</code></a>: Outputs random integers from a uniform distribution.</p> <p><a href="../../raw_ops/statefuluniformint"><code translate="no" dir="ltr">StatefulUniformInt(...)</code></a>: Outputs random integers from a uniform distribution.</p> <p><a href="../../raw_ops/statelesscase"><code translate="no" dir="ltr">StatelessCase(...)</code></a>: An n-way switch statement which calls a single branch function.</p> <p><a href="../../raw_ops/statelessif"><code translate="no" dir="ltr">StatelessIf(...)</code></a>: output = cond ? then_branch(input) : else_branch(input)</p> <p><a href="../../raw_ops/statelessmultinomial"><code translate="no" dir="ltr">StatelessMultinomial(...)</code></a>: Draws samples from a multinomial distribution.</p> <p><a href="../../raw_ops/statelessparameterizedtruncatednormal"><code translate="no" dir="ltr">StatelessParameterizedTruncatedNormal(...)</code></a></p> <p><a href="../../raw_ops/statelessrandombinomial"><code translate="no" dir="ltr">StatelessRandomBinomial(...)</code></a>: Outputs deterministic pseudorandom random numbers from a binomial distribution.</p> <p><a href="../../raw_ops/statelessrandomgammav2"><code translate="no" dir="ltr">StatelessRandomGammaV2(...)</code></a>: Outputs deterministic pseudorandom random numbers from a gamma distribution.</p> <p><a href="../../raw_ops/statelessrandomgetkeycounteralg"><code translate="no" dir="ltr">StatelessRandomGetKeyCounterAlg(...)</code></a>: Picks the best algorithm based on device, and scrambles seed into key and counter.</p> <p><a href="../../raw_ops/statelessrandomnormal"><code translate="no" dir="ltr">StatelessRandomNormal(...)</code></a>: Outputs deterministic pseudorandom values from a normal distribution.</p> <p><a href="../../raw_ops/statelessrandomnormalv2"><code translate="no" dir="ltr">StatelessRandomNormalV2(...)</code></a>: Outputs deterministic pseudorandom values from a normal distribution.</p> <p><a href="../../raw_ops/statelessrandompoisson"><code translate="no" dir="ltr">StatelessRandomPoisson(...)</code></a>: Outputs deterministic pseudorandom random numbers from a Poisson distribution.</p> <p><a href="../../raw_ops/statelessrandomuniform"><code translate="no" dir="ltr">StatelessRandomUniform(...)</code></a>: Outputs deterministic pseudorandom random values from a uniform distribution.</p> <p><a href="../../raw_ops/statelessrandomuniformfullint"><code translate="no" dir="ltr">StatelessRandomUniformFullInt(...)</code></a>: Outputs deterministic pseudorandom random integers from a uniform distribution.</p> <p><a href="../../raw_ops/statelessrandomuniformfullintv2"><code translate="no" dir="ltr">StatelessRandomUniformFullIntV2(...)</code></a>: Outputs deterministic pseudorandom random integers from a uniform distribution.</p> <p><a href="../../raw_ops/statelessrandomuniformint"><code translate="no" dir="ltr">StatelessRandomUniformInt(...)</code></a>: Outputs deterministic pseudorandom random integers from a uniform distribution.</p> <p><a href="../../raw_ops/statelessrandomuniformintv2"><code translate="no" dir="ltr">StatelessRandomUniformIntV2(...)</code></a>: Outputs deterministic pseudorandom random integers from a uniform distribution.</p> <p><a href="../../raw_ops/statelessrandomuniformv2"><code translate="no" dir="ltr">StatelessRandomUniformV2(...)</code></a>: Outputs deterministic pseudorandom random values from a uniform distribution.</p> <p><a href="../../raw_ops/statelesssampledistortedboundingbox"><code translate="no" dir="ltr">StatelessSampleDistortedBoundingBox(...)</code></a>: Generate a randomly distorted bounding box for an image deterministically.</p> <p><a href="../../raw_ops/statelesstruncatednormal"><code translate="no" dir="ltr">StatelessTruncatedNormal(...)</code></a>: Outputs deterministic pseudorandom values from a truncated normal distribution.</p> <p><a href="../../raw_ops/statelesstruncatednormalv2"><code translate="no" dir="ltr">StatelessTruncatedNormalV2(...)</code></a>: Outputs deterministic pseudorandom values from a truncated normal distribution.</p> <p><a href="../../raw_ops/statelesswhile"><code translate="no" dir="ltr">StatelessWhile(...)</code></a>: output = input; While (Cond(output)) { output = Body(output) }</p> <p><a href="../../raw_ops/staticregexfullmatch"><code translate="no" dir="ltr">StaticRegexFullMatch(...)</code></a>: Check if the input matches the regex pattern.</p> <p><a href="../../raw_ops/staticregexreplace"><code translate="no" dir="ltr">StaticRegexReplace(...)</code></a>: Replaces the match of pattern in input with rewrite.</p> <p><a href="../../raw_ops/statsaggregatorhandle"><code translate="no" dir="ltr">StatsAggregatorHandle(...)</code></a>: Creates a statistics manager resource.</p> <p><a href="../../raw_ops/statsaggregatorhandlev2"><code translate="no" dir="ltr">StatsAggregatorHandleV2(...)</code></a></p> <p><a href="../../raw_ops/statsaggregatorsetsummarywriter"><code translate="no" dir="ltr">StatsAggregatorSetSummaryWriter(...)</code></a>: Set a summary_writer_interface to record statistics using given stats_aggregator.</p> <p><a href="../../raw_ops/statsaggregatorsummary"><code translate="no" dir="ltr">StatsAggregatorSummary(...)</code></a>: Produces a summary of any statistics recorded by the given statistics manager.</p> <p><a href="../../raw_ops/stopgradient"><code translate="no" dir="ltr">StopGradient(...)</code></a>: Stops gradient computation.</p> <p><a href="../../raw_ops/stridedslice"><code translate="no" dir="ltr">StridedSlice(...)</code></a>: Return a strided slice from <code translate="no" dir="ltr">input</code>.</p> <p><a href="../../raw_ops/stridedsliceassign"><code translate="no" dir="ltr">StridedSliceAssign(...)</code></a>: Assign <code translate="no" dir="ltr">value</code> to the sliced l-value reference of <code translate="no" dir="ltr">ref</code>.</p> <p><a href="../../raw_ops/stridedslicegrad"><code translate="no" dir="ltr">StridedSliceGrad(...)</code></a>: Returns the gradient of <code translate="no" dir="ltr">StridedSlice</code>.</p> <p><a href="../../raw_ops/stringformat"><code translate="no" dir="ltr">StringFormat(...)</code></a>: Formats a string template using a list of tensors.</p> <p><a href="../../raw_ops/stringjoin"><code translate="no" dir="ltr">StringJoin(...)</code></a>: Joins the strings in the given list of string tensors into one tensor;</p> <p><a href="../../raw_ops/stringlength"><code translate="no" dir="ltr">StringLength(...)</code></a>: String lengths of <code translate="no" dir="ltr">input</code>.</p> <p><a href="../../raw_ops/stringlower"><code translate="no" dir="ltr">StringLower(...)</code></a>: Converts all uppercase characters into their respective lowercase replacements.</p> <p><a href="../../raw_ops/stringngrams"><code translate="no" dir="ltr">StringNGrams(...)</code></a>: Creates ngrams from ragged string data.</p> <p><a href="../../raw_ops/stringsplit"><code translate="no" dir="ltr">StringSplit(...)</code></a>: Split elements of <code translate="no" dir="ltr">input</code> based on <code translate="no" dir="ltr">delimiter</code> into a <code translate="no" dir="ltr">SparseTensor</code>.</p> <p><a href="../../raw_ops/stringsplitv2"><code translate="no" dir="ltr">StringSplitV2(...)</code></a>: Split elements of <code translate="no" dir="ltr">source</code> based on <code translate="no" dir="ltr">sep</code> into a <code translate="no" dir="ltr">SparseTensor</code>.</p> <p><a href="../../raw_ops/stringstrip"><code translate="no" dir="ltr">StringStrip(...)</code></a>: Strip leading and trailing whitespaces from the Tensor.</p> <p><a href="../../raw_ops/stringtohashbucket"><code translate="no" dir="ltr">StringToHashBucket(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p> <p><a href="../../raw_ops/stringtohashbucketfast"><code translate="no" dir="ltr">StringToHashBucketFast(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p> <p><a href="../../raw_ops/stringtohashbucketstrong"><code translate="no" dir="ltr">StringToHashBucketStrong(...)</code></a>: Converts each string in the input Tensor to its hash mod by a number of buckets.</p> <p><a href="../../raw_ops/stringtonumber"><code translate="no" dir="ltr">StringToNumber(...)</code></a>: Converts each string in the input Tensor to the specified numeric type.</p> <p><a href="../../raw_ops/stringupper"><code translate="no" dir="ltr">StringUpper(...)</code></a>: Converts all lowercase characters into their respective uppercase replacements.</p> <p><a href="../../raw_ops/sub"><code translate="no" dir="ltr">Sub(...)</code></a>: Returns x - y element-wise.</p> <p><a href="../../raw_ops/substr"><code translate="no" dir="ltr">Substr(...)</code></a>: Return substrings from <code translate="no" dir="ltr">Tensor</code> of strings.</p> <p><a href="../../raw_ops/sum"><code translate="no" dir="ltr">Sum(...)</code></a>: Computes the sum of elements across dimensions of a tensor.</p> <p><a href="../../raw_ops/summarywriter"><code translate="no" dir="ltr">SummaryWriter(...)</code></a></p> <p><a href="../../raw_ops/svd"><code translate="no" dir="ltr">Svd(...)</code></a>: Computes the singular value decompositions of one or more matrices.</p> <p><a href="../../raw_ops/switch"><code translate="no" dir="ltr">Switch(...)</code></a>: Forwards <code translate="no" dir="ltr">data</code> to the output port determined by <code translate="no" dir="ltr">pred</code>.</p> <p><a href="../../raw_ops/symbolicgradient"><code translate="no" dir="ltr">SymbolicGradient(...)</code></a>: Computes the gradient function for function f via backpropagation.</p> <p><a href="../../raw_ops/tfrecorddataset"><code translate="no" dir="ltr">TFRecordDataset(...)</code></a>: Creates a dataset that emits the records from one or more TFRecord files.</p> <p><a href="../../raw_ops/tfrecordreader"><code translate="no" dir="ltr">TFRecordReader(...)</code></a>: A Reader that outputs the records from a TensorFlow Records file.</p> <p><a href="../../raw_ops/tfrecordreaderv2"><code translate="no" dir="ltr">TFRecordReaderV2(...)</code></a>: A Reader that outputs the records from a TensorFlow Records file.</p> <p><a href="../../raw_ops/tpucompilationresult"><code translate="no" dir="ltr">TPUCompilationResult(...)</code></a>: Returns the result of a TPU compilation.</p> <p><a href="../../raw_ops/tpuembeddingactivations"><code translate="no" dir="ltr">TPUEmbeddingActivations(...)</code></a>: An op enabling differentiation of TPU Embeddings.</p> <p><a href="../../raw_ops/tpuordinalselector"><code translate="no" dir="ltr">TPUOrdinalSelector(...)</code></a>: A TPU core selector Op.</p> <p><a href="../../raw_ops/tpupartitionedcall"><code translate="no" dir="ltr">TPUPartitionedCall(...)</code></a>: Calls a function placed on a specified TPU device.</p> <p><a href="../../raw_ops/tpureplicatemetadata"><code translate="no" dir="ltr">TPUReplicateMetadata(...)</code></a>: Metadata indicating how the TPU computation should be replicated.</p> <p><a href="../../raw_ops/tpureplicatedinput"><code translate="no" dir="ltr">TPUReplicatedInput(...)</code></a>: Connects N inputs to an N-way replicated TPU computation.</p> <p><a href="../../raw_ops/tpureplicatedoutput"><code translate="no" dir="ltr">TPUReplicatedOutput(...)</code></a>: Connects N outputs from an N-way replicated TPU computation.</p> <p><a href="../../raw_ops/takedataset"><code translate="no" dir="ltr">TakeDataset(...)</code></a>: Creates a dataset that contains <code translate="no" dir="ltr">count</code> elements from the <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/takemanysparsefromtensorsmap"><code translate="no" dir="ltr">TakeManySparseFromTensorsMap(...)</code></a>: Read <code translate="no" dir="ltr">SparseTensors</code> from a <code translate="no" dir="ltr">SparseTensorsMap</code> and concatenate them.</p> <p><a href="../../raw_ops/takewhiledataset"><code translate="no" dir="ltr">TakeWhileDataset(...)</code></a>: Creates a dataset that stops iteration when predicate` is false.</p> <p><a href="../../raw_ops/tan"><code translate="no" dir="ltr">Tan(...)</code></a>: Computes tan of x element-wise.</p> <p><a href="../../raw_ops/tanh"><code translate="no" dir="ltr">Tanh(...)</code></a>: Computes hyperbolic tangent of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="../../raw_ops/tanhgrad"><code translate="no" dir="ltr">TanhGrad(...)</code></a>: Computes the gradient for the tanh of <code translate="no" dir="ltr">x</code> wrt its input.</p> <p><a href="../../raw_ops/temporaryvariable"><code translate="no" dir="ltr">TemporaryVariable(...)</code></a>: Returns a tensor that may be mutated, but only persists within a single step.</p> <p><a href="../../raw_ops/tensorarray"><code translate="no" dir="ltr">TensorArray(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayclose"><code translate="no" dir="ltr">TensorArrayClose(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayclosev2"><code translate="no" dir="ltr">TensorArrayCloseV2(...)</code></a>: Deprecated. Use TensorArrayCloseV3</p> <p><a href="../../raw_ops/tensorarrayclosev3"><code translate="no" dir="ltr">TensorArrayCloseV3(...)</code></a>: Delete the TensorArray from its resource container.</p> <p><a href="../../raw_ops/tensorarrayconcat"><code translate="no" dir="ltr">TensorArrayConcat(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayconcatv2"><code translate="no" dir="ltr">TensorArrayConcatV2(...)</code></a>: Deprecated. Use TensorArrayConcatV3</p> <p><a href="../../raw_ops/tensorarrayconcatv3"><code translate="no" dir="ltr">TensorArrayConcatV3(...)</code></a>: Concat the elements from the TensorArray into value <code translate="no" dir="ltr">value</code>.</p> <p><a href="../../raw_ops/tensorarraygather"><code translate="no" dir="ltr">TensorArrayGather(...)</code></a></p> <p><a href="../../raw_ops/tensorarraygatherv2"><code translate="no" dir="ltr">TensorArrayGatherV2(...)</code></a>: Deprecated. Use TensorArrayGatherV3</p> <p><a href="../../raw_ops/tensorarraygatherv3"><code translate="no" dir="ltr">TensorArrayGatherV3(...)</code></a>: Gather specific elements from the TensorArray into output <code translate="no" dir="ltr">value</code>.</p> <p><a href="../../raw_ops/tensorarraygrad"><code translate="no" dir="ltr">TensorArrayGrad(...)</code></a></p> <p><a href="../../raw_ops/tensorarraygradv2"><code translate="no" dir="ltr">TensorArrayGradV2(...)</code></a>: Deprecated. Use TensorArrayGradV3</p> <p><a href="../../raw_ops/tensorarraygradv3"><code translate="no" dir="ltr">TensorArrayGradV3(...)</code></a>: Creates a TensorArray for storing the gradients of values in the given handle.</p> <p><a href="../../raw_ops/tensorarraygradwithshape"><code translate="no" dir="ltr">TensorArrayGradWithShape(...)</code></a>: Creates a TensorArray for storing multiple gradients of values in the given handle.</p> <p><a href="../../raw_ops/tensorarraypack"><code translate="no" dir="ltr">TensorArrayPack(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayread"><code translate="no" dir="ltr">TensorArrayRead(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayreadv2"><code translate="no" dir="ltr">TensorArrayReadV2(...)</code></a>: Deprecated. Use TensorArrayReadV3</p> <p><a href="../../raw_ops/tensorarrayreadv3"><code translate="no" dir="ltr">TensorArrayReadV3(...)</code></a>: Read an element from the TensorArray into output <code translate="no" dir="ltr">value</code>.</p> <p><a href="../../raw_ops/tensorarrayscatter"><code translate="no" dir="ltr">TensorArrayScatter(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayscatterv2"><code translate="no" dir="ltr">TensorArrayScatterV2(...)</code></a>: Deprecated. Use TensorArrayScatterV3</p> <p><a href="../../raw_ops/tensorarrayscatterv3"><code translate="no" dir="ltr">TensorArrayScatterV3(...)</code></a>: Scatter the data from the input value into specific TensorArray elements.</p> <p><a href="../../raw_ops/tensorarraysize"><code translate="no" dir="ltr">TensorArraySize(...)</code></a></p> <p><a href="../../raw_ops/tensorarraysizev2"><code translate="no" dir="ltr">TensorArraySizeV2(...)</code></a>: Deprecated. Use TensorArraySizeV3</p> <p><a href="../../raw_ops/tensorarraysizev3"><code translate="no" dir="ltr">TensorArraySizeV3(...)</code></a>: Get the current size of the TensorArray.</p> <p><a href="../../raw_ops/tensorarraysplit"><code translate="no" dir="ltr">TensorArraySplit(...)</code></a></p> <p><a href="../../raw_ops/tensorarraysplitv2"><code translate="no" dir="ltr">TensorArraySplitV2(...)</code></a>: Deprecated. Use TensorArraySplitV3</p> <p><a href="../../raw_ops/tensorarraysplitv3"><code translate="no" dir="ltr">TensorArraySplitV3(...)</code></a>: Split the data from the input value into TensorArray elements.</p> <p><a href="../../raw_ops/tensorarrayunpack"><code translate="no" dir="ltr">TensorArrayUnpack(...)</code></a></p> <p><a href="../../raw_ops/tensorarrayv2"><code translate="no" dir="ltr">TensorArrayV2(...)</code></a>: Deprecated. Use TensorArrayV3</p> <p><a href="../../raw_ops/tensorarrayv3"><code translate="no" dir="ltr">TensorArrayV3(...)</code></a>: An array of Tensors of given size.</p> <p><a href="../../raw_ops/tensorarraywrite"><code translate="no" dir="ltr">TensorArrayWrite(...)</code></a></p> <p><a href="../../raw_ops/tensorarraywritev2"><code translate="no" dir="ltr">TensorArrayWriteV2(...)</code></a>: Deprecated. Use TensorArrayGradV3</p> <p><a href="../../raw_ops/tensorarraywritev3"><code translate="no" dir="ltr">TensorArrayWriteV3(...)</code></a>: Push an element onto the tensor_array.</p> <p><a href="../../raw_ops/tensordataset"><code translate="no" dir="ltr">TensorDataset(...)</code></a>: Creates a dataset that emits <code translate="no" dir="ltr">components</code> as a tuple of tensors once.</p> <p><a href="../../raw_ops/tensorlistconcat"><code translate="no" dir="ltr">TensorListConcat(...)</code></a>: Concats all tensors in the list along the 0th dimension.</p> <p><a href="../../raw_ops/tensorlistconcatlists"><code translate="no" dir="ltr">TensorListConcatLists(...)</code></a></p> <p><a href="../../raw_ops/tensorlistconcatv2"><code translate="no" dir="ltr">TensorListConcatV2(...)</code></a>: Concats all tensors in the list along the 0th dimension.</p> <p><a href="../../raw_ops/tensorlistelementshape"><code translate="no" dir="ltr">TensorListElementShape(...)</code></a>: The shape of the elements of the given list, as a tensor.</p> <p><a href="../../raw_ops/tensorlistfromtensor"><code translate="no" dir="ltr">TensorListFromTensor(...)</code></a>: Creates a TensorList which, when stacked, has the value of <code translate="no" dir="ltr">tensor</code>.</p> <p><a href="../../raw_ops/tensorlistgather"><code translate="no" dir="ltr">TensorListGather(...)</code></a>: Creates a Tensor by indexing into the TensorList.</p> <p><a href="../../raw_ops/tensorlistgetitem"><code translate="no" dir="ltr">TensorListGetItem(...)</code></a>: Returns the item in the list with the given index.</p> <p><a href="../../raw_ops/tensorlistlength"><code translate="no" dir="ltr">TensorListLength(...)</code></a>: Returns the number of tensors in the input tensor list.</p> <p><a href="../../raw_ops/tensorlistpopback"><code translate="no" dir="ltr">TensorListPopBack(...)</code></a>: Returns the last element of the input list as well as a list with all but that element.</p> <p><a href="../../raw_ops/tensorlistpushback"><code translate="no" dir="ltr">TensorListPushBack(...)</code></a>: Returns a list which has the passed-in <code translate="no" dir="ltr">Tensor</code> as last element and the other elements of the given list in <code translate="no" dir="ltr">input_handle</code>.</p> <p><a href="../../raw_ops/tensorlistpushbackbatch"><code translate="no" dir="ltr">TensorListPushBackBatch(...)</code></a></p> <p><a href="../../raw_ops/tensorlistreserve"><code translate="no" dir="ltr">TensorListReserve(...)</code></a>: List of the given size with empty elements.</p> <p><a href="../../raw_ops/tensorlistresize"><code translate="no" dir="ltr">TensorListResize(...)</code></a>: Resizes the list.</p> <p><a href="../../raw_ops/tensorlistscatter"><code translate="no" dir="ltr">TensorListScatter(...)</code></a>: Creates a TensorList by indexing into a Tensor.</p> <p><a href="../../raw_ops/tensorlistscatterintoexistinglist"><code translate="no" dir="ltr">TensorListScatterIntoExistingList(...)</code></a>: Scatters tensor at indices in an input list.</p> <p><a href="../../raw_ops/tensorlistscatterv2"><code translate="no" dir="ltr">TensorListScatterV2(...)</code></a>: Creates a TensorList by indexing into a Tensor.</p> <p><a href="../../raw_ops/tensorlistsetitem"><code translate="no" dir="ltr">TensorListSetItem(...)</code></a>: Sets the index-th position of the list to contain the given tensor.</p> <p><a href="../../raw_ops/tensorlistsplit"><code translate="no" dir="ltr">TensorListSplit(...)</code></a>: Splits a tensor into a list.</p> <p><a href="../../raw_ops/tensorliststack"><code translate="no" dir="ltr">TensorListStack(...)</code></a>: Stacks all tensors in the list.</p> <p><a href="../../raw_ops/tensorscatteradd"><code translate="no" dir="ltr">TensorScatterAdd(...)</code></a>: Adds sparse <code translate="no" dir="ltr">updates</code> to an existing tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/tensorscattermax"><code translate="no" dir="ltr">TensorScatterMax(...)</code></a></p> <p><a href="../../raw_ops/tensorscattermin"><code translate="no" dir="ltr">TensorScatterMin(...)</code></a></p> <p><a href="../../raw_ops/tensorscattersub"><code translate="no" dir="ltr">TensorScatterSub(...)</code></a>: Subtracts sparse <code translate="no" dir="ltr">updates</code> from an existing tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/tensorscatterupdate"><code translate="no" dir="ltr">TensorScatterUpdate(...)</code></a>: Scatter <code translate="no" dir="ltr">updates</code> into an existing tensor according to <code translate="no" dir="ltr">indices</code>.</p> <p><a href="../../raw_ops/tensorslicedataset"><code translate="no" dir="ltr">TensorSliceDataset(...)</code></a>: Creates a dataset that emits each dim-0 slice of <code translate="no" dir="ltr">components</code> once.</p> <p><a href="../../raw_ops/tensorstridedsliceupdate"><code translate="no" dir="ltr">TensorStridedSliceUpdate(...)</code></a>: Assign <code translate="no" dir="ltr">value</code> to the sliced l-value reference of <code translate="no" dir="ltr">input</code>.</p> <p><a href="../../raw_ops/tensorsummary"><code translate="no" dir="ltr">TensorSummary(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with a tensor.</p> <p><a href="../../raw_ops/tensorsummaryv2"><code translate="no" dir="ltr">TensorSummaryV2(...)</code></a>: Outputs a <code translate="no" dir="ltr">Summary</code> protocol buffer with a tensor and per-plugin data.</p> <p><a href="../../raw_ops/textlinedataset"><code translate="no" dir="ltr">TextLineDataset(...)</code></a>: Creates a dataset that emits the lines of one or more text files.</p> <p><a href="../../raw_ops/textlinereader"><code translate="no" dir="ltr">TextLineReader(...)</code></a>: A Reader that outputs the lines of a file delimited by '\n'.</p> <p><a href="../../raw_ops/textlinereaderv2"><code translate="no" dir="ltr">TextLineReaderV2(...)</code></a>: A Reader that outputs the lines of a file delimited by '\n'.</p> <p><a href="../../raw_ops/threadpooldataset"><code translate="no" dir="ltr">ThreadPoolDataset(...)</code></a>: Creates a dataset that uses a custom thread pool to compute <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/threadpoolhandle"><code translate="no" dir="ltr">ThreadPoolHandle(...)</code></a>: Creates a dataset that uses a custom thread pool to compute <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/threadunsafeunigramcandidatesampler"><code translate="no" dir="ltr">ThreadUnsafeUnigramCandidateSampler(...)</code></a>: Generates labels for candidate sampling with a learned unigram distribution.</p> <p><a href="../../raw_ops/tile"><code translate="no" dir="ltr">Tile(...)</code></a>: Constructs a tensor by tiling a given tensor.</p> <p><a href="../../raw_ops/tilegrad"><code translate="no" dir="ltr">TileGrad(...)</code></a>: Returns the gradient of <code translate="no" dir="ltr">Tile</code>.</p> <p><a href="../../raw_ops/timestamp"><code translate="no" dir="ltr">Timestamp(...)</code></a>: Provides the time since epoch in seconds.</p> <p><a href="../../raw_ops/tobool"><code translate="no" dir="ltr">ToBool(...)</code></a>: Converts a tensor to a scalar predicate.</p> <p><a href="../../raw_ops/topk"><code translate="no" dir="ltr">TopK(...)</code></a>: Finds values and indices of the <code translate="no" dir="ltr">k</code> largest elements for the last dimension.</p> <p><a href="../../raw_ops/topkv2"><code translate="no" dir="ltr">TopKV2(...)</code></a>: Finds values and indices of the <code translate="no" dir="ltr">k</code> largest elements for the last dimension.</p> <p><a href="../../raw_ops/transpose"><code translate="no" dir="ltr">Transpose(...)</code></a>: Shuffle dimensions of x according to a permutation.</p> <p><a href="../../raw_ops/tridiagonalmatmul"><code translate="no" dir="ltr">TridiagonalMatMul(...)</code></a>: Calculate product with tridiagonal matrix.</p> <p><a href="../../raw_ops/tridiagonalsolve"><code translate="no" dir="ltr">TridiagonalSolve(...)</code></a>: Solves tridiagonal systems of equations.</p> <p><a href="../../raw_ops/truncatediv"><code translate="no" dir="ltr">TruncateDiv(...)</code></a>: Returns x / y element-wise for integer types.</p> <p><a href="../../raw_ops/truncatemod"><code translate="no" dir="ltr">TruncateMod(...)</code></a>: Returns element-wise remainder of division. This emulates C semantics in that</p> <p><a href="../../raw_ops/truncatednormal"><code translate="no" dir="ltr">TruncatedNormal(...)</code></a>: Outputs random values from a truncated normal distribution.</p> <p><a href="../../raw_ops/unbatch"><code translate="no" dir="ltr">Unbatch(...)</code></a>: Reverses the operation of Batch for a single output Tensor.</p> <p><a href="../../raw_ops/unbatchdataset"><code translate="no" dir="ltr">UnbatchDataset(...)</code></a>: A dataset that splits the elements of its input into multiple elements.</p> <p><a href="../../raw_ops/unbatchgrad"><code translate="no" dir="ltr">UnbatchGrad(...)</code></a>: Gradient of Unbatch.</p> <p><a href="../../raw_ops/uncompresselement"><code translate="no" dir="ltr">UncompressElement(...)</code></a>: Uncompresses a compressed dataset element.</p> <p><a href="../../raw_ops/unicodedecode"><code translate="no" dir="ltr">UnicodeDecode(...)</code></a>: Decodes each string in <code translate="no" dir="ltr">input</code> into a sequence of Unicode code points.</p> <p><a href="../../raw_ops/unicodedecodewithoffsets"><code translate="no" dir="ltr">UnicodeDecodeWithOffsets(...)</code></a>: Decodes each string in <code translate="no" dir="ltr">input</code> into a sequence of Unicode code points.</p> <p><a href="../../raw_ops/unicodeencode"><code translate="no" dir="ltr">UnicodeEncode(...)</code></a>: Encode a tensor of ints into unicode strings.</p> <p><a href="../../raw_ops/unicodescript"><code translate="no" dir="ltr">UnicodeScript(...)</code></a>: Determine the script codes of a given tensor of Unicode integer code points.</p> <p><a href="../../raw_ops/unicodetranscode"><code translate="no" dir="ltr">UnicodeTranscode(...)</code></a>: Transcode the input text from a source encoding to a destination encoding.</p> <p><a href="../../raw_ops/uniformcandidatesampler"><code translate="no" dir="ltr">UniformCandidateSampler(...)</code></a>: Generates labels for candidate sampling with a uniform distribution.</p> <p><a href="../../raw_ops/unique"><code translate="no" dir="ltr">Unique(...)</code></a>: Finds unique elements in a 1-D tensor.</p> <p><a href="../../raw_ops/uniquedataset"><code translate="no" dir="ltr">UniqueDataset(...)</code></a>: Creates a dataset that contains the unique elements of <code translate="no" dir="ltr">input_dataset</code>.</p> <p><a href="../../raw_ops/uniquev2"><code translate="no" dir="ltr">UniqueV2(...)</code></a>: Finds unique elements along an axis of a tensor.</p> <p><a href="../../raw_ops/uniquewithcounts"><code translate="no" dir="ltr">UniqueWithCounts(...)</code></a>: Finds unique elements in a 1-D tensor.</p> <p><a href="../../raw_ops/uniquewithcountsv2"><code translate="no" dir="ltr">UniqueWithCountsV2(...)</code></a>: Finds unique elements along an axis of a tensor.</p> <p><a href="../../raw_ops/unpack"><code translate="no" dir="ltr">Unpack(...)</code></a>: Unpacks a given dimension of a rank-<code translate="no" dir="ltr">R</code> tensor into <code translate="no" dir="ltr">num</code> rank-<code translate="no" dir="ltr">(R-1)</code> tensors.</p> <p><a href="../../raw_ops/unravelindex"><code translate="no" dir="ltr">UnravelIndex(...)</code></a>: Converts an array of flat indices into a tuple of coordinate arrays.</p> <p><a href="../../raw_ops/unsortedsegmentjoin"><code translate="no" dir="ltr">UnsortedSegmentJoin(...)</code></a>: Joins the elements of <code translate="no" dir="ltr">inputs</code> based on <code translate="no" dir="ltr">segment_ids</code>.</p> <p><a href="../../raw_ops/unsortedsegmentmax"><code translate="no" dir="ltr">UnsortedSegmentMax(...)</code></a>: Computes the maximum along segments of a tensor.</p> <p><a href="../../raw_ops/unsortedsegmentmin"><code translate="no" dir="ltr">UnsortedSegmentMin(...)</code></a>: Computes the minimum along segments of a tensor.</p> <p><a href="../../raw_ops/unsortedsegmentprod"><code translate="no" dir="ltr">UnsortedSegmentProd(...)</code></a>: Computes the product along segments of a tensor.</p> <p><a href="../../raw_ops/unsortedsegmentsum"><code translate="no" dir="ltr">UnsortedSegmentSum(...)</code></a>: Computes the sum along segments of a tensor.</p> <p><a href="../../raw_ops/unstage"><code translate="no" dir="ltr">Unstage(...)</code></a>: Op is similar to a lightweight Dequeue.</p> <p><a href="../../raw_ops/unwrapdatasetvariant"><code translate="no" dir="ltr">UnwrapDatasetVariant(...)</code></a></p> <p><a href="../../raw_ops/upperbound"><code translate="no" dir="ltr">UpperBound(...)</code></a>: Applies upper_bound(sorted_search_values, values) along each row.</p> <p><a href="../../raw_ops/varhandleop"><code translate="no" dir="ltr">VarHandleOp(...)</code></a>: Creates a handle to a Variable resource.</p> <p><a href="../../raw_ops/varisinitializedop"><code translate="no" dir="ltr">VarIsInitializedOp(...)</code></a>: Checks whether a resource handle-based variable has been initialized.</p> <p><a href="../../raw_ops/variable"><code translate="no" dir="ltr">Variable(...)</code></a>: Use VariableV2 instead.</p> <p><a href="../../raw_ops/variableshape"><code translate="no" dir="ltr">VariableShape(...)</code></a>: Returns the shape of the variable pointed to by <code translate="no" dir="ltr">resource</code>.</p> <p><a href="../../raw_ops/variablev2"><code translate="no" dir="ltr">VariableV2(...)</code></a>: Holds state in the form of a tensor that persists across steps.</p> <p><a href="../../raw_ops/where"><code translate="no" dir="ltr">Where(...)</code></a>: Returns locations of nonzero / true values in a tensor.</p> <p><a href="../../raw_ops/while"><code translate="no" dir="ltr">While(...)</code></a>: output = input; While (Cond(output)) { output = Body(output) }</p> <p><a href="../../raw_ops/wholefilereader"><code translate="no" dir="ltr">WholeFileReader(...)</code></a>: A Reader that outputs the entire contents of a file as a value.</p> <p><a href="../../raw_ops/wholefilereaderv2"><code translate="no" dir="ltr">WholeFileReaderV2(...)</code></a>: A Reader that outputs the entire contents of a file as a value.</p> <p><a href="../../raw_ops/windowdataset"><code translate="no" dir="ltr">WindowDataset(...)</code></a>: Combines (nests of) input elements into a dataset of (nests of) windows.</p> <p><a href="../../raw_ops/workerheartbeat"><code translate="no" dir="ltr">WorkerHeartbeat(...)</code></a>: Worker heartbeat op.</p> <p><a href="../../raw_ops/wrapdatasetvariant"><code translate="no" dir="ltr">WrapDatasetVariant(...)</code></a></p> <p><a href="../../raw_ops/writeaudiosummary"><code translate="no" dir="ltr">WriteAudioSummary(...)</code></a>: Writes an audio summary.</p> <p><a href="../../raw_ops/writefile"><code translate="no" dir="ltr">WriteFile(...)</code></a>: Writes contents to the file at input filename. Creates file and recursively</p> <p><a href="../../raw_ops/writegraphsummary"><code translate="no" dir="ltr">WriteGraphSummary(...)</code></a>: Writes a graph summary.</p> <p><a href="../../raw_ops/writehistogramsummary"><code translate="no" dir="ltr">WriteHistogramSummary(...)</code></a>: Writes a histogram summary.</p> <p><a href="../../raw_ops/writeimagesummary"><code translate="no" dir="ltr">WriteImageSummary(...)</code></a>: Writes an image summary.</p> <p><a href="../../raw_ops/writerawprotosummary"><code translate="no" dir="ltr">WriteRawProtoSummary(...)</code></a>: Writes a serialized proto summary.</p> <p><a href="../../raw_ops/writescalarsummary"><code translate="no" dir="ltr">WriteScalarSummary(...)</code></a>: Writes a scalar summary.</p> <p><a href="../../raw_ops/writesummary"><code translate="no" dir="ltr">WriteSummary(...)</code></a>: Writes a tensor summary.</p> <p><a href="../../raw_ops/xdivy"><code translate="no" dir="ltr">Xdivy(...)</code></a>: Returns 0 if x == 0, and x / y otherwise, elementwise.</p> <p><a href="../../raw_ops/xlog1py"><code translate="no" dir="ltr">Xlog1py(...)</code></a>: Returns 0 if x == 0, and x * log1p(y) otherwise, elementwise.</p> <p><a href="../../raw_ops/xlogy"><code translate="no" dir="ltr">Xlogy(...)</code></a>: Returns 0 if x == 0, and x * log(y) otherwise, elementwise.</p> <p><a href="../../raw_ops/zeroslike"><code translate="no" dir="ltr">ZerosLike(...)</code></a>: Returns a tensor of zeros with the same shape and type as x.</p> <p><a href="../../raw_ops/zeta"><code translate="no" dir="ltr">Zeta(...)</code></a>: Compute the Hurwitz zeta function \(\zeta(x, q)\).</p> <p><a href="../../raw_ops/zipdataset"><code translate="no" dir="ltr">ZipDataset(...)</code></a>: Creates a dataset that zips together <code translate="no" dir="ltr">input_datasets</code>.</p>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/compat/v1/raw_ops" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/compat/v1/raw_ops</a>
  </p>
</div>
