<h1 class="devsite-page-title">tf.compat.v1.train.import_meta_graph</h1>       <p>Recreates a Graph saved in a <code translate="no" dir="ltr">MetaGraphDef</code> proto.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.compat.v1.train.import_meta_graph(
    meta_graph_or_file, clear_devices=False, import_scope=None, **kwargs
)
</pre>  <p>This function takes a <code translate="no" dir="ltr">MetaGraphDef</code> protocol buffer as input. If the argument is a file containing a <code translate="no" dir="ltr">MetaGraphDef</code> protocol buffer , it constructs a protocol buffer from the file content. The function then adds all the nodes from the <code translate="no" dir="ltr">graph_def</code> field to the current graph, recreates all the collections, and returns a saver constructed from the <code translate="no" dir="ltr">saver_def</code> field.</p> <p>In combination with <code translate="no" dir="ltr">export_meta_graph()</code>, this function can be used to</p> <ul> <li><p>Serialize a graph along with other Python objects such as <code translate="no" dir="ltr">QueueRunner</code>, <code translate="no" dir="ltr">Variable</code> into a <code translate="no" dir="ltr">MetaGraphDef</code>.</p></li> <li><p>Restart training from a saved graph and checkpoints.</p></li> <li><p>Run inference from a saved graph and checkpoints.</p></li> </ul> <pre class="prettyprint lang-Python" translate="no" dir="ltr" data-language="python">...
# Create a saver.
saver = tf.compat.v1.train.Saver(...variables...)
# Remember the training_op we want to run by adding it to a collection.
tf.compat.v1.add_to_collection('train_op', train_op)
sess = tf.compat.v1.Session()
for step in xrange(1000000):
    sess.run(train_op)
    if step % 1000 == 0:
        # Saves checkpoint, which by default also exports a meta_graph
        # named 'my-model-global_step.meta'.
        saver.save(sess, 'my-model', global_step=step)
</pre> <p>Later we can continue training from this saved <code translate="no" dir="ltr">meta_graph</code> without building the model from scratch.</p> <pre class="prettyprint lang-Python" translate="no" dir="ltr" data-language="python">with tf.Session() as sess:
  new_saver =
  tf.train.import_meta_graph('my-save-dir/my-model-10000.meta')
  new_saver.restore(sess, 'my-save-dir/my-model-10000')
  # tf.get_collection() returns a list. In this example we only want
  # the first one.
  train_op = tf.get_collection('train_op')[0]
  for step in xrange(1000000):
    sess.run(train_op)
</pre>
<blockquote class="note">
<strong>Note:</strong><span> Restarting training from saved <code translate="no" dir="ltr">meta_graph</code> only works if the device assignments have not changed.</span>
</blockquote> <h4 id="example" data-text="Example:">Example:</h4> <p>Variables, placeholders, and independent operations can also be stored, as shown in the following example.</p> <pre class="prettyprint lang-Python" translate="no" dir="ltr" data-language="python"># Saving contents and operations.
v1 = tf.placeholder(tf.float32, name="v1")
v2 = tf.placeholder(tf.float32, name="v2")
v3 = tf.math.multiply(v1, v2)
vx = tf.Variable(10.0, name="vx")
v4 = tf.add(v3, vx, name="v4")
saver = tf.train.Saver([vx])
sess = tf.Session()
sess.run(tf.global_variables_initializer())
sess.run(vx.assign(tf.add(vx, vx)))
result = sess.run(v4, feed_dict={v1:12.0, v2:3.3})
print(result)
saver.save(sess, "./model_ex1")
</pre> <p>Later this model can be restored and contents loaded.</p> <pre class="prettyprint lang-Python" translate="no" dir="ltr" data-language="python"># Restoring variables and running operations.
saver = tf.train.import_meta_graph("./model_ex1.meta")
sess = tf.Session()
saver.restore(sess, "./model_ex1")
result = sess.run("v4:0", feed_dict={"v1:0": 12.0, "v2:0": 3.3})
print(result)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">meta_graph_or_file</code> </td> <td> <code translate="no" dir="ltr">MetaGraphDef</code> protocol buffer or filename (including the path) containing a <code translate="no" dir="ltr">MetaGraphDef</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">clear_devices</code> </td> <td> Whether or not to clear the device field for an <code translate="no" dir="ltr">Operation</code> or <code translate="no" dir="ltr">Tensor</code> during import. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">import_scope</code> </td> <td> Optional <code translate="no" dir="ltr">string</code>. Name scope to add. Only used when initializing from protocol buffer. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">**kwargs</code> </td> <td> Optional keyed arguments. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A saver constructed from <code translate="no" dir="ltr">saver_def</code> in <code translate="no" dir="ltr">MetaGraphDef</code> or None. <p>A None value is returned if no variables exist in the <code translate="no" dir="ltr">MetaGraphDef</code> (i.e., there are no variables to restore). </p>
</td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">RuntimeError</code> </td> <td> If called with eager execution enabled. </td> </tr> </table> <h4 id="eager_compatibility" data-text="Eager Compatibility">Eager Compatibility</h4> <p>Exporting/importing meta graphs is not supported. No graph exists when eager execution is enabled.</p>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/compat/v1/train/import_meta_graph" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/compat/v1/train/import_meta_graph</a>
  </p>
</div>
