<h1 class="devsite-page-title">Module: tf.compat.v1.losses</h1>       <p>Loss operations for use in neural networks.</p> <blockquote class="note">
<strong>Note:</strong><span> All the losses are added to the <code translate="no" dir="ltr">GraphKeys.LOSSES</code> collection by default.</span>
</blockquote> <h2 id="classes" data-text="Classes">Classes</h2> <p><a href="losses/reduction"><code translate="no" dir="ltr">class Reduction</code></a>: Types of loss reduction.</p> <h2 id="functions" data-text="Functions">Functions</h2> <p><a href="losses/absolute_difference"><code translate="no" dir="ltr">absolute_difference(...)</code></a>: Adds an Absolute Difference loss to the training procedure.</p> <p><a href="losses/add_loss"><code translate="no" dir="ltr">add_loss(...)</code></a>: Adds a externally defined loss to the collection of losses.</p> <p><a href="losses/compute_weighted_loss"><code translate="no" dir="ltr">compute_weighted_loss(...)</code></a>: Computes the weighted loss.</p> <p><a href="losses/cosine_distance"><code translate="no" dir="ltr">cosine_distance(...)</code></a>: Adds a cosine-distance loss to the training procedure. (deprecated arguments)</p> <p><a href="losses/get_losses"><code translate="no" dir="ltr">get_losses(...)</code></a>: Gets the list of losses from the loss_collection.</p> <p><a href="losses/get_regularization_loss"><code translate="no" dir="ltr">get_regularization_loss(...)</code></a>: Gets the total regularization loss.</p> <p><a href="losses/get_regularization_losses"><code translate="no" dir="ltr">get_regularization_losses(...)</code></a>: Gets the list of regularization losses.</p> <p><a href="losses/get_total_loss"><code translate="no" dir="ltr">get_total_loss(...)</code></a>: Returns a tensor whose value represents the total loss.</p> <p><a href="losses/hinge_loss"><code translate="no" dir="ltr">hinge_loss(...)</code></a>: Adds a hinge loss to the training procedure.</p> <p><a href="losses/huber_loss"><code translate="no" dir="ltr">huber_loss(...)</code></a>: Adds a <a href="https://en.wikipedia.org/wiki/Huber_loss">Huber Loss</a> term to the training procedure.</p> <p><a href="losses/log_loss"><code translate="no" dir="ltr">log_loss(...)</code></a>: Adds a Log Loss term to the training procedure.</p> <p><a href="losses/mean_pairwise_squared_error"><code translate="no" dir="ltr">mean_pairwise_squared_error(...)</code></a>: Adds a pairwise-errors-squared loss to the training procedure.</p> <p><a href="losses/mean_squared_error"><code translate="no" dir="ltr">mean_squared_error(...)</code></a>: Adds a Sum-of-Squares loss to the training procedure.</p> <p><a href="losses/sigmoid_cross_entropy"><code translate="no" dir="ltr">sigmoid_cross_entropy(...)</code></a>: Creates a cross-entropy loss using tf.nn.sigmoid_cross_entropy_with_logits.</p> <p><a href="losses/softmax_cross_entropy"><code translate="no" dir="ltr">softmax_cross_entropy(...)</code></a>: Creates a cross-entropy loss using tf.nn.softmax_cross_entropy_with_logits_v2.</p> <p><a href="losses/sparse_softmax_cross_entropy"><code translate="no" dir="ltr">sparse_softmax_cross_entropy(...)</code></a>: Cross-entropy loss using <a href="../../nn/sparse_softmax_cross_entropy_with_logits"><code translate="no" dir="ltr">tf.nn.sparse_softmax_cross_entropy_with_logits</code></a>.</p>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/compat/v1/losses" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/compat/v1/losses</a>
  </p>
</div>
