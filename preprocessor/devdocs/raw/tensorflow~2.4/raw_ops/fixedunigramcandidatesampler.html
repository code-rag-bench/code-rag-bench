<h1 class="devsite-page-title">tf.raw_ops.FixedUnigramCandidateSampler</h1>       <p>Generates labels for candidate sampling with a learned unigram distribution.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/raw_ops/FixedUnigramCandidateSampler"><code translate="no" dir="ltr">tf.compat.v1.raw_ops.FixedUnigramCandidateSampler</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.raw_ops.FixedUnigramCandidateSampler(
    true_classes, num_true, num_sampled, unique, range_max, vocab_file='',
    distortion=1, num_reserved_ids=0, num_shards=1, shard=0, unigrams=[], seed=0,
    seed2=0, name=None
)
</pre>  <p>A unigram sampler could use a fixed unigram distribution read from a file or passed in as an in-memory array instead of building up the distribution from data on the fly. There is also an option to skew the distribution by applying a distortion power to the weights.</p> <p>The vocabulary file should be in CSV-like format, with the last field being the weight associated with the word.</p> <p>For each batch, this op picks a single set of sampled candidate labels.</p> <p>The advantages of sampling candidates per-batch are simplicity and the possibility of efficient dense matrix multiplication. The disadvantage is that the sampled candidates must be chosen independently of the context and of the true labels.</p>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">true_classes</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">int64</code>. A batch_size * num_true matrix, in which each row contains the IDs of the num_true target_classes in the corresponding original label. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_true</code> </td> <td> An <code translate="no" dir="ltr">int</code> that is <code translate="no" dir="ltr">&gt;= 1</code>. Number of true labels per context. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_sampled</code> </td> <td> An <code translate="no" dir="ltr">int</code> that is <code translate="no" dir="ltr">&gt;= 1</code>. Number of candidates to randomly sample. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">unique</code> </td> <td> A <code translate="no" dir="ltr">bool</code>. If unique is true, we sample with rejection, so that all sampled candidates in a batch are unique. This requires some approximation to estimate the post-rejection sampling probabilities. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">range_max</code> </td> <td> An <code translate="no" dir="ltr">int</code> that is <code translate="no" dir="ltr">&gt;= 1</code>. The sampler will sample integers from the interval [0, range_max). </td> </tr>
<tr> <td> <code translate="no" dir="ltr">vocab_file</code> </td> <td> An optional <code translate="no" dir="ltr">string</code>. Defaults to <code translate="no" dir="ltr">""</code>. Each valid line in this file (which should have a CSV-like format) corresponds to a valid word ID. IDs are in sequential order, starting from num_reserved_ids. The last entry in each line is expected to be a value corresponding to the count or relative probability. Exactly one of vocab_file and unigrams needs to be passed to this op. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">distortion</code> </td> <td> An optional <code translate="no" dir="ltr">float</code>. Defaults to <code translate="no" dir="ltr">1</code>. The distortion is used to skew the unigram probability distribution. Each weight is first raised to the distortion's power before adding to the internal unigram distribution. As a result, distortion = 1.0 gives regular unigram sampling (as defined by the vocab file), and distortion = 0.0 gives a uniform distribution. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_reserved_ids</code> </td> <td> An optional <code translate="no" dir="ltr">int</code>. Defaults to <code translate="no" dir="ltr">0</code>. Optionally some reserved IDs can be added in the range [0, ..., num_reserved_ids) by the users. One use case is that a special unknown word token is used as ID 0. These IDs will have a sampling probability of 0. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">num_shards</code> </td> <td> An optional <code translate="no" dir="ltr">int</code> that is <code translate="no" dir="ltr">&gt;= 1</code>. Defaults to <code translate="no" dir="ltr">1</code>. A sampler can be used to sample from a subset of the original range in order to speed up the whole computation through parallelism. This parameter (together with 'shard') indicates the number of partitions that are being used in the overall computation. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">shard</code> </td> <td> An optional <code translate="no" dir="ltr">int</code> that is <code translate="no" dir="ltr">&gt;= 0</code>. Defaults to <code translate="no" dir="ltr">0</code>. A sampler can be used to sample from a subset of the original range in order to speed up the whole computation through parallelism. This parameter (together with 'num_shards') indicates the particular partition number of a sampler op, when partitioning is being used. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">unigrams</code> </td> <td> An optional list of <code translate="no" dir="ltr">floats</code>. Defaults to <code translate="no" dir="ltr">[]</code>. A list of unigram counts or probabilities, one per ID in sequential order. Exactly one of vocab_file and unigrams should be passed to this op. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">seed</code> </td> <td> An optional <code translate="no" dir="ltr">int</code>. Defaults to <code translate="no" dir="ltr">0</code>. If either seed or seed2 are set to be non-zero, the random number generator is seeded by the given seed. Otherwise, it is seeded by a random seed. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">seed2</code> </td> <td> An optional <code translate="no" dir="ltr">int</code>. Defaults to <code translate="no" dir="ltr">0</code>. An second seed to avoid seed collision. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A tuple of <code translate="no" dir="ltr">Tensor</code> objects (sampled_candidates, true_expected_count, sampled_expected_count). </td> </tr> <tr> <td> <code translate="no" dir="ltr">sampled_candidates</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">int64</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">true_expected_count</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">sampled_expected_count</code> </td> <td> A <code translate="no" dir="ltr">Tensor</code> of type <code translate="no" dir="ltr">float32</code>. </td> </tr> </table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/raw_ops/FixedUnigramCandidateSampler" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/raw_ops/FixedUnigramCandidateSampler</a>
  </p>
</div>
