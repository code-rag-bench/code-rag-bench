<h1 class="devsite-page-title">tf.random.stateless_gamma</h1>       <p>Outputs deterministic pseudorandom values from a gamma distribution.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/random/stateless_gamma"><code translate="no" dir="ltr">tf.compat.v1.random.stateless_gamma</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.random.stateless_gamma(
    shape, seed, alpha, beta=None, dtype=tf.dtypes.float32, name=None
)
</pre>  <p>The generated values follow a gamma distribution with specified concentration (<code translate="no" dir="ltr">alpha</code>) and inverse scale (<code translate="no" dir="ltr">beta</code>) parameters.</p> <p>This is a stateless version of <a href="gamma"><code translate="no" dir="ltr">tf.random.gamma</code></a>: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.</p> <p>A slight difference exists in the interpretation of the <code translate="no" dir="ltr">shape</code> parameter between <code translate="no" dir="ltr">stateless_gamma</code> and <code translate="no" dir="ltr">gamma</code>: in <code translate="no" dir="ltr">gamma</code>, the <code translate="no" dir="ltr">shape</code> is always prepended to the shape of the broadcast of <code translate="no" dir="ltr">alpha</code> with <code translate="no" dir="ltr">beta</code>; whereas in <code translate="no" dir="ltr">stateless_gamma</code> the <code translate="no" dir="ltr">shape</code> parameter must always encompass the shapes of each of <code translate="no" dir="ltr">alpha</code> and <code translate="no" dir="ltr">beta</code> (which must broadcast together to match the trailing dimensions of <code translate="no" dir="ltr">shape</code>).</p> <blockquote class="note">
<strong>Note:</strong><span> Because internal calculations are done using <code translate="no" dir="ltr">float64</code> and casting has <code translate="no" dir="ltr">floor</code> semantics, we must manually map zero outcomes to the smallest possible positive floating-point value, i.e., <code translate="no" dir="ltr">np.finfo(dtype).tiny</code>. This means that <code translate="no" dir="ltr">np.finfo(dtype).tiny</code> occurs more frequently than it otherwise should. This bias can only happen for small values of <code translate="no" dir="ltr">alpha</code>, i.e., <code translate="no" dir="ltr">alpha &lt;&lt; 1</code> or large values of <code translate="no" dir="ltr">beta</code>, i.e., <code translate="no" dir="ltr">beta &gt;&gt; 1</code>.</span>
</blockquote> <p>The samples are differentiable w.r.t. alpha and beta. The derivatives are computed using the approach described in (Figurnov et al., 2018).</p> <h4 id="example" data-text="Example:">Example:</h4> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">samples = tf.random.stateless_gamma([10, 2], seed=[12, 34], alpha=[0.5, 1.5])
# samples has shape [10, 2], where each slice [:, 0] and [:, 1] represents
# the samples drawn from each distribution

samples = tf.random.stateless_gamma([7, 5, 2], seed=[12, 34], alpha=[.5, 1.5])
# samples has shape [7, 5, 2], where each slice [:, :, 0] and [:, :, 1]
# represents the 7x5 samples drawn from each of the two distributions

alpha = tf.constant([[1.], [3.], [5.]])
beta = tf.constant([[3., 4.]])
samples = tf.random.stateless_gamma(
    [30, 3, 2], seed=[12, 34], alpha=alpha, beta=beta)
# samples has shape [30, 3, 2], with 30 samples each of 3x2 distributions.

with tf.GradientTape() as tape:
  tape.watch([alpha, beta])
  loss = tf.reduce_mean(tf.square(tf.random.stateless_gamma(
      [30, 3, 2], seed=[12, 34], alpha=alpha, beta=beta)))
dloss_dalpha, dloss_dbeta = tape.gradient(loss, [alpha, beta])
# unbiased stochastic derivatives of the loss function
alpha.shape == dloss_dalpha.shape  # True
beta.shape == dloss_dbeta.shape  # True
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">shape</code> </td> <td> A 1-D integer Tensor or Python array. The shape of the output tensor. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">seed</code> </td> <td> A shape [2] Tensor, the seed to the random number generator. Must have dtype <code translate="no" dir="ltr">int32</code> or <code translate="no" dir="ltr">int64</code>. (When using XLA, only <code translate="no" dir="ltr">int32</code> is allowed.) </td> </tr>
<tr> <td> <code translate="no" dir="ltr">alpha</code> </td> <td> Tensor. The concentration parameter of the gamma distribution. Must be broadcastable with <code translate="no" dir="ltr">beta</code>, and broadcastable with the rightmost dimensions of <code translate="no" dir="ltr">shape</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">beta</code> </td> <td> Tensor. The inverse scale parameter of the gamma distribution. Must be broadcastable with <code translate="no" dir="ltr">alpha</code> and broadcastable with the rightmost dimensions of <code translate="no" dir="ltr">shape</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> Floating point dtype of <code translate="no" dir="ltr">alpha</code>, <code translate="no" dir="ltr">beta</code>, and the output. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> A name for the operation (optional). </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> 
<tr> <td> <code translate="no" dir="ltr">samples</code> </td> <td> A Tensor of the specified shape filled with random gamma values. For each i, each `samples[..., i] is an independent draw from the gamma distribution with concentration alpha[i] and scale beta[i]. </td> </tr> </table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/random/stateless_gamma" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/random/stateless_gamma</a>
  </p>
</div>
