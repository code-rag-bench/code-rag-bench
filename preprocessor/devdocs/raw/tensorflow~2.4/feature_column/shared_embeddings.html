<h1 class="devsite-page-title">tf.feature_column.shared_embeddings</h1>       <p>List of dense columns that convert from sparse, categorical input.</p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.feature_column.shared_embeddings(
    categorical_columns, dimension, combiner='mean', initializer=None,
    shared_embedding_collection_name=None, ckpt_to_load_from=None,
    tensor_name_in_ckpt=None, max_norm=None, trainable=True,
    use_safe_embedding_lookup=True
)
</pre>  <p>This is similar to <code translate="no" dir="ltr">embedding_column</code>, except that it produces a list of embedding columns that share the same embedding weights.</p> <p>Use this when your inputs are sparse and of the same type (e.g. watched and impression video IDs that share the same vocabulary), and you want to convert them to a dense representation (e.g., to feed to a DNN).</p> <p>Inputs must be a list of categorical columns created by any of the <code translate="no" dir="ltr">categorical_column_*</code> function. They must all be of the same type and have the same arguments except <code translate="no" dir="ltr">key</code>. E.g. they can be categorical_column_with_vocabulary_file with the same vocabulary_file. Some or all columns could also be weighted_categorical_column.</p> <p>Here is an example embedding of two features for a DNNClassifier model:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">watched_video_id = categorical_column_with_vocabulary_file(
    'watched_video_id', video_vocabulary_file, video_vocabulary_size)
impression_video_id = categorical_column_with_vocabulary_file(
    'impression_video_id', video_vocabulary_file, video_vocabulary_size)
columns = shared_embedding_columns(
    [watched_video_id, impression_video_id], dimension=10)

estimator = tf.estimator.DNNClassifier(feature_columns=columns, ...)

label_column = ...
def input_fn():
  features = tf.io.parse_example(
      ..., features=make_parse_example_spec(columns + [label_column]))
  labels = features.pop(label_column.name)
  return features, labels

estimator.train(input_fn=input_fn, steps=100)
</pre> <p>Here is an example using <code translate="no" dir="ltr">shared_embedding_columns</code> with model_fn:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">def model_fn(features, ...):
  watched_video_id = categorical_column_with_vocabulary_file(
      'watched_video_id', video_vocabulary_file, video_vocabulary_size)
  impression_video_id = categorical_column_with_vocabulary_file(
      'impression_video_id', video_vocabulary_file, video_vocabulary_size)
  columns = shared_embedding_columns(
      [watched_video_id, impression_video_id], dimension=10)
  dense_tensor = input_layer(features, columns)
  # Form DNN layers, calculate loss, and return EstimatorSpec.
  ...
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">categorical_columns</code> </td> <td> List of categorical columns created by a <code translate="no" dir="ltr">categorical_column_with_*</code> function. These columns produce the sparse IDs that are inputs to the embedding lookup. All columns must be of the same type and have the same arguments except <code translate="no" dir="ltr">key</code>. E.g. they can be categorical_column_with_vocabulary_file with the same vocabulary_file. Some or all columns could also be weighted_categorical_column. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dimension</code> </td> <td> An integer specifying dimension of the embedding, must be &gt; 0. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">combiner</code> </td> <td> A string specifying how to reduce if there are multiple entries in a single row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default. 'sqrtn' often achieves good accuracy, in particular with bag-of-words columns. Each of this can be thought as example level normalizations on the column. For more information, see <code translate="no" dir="ltr">tf.embedding_lookup_sparse</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">initializer</code> </td> <td> A variable initializer function to be used in embedding variable initialization. If not specified, defaults to <code translate="no" dir="ltr">truncated_normal_initializer</code> with mean <code translate="no" dir="ltr">0.0</code> and standard deviation <code translate="no" dir="ltr">1/sqrt(dimension)</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">shared_embedding_collection_name</code> </td> <td> Optional collective name of these columns. If not given, a reasonable name will be chosen based on the names of <code translate="no" dir="ltr">categorical_columns</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ckpt_to_load_from</code> </td> <td> String representing checkpoint name/pattern from which to restore column weights. Required if <code translate="no" dir="ltr">tensor_name_in_ckpt</code> is not <code translate="no" dir="ltr">None</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">tensor_name_in_ckpt</code> </td> <td> Name of the <code translate="no" dir="ltr">Tensor</code> in <code translate="no" dir="ltr">ckpt_to_load_from</code> from which to restore the column weights. Required if <code translate="no" dir="ltr">ckpt_to_load_from</code> is not <code translate="no" dir="ltr">None</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_norm</code> </td> <td> If not <code translate="no" dir="ltr">None</code>, each embedding is clipped if its l2-norm is larger than this value, before combining. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">trainable</code> </td> <td> Whether or not the embedding is trainable. Default is True. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">use_safe_embedding_lookup</code> </td> <td> If true, uses safe_embedding_lookup_sparse instead of embedding_lookup_sparse. safe_embedding_lookup_sparse ensures there are no empty rows and all weights and ids are positive at the expense of extra compute cost. This only applies to rank 2 (NxM) shaped input tensors. Defaults to true, consider turning off if the above checks are not needed. Note that having empty rows will not trigger any error though the output result might be 0 or omitted. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A list of dense columns that converts from sparse input. The order of results follows the ordering of <code translate="no" dir="ltr">categorical_columns</code>. </td> </tr> 
</table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Raises</th></tr> 
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if <code translate="no" dir="ltr">dimension</code> not &gt; 0. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if any of the given <code translate="no" dir="ltr">categorical_columns</code> is of different type or has different arguments than the others. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if exactly one of <code translate="no" dir="ltr">ckpt_to_load_from</code> and <code translate="no" dir="ltr">tensor_name_in_ckpt</code> is specified. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">ValueError</code> </td> <td> if <code translate="no" dir="ltr">initializer</code> is specified and is not callable. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">RuntimeError</code> </td> <td> if eager execution is enabled. </td> </tr> </table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/feature_column/shared_embeddings" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/feature_column/shared_embeddings</a>
  </p>
</div>
