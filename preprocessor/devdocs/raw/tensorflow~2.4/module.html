<h1 class="devsite-page-title">tf.Module</h1>      <table class="tfo-notebook-buttons tfo-api nocontent" align="left">  <td> <a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/module/module.py#L35-L302">  View source on GitHub </a> </td> </table> <p>Base neural network module class.</p> <section class="expandable"> <h4 class="showalways" id="view-aliases" data-text="View aliases">View aliases</h4> <p> <b>Compat aliases for migration</b> </p>
<p>See <a href="https://www.tensorflow.org/guide/migrate">Migration guide</a> for more details.</p> <p><a href="https://www.tensorflow.org/api_docs/python/tf/Module"><code translate="no" dir="ltr">tf.compat.v1.Module</code></a></p> </section> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.Module(
    name=None
)
</pre>  <p>A module is a named container for <a href="variable"><code translate="no" dir="ltr">tf.Variable</code></a>s, other <a href="module"><code translate="no" dir="ltr">tf.Module</code></a>s and functions which apply to user input. For example a dense layer in a neural network might be implemented as a <a href="module"><code translate="no" dir="ltr">tf.Module</code></a>:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
class Dense(tf.Module):
  def __init__(self, input_dim, output_size, name=None):
    super(Dense, self).__init__(name=name)
    self.w = tf.Variable(
      tf.random.normal([input_dim, output_size]), name='w')
    self.b = tf.Variable(tf.zeros([output_size]), name='b')
  def __call__(self, x):
    y = tf.matmul(x, self.w) + self.b
    return tf.nn.relu(y)
</pre> <p>You can use the Dense layer as you would expect:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
d = Dense(input_dim=3, output_size=2)
d(tf.ones([1, 3]))
&lt;tf.Tensor: shape=(1, 2), dtype=float32, numpy=..., dtype=float32)&gt;
</pre> <p>By subclassing <a href="module"><code translate="no" dir="ltr">tf.Module</code></a> instead of <code translate="no" dir="ltr">object</code> any <a href="variable"><code translate="no" dir="ltr">tf.Variable</code></a> or <a href="module"><code translate="no" dir="ltr">tf.Module</code></a> instances assigned to object properties can be collected using the <code translate="no" dir="ltr">variables</code>, <code translate="no" dir="ltr">trainable_variables</code> or <code translate="no" dir="ltr">submodules</code> property:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
d.variables
    (&lt;tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=...,
    dtype=float32)&gt;,
    &lt;tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=..., dtype=float32)&gt;)
</pre> <p>Subclasses of <a href="module"><code translate="no" dir="ltr">tf.Module</code></a> can also take advantage of the <code translate="no" dir="ltr">_flatten</code> method which can be used to implement tracking of any other types.</p> <p>All <a href="module"><code translate="no" dir="ltr">tf.Module</code></a> classes have an associated <a href="name_scope"><code translate="no" dir="ltr">tf.name_scope</code></a> which can be used to group operations in TensorBoard and create hierarchies for variable names which can help with debugging. We suggest using the name scope when creating nested submodules/parameters or for forward methods whose graph you might want to inspect in TensorBoard. You can enter the name scope explicitly using <code translate="no" dir="ltr">with self.name_scope:</code> or you can annotate methods (apart from <code translate="no" dir="ltr">__init__</code>) with <code translate="no" dir="ltr">@tf.Module.with_name_scope</code>.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
class MLP(tf.Module):
  def __init__(self, input_size, sizes, name=None):
    super(MLP, self).__init__(name=name)
    self.layers = []
    with self.name_scope:
      for size in sizes:
        self.layers.append(Dense(input_dim=input_size, output_size=size))
        input_size = size
  @tf.Module.with_name_scope
  def __call__(self, x):
    for layer in self.layers:
      x = layer(x)
    return x
</pre> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
module = MLP(input_size=5, sizes=[5, 5])
module.variables
(&lt;tf.Variable 'mlp/b:0' shape=(5,) dtype=float32, numpy=..., dtype=float32)&gt;,
&lt;tf.Variable 'mlp/w:0' shape=(5, 5) dtype=float32, numpy=...,
   dtype=float32)&gt;,
&lt;tf.Variable 'mlp/b:0' shape=(5,) dtype=float32, numpy=..., dtype=float32)&gt;,
&lt;tf.Variable 'mlp/w:0' shape=(5, 5) dtype=float32, numpy=...,
   dtype=float32)&gt;)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Attributes</th></tr> 
<tr> <td> <code translate="no" dir="ltr">name</code> </td> <td> Returns the name of this module as passed or determined in the ctor. <blockquote class="note">
<strong>Note:</strong><span> This is not the same as the <code translate="no" dir="ltr">self.name_scope.name</code> which includes parent module names. </span>
</blockquote>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">name_scope</code> </td> <td> Returns a <a href="name_scope"><code translate="no" dir="ltr">tf.name_scope</code></a> instance for this class. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">submodules</code> </td> <td> Sequence of all sub-modules. <p>Submodules are modules which are properties of this module, or found as properties of modules which are properties of this module (and so on).</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
a = tf.Module()
b = tf.Module()
c = tf.Module()
a.b = b
b.c = c
list(a.submodules) == [b, c]
True
list(b.submodules) == [c]
True
list(c.submodules) == []
True
</pre> 
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">trainable_variables</code> </td> <td> Sequence of trainable variables owned by this module and its submodules. <blockquote class="note">
<strong>Note:</strong><span> this method uses reflection to find variables on the current instance and submodules. For performance reasons you may wish to cache the result of calling this method if you don't expect the return value to change. </span>
</blockquote>
</td> </tr>
<tr> <td> <code translate="no" dir="ltr">variables</code> </td> <td> Sequence of variables owned by this module and its submodules.<blockquote class="note">
<strong>Note:</strong><span> this method uses reflection to find variables on the current instance and submodules. For performance reasons you may wish to cache the result of calling this method if you don't expect the return value to change. </span>
</blockquote>
</td> </tr> </table> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="with_name_scope" data-text="with_name_scope"><code translate="no" dir="ltr">with_name_scope</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/module/module.py#L271-L302">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
@classmethod
with_name_scope(
    method
)
</pre> <p>Decorator to automatically enter the module name scope.</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
class MyModule(tf.Module):
  @tf.Module.with_name_scope
  def __call__(self, x):
    if not hasattr(self, 'w'):
      self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))
    return tf.matmul(x, self.w)
</pre> <p>Using the above module would produce <a href="variable"><code translate="no" dir="ltr">tf.Variable</code></a>s and <a href="tensor"><code translate="no" dir="ltr">tf.Tensor</code></a>s whose names included the module name:</p> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
mod = MyModule()
mod(tf.ones([1, 2]))
&lt;tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)&gt;
mod.w
&lt;tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,
numpy=..., dtype=float32)&gt;
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">method</code> </td> <td> The method to wrap. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> The original method wrapped such that it enters the module's name scope. </td> </tr> 
</table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/Module" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/Module</a>
  </p>
</div>
