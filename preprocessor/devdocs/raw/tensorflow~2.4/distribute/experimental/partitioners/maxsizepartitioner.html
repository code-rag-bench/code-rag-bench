<h1 class="devsite-page-title">tf.distribute.experimental.partitioners.MaxSizePartitioner</h1>       <p>Partitioner that keeps shards below <code translate="no" dir="ltr">max_shard_bytes</code>.</p> <p>Inherits From: <a href="partitioner"><code translate="no" dir="ltr">Partitioner</code></a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
tf.distribute.experimental.partitioners.MaxSizePartitioner(
    max_shard_bytes, max_shards=None, bytes_per_string=16
)
</pre>  <p>This partitioner ensures each shard has at most <code translate="no" dir="ltr">max_shard_bytes</code>, and tries to allocate as few shards as possible, i.e., keeping shard size as large as possible.</p> <p>If the partitioner hits the <code translate="no" dir="ltr">max_shards</code> limit, then each shard may end up larger than <code translate="no" dir="ltr">max_shard_bytes</code>. By default <code translate="no" dir="ltr">max_shards</code> equals <code translate="no" dir="ltr">None</code> and no limit on the number of shards is enforced.</p> <h4 id="examples" data-text="Examples:">Examples:</h4> <pre class="devsite-click-to-copy prettyprint lang-py" translate="no" dir="ltr" data-language="cpp">
partitioner = MaxSizePartitioner(max_shard_bytes=4)
partitions = partitioner(tf.TensorShape([6, 1]), tf.float32)
[6, 1]
partitioner = MaxSizePartitioner(max_shard_bytes=4, max_shards=2)
partitions = partitioner(tf.TensorShape([6, 1]), tf.float32)
[2, 1]
partitioner = MaxSizePartitioner(max_shard_bytes=1024)
partitions = partitioner(tf.TensorShape([6, 1]), tf.float32)
[1, 1]

# use in ParameterServerStrategy
# strategy = tf.distribute.experimental.ParameterServerStrategy(
#   cluster_resolver=cluster_resolver, variable_partitioner=partitioner)
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">max_shard_bytes</code> </td> <td> The maximum size any given shard is allowed to be. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">max_shards</code> </td> <td> The maximum number of shards in <code translate="no" dir="ltr">int</code> created taking precedence over <code translate="no" dir="ltr">max_shard_bytes</code>. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">bytes_per_string</code> </td> <td> If the partition value is of type string, this provides an estimate of how large each string is. </td> </tr> </table> <h2 id="methods" data-text="Methods">Methods</h2> <h3 id="__call__" data-text="__call__"><code translate="no" dir="ltr">__call__</code></h3> <p><a target="_blank" href="https://github.com/tensorflow/tensorflow/blob/v2.4.0/tensorflow/python/distribute/sharded_variable.py#L214-L219">View source</a></p> <pre class="devsite-click-to-copy prettyprint lang-py tfo-signature-link" translate="no" dir="ltr" data-language="cpp">
__call__(
    shape, dtype, axis=0
)
</pre> <p>Partitions the given <code translate="no" dir="ltr">shape</code> and returns the partition results.</p> <p>Examples of a partitioner that allocates a fixed number of shards:</p> <pre class="prettyprint lang-python" translate="no" dir="ltr" data-language="python">partitioner = FixedShardsPartitioner(num_shards=2)
partitions = partitioner(tf.TensorShape([10, 3], tf.float32), axis=0)
print(partitions) # [2, 0]
</pre>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Args</th></tr> 
<tr> <td> <code translate="no" dir="ltr">shape</code> </td> <td> a <a href="../../../tensorshape"><code translate="no" dir="ltr">tf.TensorShape</code></a>, the shape to partition. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">dtype</code> </td> <td> a <code translate="no" dir="ltr">tf.dtypes.Dtype</code> indicating the type of the partition value. </td> </tr>
<tr> <td> <code translate="no" dir="ltr">axis</code> </td> <td> The axis to partition along. Default: outermost axis. </td> </tr> </table>  
<table class="responsive fixed orange"> <colgroup>
<col width="214px">
<col>
</colgroup> <tr><th colspan="2">Returns</th></tr> <tr class="alt"> <td colspan="2"> A list of integers representing the number of partitions on each axis, where i-th value correponds to i-th axis. </td> </tr> 
</table>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/distribute/experimental/partitioners/MaxSizePartitioner" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/distribute/experimental/partitioners/MaxSizePartitioner</a>
  </p>
</div>
