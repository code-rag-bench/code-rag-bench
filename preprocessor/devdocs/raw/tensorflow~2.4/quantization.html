<h1 class="devsite-page-title">Module: tf.quantization</h1>       <p>Public API for tf.quantization namespace.</p> <h2 id="functions" data-text="Functions">Functions</h2> <p><a href="quantization/dequantize"><code translate="no" dir="ltr">dequantize(...)</code></a>: Dequantize the 'input' tensor into a float or bfloat16 Tensor.</p> <p><a href="quantization/fake_quant_with_min_max_args"><code translate="no" dir="ltr">fake_quant_with_min_max_args(...)</code></a>: Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.</p> <p><a href="quantization/fake_quant_with_min_max_args_gradient"><code translate="no" dir="ltr">fake_quant_with_min_max_args_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxArgs operation.</p> <p><a href="quantization/fake_quant_with_min_max_vars"><code translate="no" dir="ltr">fake_quant_with_min_max_vars(...)</code></a>: Fake-quantize the 'inputs' tensor of type float via global float scalars</p> <p><a href="quantization/fake_quant_with_min_max_vars_gradient"><code translate="no" dir="ltr">fake_quant_with_min_max_vars_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVars operation.</p> <p><a href="quantization/fake_quant_with_min_max_vars_per_channel"><code translate="no" dir="ltr">fake_quant_with_min_max_vars_per_channel(...)</code></a>: Fake-quantize the 'inputs' tensor of type float via per-channel floats</p> <p><a href="quantization/fake_quant_with_min_max_vars_per_channel_gradient"><code translate="no" dir="ltr">fake_quant_with_min_max_vars_per_channel_gradient(...)</code></a>: Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.</p> <p><a href="quantization/quantize"><code translate="no" dir="ltr">quantize(...)</code></a>: Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.</p> <p><a href="quantization/quantize_and_dequantize"><code translate="no" dir="ltr">quantize_and_dequantize(...)</code></a>: Quantizes then dequantizes a tensor. (deprecated)</p> <p><a href="quantization/quantize_and_dequantize_v2"><code translate="no" dir="ltr">quantize_and_dequantize_v2(...)</code></a>: Quantizes then dequantizes a tensor.</p> <p><a href="quantization/quantized_concat"><code translate="no" dir="ltr">quantized_concat(...)</code></a>: Concatenates quantized tensors along one dimension.</p>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/quantization" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/quantization</a>
  </p>
</div>
