<h1 class="devsite-page-title">Module: tf.nn</h1>       <p>Wrappers for primitive Neural Net (NN) Operations.</p> <h2 id="classes" data-text="Classes">Classes</h2> <p><a href="nn/rnncelldevicewrapper"><code translate="no" dir="ltr">class RNNCellDeviceWrapper</code></a>: Operator that ensures an RNNCell runs on a particular device.</p> <p><a href="nn/rnncelldropoutwrapper"><code translate="no" dir="ltr">class RNNCellDropoutWrapper</code></a>: Operator adding dropout to inputs and outputs of the given cell.</p> <p><a href="nn/rnncellresidualwrapper"><code translate="no" dir="ltr">class RNNCellResidualWrapper</code></a>: RNNCell wrapper that ensures cell inputs are added to the outputs.</p> <h2 id="functions" data-text="Functions">Functions</h2> <p><a href="random/all_candidate_sampler"><code translate="no" dir="ltr">all_candidate_sampler(...)</code></a>: Generate the set of all classes.</p> <p><a href="nn/atrous_conv2d"><code translate="no" dir="ltr">atrous_conv2d(...)</code></a>: Atrous convolution (a.k.a. convolution with holes or dilated convolution).</p> <p><a href="nn/atrous_conv2d_transpose"><code translate="no" dir="ltr">atrous_conv2d_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">atrous_conv2d</code>.</p> <p><a href="nn/avg_pool"><code translate="no" dir="ltr">avg_pool(...)</code></a>: Performs the avg pooling on the input.</p> <p><a href="nn/avg_pool1d"><code translate="no" dir="ltr">avg_pool1d(...)</code></a>: Performs the average pooling on the input.</p> <p><a href="nn/avg_pool2d"><code translate="no" dir="ltr">avg_pool2d(...)</code></a>: Performs the average pooling on the input.</p> <p><a href="nn/avg_pool3d"><code translate="no" dir="ltr">avg_pool3d(...)</code></a>: Performs the average pooling on the input.</p> <p><a href="nn/batch_norm_with_global_normalization"><code translate="no" dir="ltr">batch_norm_with_global_normalization(...)</code></a>: Batch normalization.</p> <p><a href="nn/batch_normalization"><code translate="no" dir="ltr">batch_normalization(...)</code></a>: Batch normalization.</p> <p><a href="nn/bias_add"><code translate="no" dir="ltr">bias_add(...)</code></a>: Adds <code translate="no" dir="ltr">bias</code> to <code translate="no" dir="ltr">value</code>.</p> <p><a href="nn/collapse_repeated"><code translate="no" dir="ltr">collapse_repeated(...)</code></a>: Merge repeated labels into single labels.</p> <p><a href="nn/compute_accidental_hits"><code translate="no" dir="ltr">compute_accidental_hits(...)</code></a>: Compute the position ids in <code translate="no" dir="ltr">sampled_candidates</code> matching <code translate="no" dir="ltr">true_classes</code>.</p> <p><a href="nn/compute_average_loss"><code translate="no" dir="ltr">compute_average_loss(...)</code></a>: Scales per-example losses with sample_weights and computes their average.</p> <p><a href="nn/conv1d"><code translate="no" dir="ltr">conv1d(...)</code></a>: Computes a 1-D convolution given 3-D input and filter tensors.</p> <p><a href="nn/conv1d_transpose"><code translate="no" dir="ltr">conv1d_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">conv1d</code>.</p> <p><a href="nn/conv2d"><code translate="no" dir="ltr">conv2d(...)</code></a>: Computes a 2-D convolution given <code translate="no" dir="ltr">input</code> and 4-D <code translate="no" dir="ltr">filters</code> tensors.</p> <p><a href="nn/conv2d_transpose"><code translate="no" dir="ltr">conv2d_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">conv2d</code>.</p> <p><a href="nn/conv3d"><code translate="no" dir="ltr">conv3d(...)</code></a>: Computes a 3-D convolution given 5-D <code translate="no" dir="ltr">input</code> and <code translate="no" dir="ltr">filters</code> tensors.</p> <p><a href="nn/conv3d_transpose"><code translate="no" dir="ltr">conv3d_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">conv3d</code>.</p> <p><a href="nn/conv_transpose"><code translate="no" dir="ltr">conv_transpose(...)</code></a>: The transpose of <code translate="no" dir="ltr">convolution</code>.</p> <p><a href="nn/convolution"><code translate="no" dir="ltr">convolution(...)</code></a>: Computes sums of N-D convolutions (actually cross-correlation).</p> <p><a href="nn/crelu"><code translate="no" dir="ltr">crelu(...)</code></a>: Computes Concatenated ReLU.</p> <p><a href="nn/ctc_beam_search_decoder"><code translate="no" dir="ltr">ctc_beam_search_decoder(...)</code></a>: Performs beam search decoding on the logits given in input.</p> <p><a href="nn/ctc_greedy_decoder"><code translate="no" dir="ltr">ctc_greedy_decoder(...)</code></a>: Performs greedy decoding on the logits given in input (best path).</p> <p><a href="nn/ctc_loss"><code translate="no" dir="ltr">ctc_loss(...)</code></a>: Computes CTC (Connectionist Temporal Classification) loss.</p> <p><a href="nn/ctc_unique_labels"><code translate="no" dir="ltr">ctc_unique_labels(...)</code></a>: Get unique labels and indices for batched labels for <a href="nn/ctc_loss"><code translate="no" dir="ltr">tf.nn.ctc_loss</code></a>.</p> <p><a href="nn/depth_to_space"><code translate="no" dir="ltr">depth_to_space(...)</code></a>: DepthToSpace for tensors of type T.</p> <p><a href="nn/depthwise_conv2d"><code translate="no" dir="ltr">depthwise_conv2d(...)</code></a>: Depthwise 2-D convolution.</p> <p><a href="nn/depthwise_conv2d_backprop_filter"><code translate="no" dir="ltr">depthwise_conv2d_backprop_filter(...)</code></a>: Computes the gradients of depthwise convolution with respect to the filter.</p> <p><a href="nn/depthwise_conv2d_backprop_input"><code translate="no" dir="ltr">depthwise_conv2d_backprop_input(...)</code></a>: Computes the gradients of depthwise convolution with respect to the input.</p> <p><a href="nn/dilation2d"><code translate="no" dir="ltr">dilation2d(...)</code></a>: Computes the grayscale dilation of 4-D <code translate="no" dir="ltr">input</code> and 3-D <code translate="no" dir="ltr">filters</code> tensors.</p> <p><a href="nn/dropout"><code translate="no" dir="ltr">dropout(...)</code></a>: Computes dropout: randomly sets elements to zero to prevent overfitting.</p> <p><a href="nn/elu"><code translate="no" dir="ltr">elu(...)</code></a>: Computes exponential linear: <code translate="no" dir="ltr">exp(features) - 1</code> if &lt; 0, <code translate="no" dir="ltr">features</code> otherwise.</p> <p><a href="nn/embedding_lookup"><code translate="no" dir="ltr">embedding_lookup(...)</code></a>: Looks up embeddings for the given <code translate="no" dir="ltr">ids</code> from a list of tensors.</p> <p><a href="nn/embedding_lookup_sparse"><code translate="no" dir="ltr">embedding_lookup_sparse(...)</code></a>: Looks up embeddings for the given ids and weights from a list of tensors.</p> <p><a href="nn/erosion2d"><code translate="no" dir="ltr">erosion2d(...)</code></a>: Computes the grayscale erosion of 4-D <code translate="no" dir="ltr">value</code> and 3-D <code translate="no" dir="ltr">filters</code> tensors.</p> <p><a href="random/fixed_unigram_candidate_sampler"><code translate="no" dir="ltr">fixed_unigram_candidate_sampler(...)</code></a>: Samples a set of classes using the provided (fixed) base distribution.</p> <p><a href="nn/fractional_avg_pool"><code translate="no" dir="ltr">fractional_avg_pool(...)</code></a>: Performs fractional average pooling on the input.</p> <p><a href="nn/fractional_max_pool"><code translate="no" dir="ltr">fractional_max_pool(...)</code></a>: Performs fractional max pooling on the input.</p> <p><a href="nn/gelu"><code translate="no" dir="ltr">gelu(...)</code></a>: Compute the Gaussian Error Linear Unit (GELU) activation function.</p> <p><a href="math/in_top_k"><code translate="no" dir="ltr">in_top_k(...)</code></a>: Says whether the targets are in the top <code translate="no" dir="ltr">K</code> predictions.</p> <p><a href="nn/isotonic_regression"><code translate="no" dir="ltr">isotonic_regression(...)</code></a>: Solves isotonic regression problems along the given axis.</p> <p><a href="nn/l2_loss"><code translate="no" dir="ltr">l2_loss(...)</code></a>: L2 Loss.</p> <p><a href="math/l2_normalize"><code translate="no" dir="ltr">l2_normalize(...)</code></a>: Normalizes along dimension <code translate="no" dir="ltr">axis</code> using an L2 norm.</p> <p><a href="nn/leaky_relu"><code translate="no" dir="ltr">leaky_relu(...)</code></a>: Compute the Leaky ReLU activation function.</p> <p><a href="random/learned_unigram_candidate_sampler"><code translate="no" dir="ltr">learned_unigram_candidate_sampler(...)</code></a>: Samples a set of classes from a distribution learned during training.</p> <p><a href="nn/local_response_normalization"><code translate="no" dir="ltr">local_response_normalization(...)</code></a>: Local Response Normalization.</p> <p><a href="nn/log_poisson_loss"><code translate="no" dir="ltr">log_poisson_loss(...)</code></a>: Computes log Poisson loss given <code translate="no" dir="ltr">log_input</code>.</p> <p><a href="nn/log_softmax"><code translate="no" dir="ltr">log_softmax(...)</code></a>: Computes log softmax activations.</p> <p><a href="nn/local_response_normalization"><code translate="no" dir="ltr">lrn(...)</code></a>: Local Response Normalization.</p> <p><a href="nn/max_pool"><code translate="no" dir="ltr">max_pool(...)</code></a>: Performs the max pooling on the input.</p> <p><a href="nn/max_pool1d"><code translate="no" dir="ltr">max_pool1d(...)</code></a>: Performs the max pooling on the input.</p> <p><a href="nn/max_pool2d"><code translate="no" dir="ltr">max_pool2d(...)</code></a>: Performs the max pooling on the input.</p> <p><a href="nn/max_pool3d"><code translate="no" dir="ltr">max_pool3d(...)</code></a>: Performs the max pooling on the input.</p> <p><a href="nn/max_pool_with_argmax"><code translate="no" dir="ltr">max_pool_with_argmax(...)</code></a>: Performs max pooling on the input and outputs both max values and indices.</p> <p><a href="nn/moments"><code translate="no" dir="ltr">moments(...)</code></a>: Calculates the mean and variance of <code translate="no" dir="ltr">x</code>.</p> <p><a href="nn/nce_loss"><code translate="no" dir="ltr">nce_loss(...)</code></a>: Computes and returns the noise-contrastive estimation training loss.</p> <p><a href="nn/normalize_moments"><code translate="no" dir="ltr">normalize_moments(...)</code></a>: Calculate the mean and variance of based on the sufficient statistics.</p> <p><a href="nn/pool"><code translate="no" dir="ltr">pool(...)</code></a>: Performs an N-D pooling operation.</p> <p><a href="nn/relu"><code translate="no" dir="ltr">relu(...)</code></a>: Computes rectified linear: <code translate="no" dir="ltr">max(features, 0)</code>.</p> <p><a href="nn/relu6"><code translate="no" dir="ltr">relu6(...)</code></a>: Computes Rectified Linear 6: <code translate="no" dir="ltr">min(max(features, 0), 6)</code>.</p> <p><a href="nn/safe_embedding_lookup_sparse"><code translate="no" dir="ltr">safe_embedding_lookup_sparse(...)</code></a>: Lookup embedding results, accounting for invalid IDs and empty features.</p> <p><a href="nn/sampled_softmax_loss"><code translate="no" dir="ltr">sampled_softmax_loss(...)</code></a>: Computes and returns the sampled softmax training loss.</p> <p><a href="nn/scale_regularization_loss"><code translate="no" dir="ltr">scale_regularization_loss(...)</code></a>: Scales the sum of the given regularization losses by number of replicas.</p> <p><a href="nn/selu"><code translate="no" dir="ltr">selu(...)</code></a>: Computes scaled exponential linear: <code translate="no" dir="ltr">scale * alpha * (exp(features) - 1)</code></p> <p><a href="nn/separable_conv2d"><code translate="no" dir="ltr">separable_conv2d(...)</code></a>: 2-D convolution with separable filters.</p> <p><a href="math/sigmoid"><code translate="no" dir="ltr">sigmoid(...)</code></a>: Computes sigmoid of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="nn/sigmoid_cross_entropy_with_logits"><code translate="no" dir="ltr">sigmoid_cross_entropy_with_logits(...)</code></a>: Computes sigmoid cross entropy given <code translate="no" dir="ltr">logits</code>.</p> <p><a href="nn/silu"><code translate="no" dir="ltr">silu(...)</code></a>: Computes the SiLU or Swish activation function: <code translate="no" dir="ltr">x * sigmoid(x)</code>.</p> <p><a href="nn/softmax"><code translate="no" dir="ltr">softmax(...)</code></a>: Computes softmax activations.</p> <p><a href="nn/softmax_cross_entropy_with_logits"><code translate="no" dir="ltr">softmax_cross_entropy_with_logits(...)</code></a>: Computes softmax cross entropy between <code translate="no" dir="ltr">logits</code> and <code translate="no" dir="ltr">labels</code>.</p> <p><a href="math/softplus"><code translate="no" dir="ltr">softplus(...)</code></a>: Computes softplus: <code translate="no" dir="ltr">log(exp(features) + 1)</code>.</p> <p><a href="nn/softsign"><code translate="no" dir="ltr">softsign(...)</code></a>: Computes softsign: <code translate="no" dir="ltr">features / (abs(features) + 1)</code>.</p> <p><a href="space_to_batch"><code translate="no" dir="ltr">space_to_batch(...)</code></a>: SpaceToBatch for N-D tensors of type T.</p> <p><a href="nn/space_to_depth"><code translate="no" dir="ltr">space_to_depth(...)</code></a>: SpaceToDepth for tensors of type T.</p> <p><a href="nn/sparse_softmax_cross_entropy_with_logits"><code translate="no" dir="ltr">sparse_softmax_cross_entropy_with_logits(...)</code></a>: Computes sparse softmax cross entropy between <code translate="no" dir="ltr">logits</code> and <code translate="no" dir="ltr">labels</code>.</p> <p><a href="nn/sufficient_statistics"><code translate="no" dir="ltr">sufficient_statistics(...)</code></a>: Calculate the sufficient statistics for the mean and variance of <code translate="no" dir="ltr">x</code>.</p> <p><a href="nn/silu"><code translate="no" dir="ltr">swish(...)</code></a>: Computes the SiLU or Swish activation function: <code translate="no" dir="ltr">x * sigmoid(x)</code>.</p> <p><a href="math/tanh"><code translate="no" dir="ltr">tanh(...)</code></a>: Computes hyperbolic tangent of <code translate="no" dir="ltr">x</code> element-wise.</p> <p><a href="math/top_k"><code translate="no" dir="ltr">top_k(...)</code></a>: Finds values and indices of the <code translate="no" dir="ltr">k</code> largest entries for the last dimension.</p> <p><a href="nn/weighted_cross_entropy_with_logits"><code translate="no" dir="ltr">weighted_cross_entropy_with_logits(...)</code></a>: Computes a weighted cross entropy.</p> <p><a href="nn/weighted_moments"><code translate="no" dir="ltr">weighted_moments(...)</code></a>: Returns the frequency-weighted mean and variance of <code translate="no" dir="ltr">x</code>.</p> <p><a href="nn/with_space_to_batch"><code translate="no" dir="ltr">with_space_to_batch(...)</code></a>: Performs <code translate="no" dir="ltr">op</code> on the space-to-batch representation of <code translate="no" dir="ltr">input</code>.</p> <p><a href="math/zero_fraction"><code translate="no" dir="ltr">zero_fraction(...)</code></a>: Returns the fraction of zeros in <code translate="no" dir="ltr">value</code>.</p>  <devsite-page-rating position="footer" selected-rating="0" hover-rating-star="0"> </devsite-page-rating><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2020 The TensorFlow Authors. All rights reserved.<br>Licensed under the Creative Commons Attribution License 3.0.<br>Code samples licensed under the Apache 2.0 License.<br>
    <a href="https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/nn" class="_attribution-link">https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/nn</a>
  </p>
</div>
