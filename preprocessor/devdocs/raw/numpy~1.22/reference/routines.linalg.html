<h1>Linear algebra (numpy.linalg)</h1> <p>The NumPy linear algebra functions rely on BLAS and LAPACK to provide efficient low level implementations of standard linear algebra algorithms. Those libraries may be provided by NumPy itself using C versions of a subset of their reference implementations but, when possible, highly optimized libraries that take advantage of specialized processor functionality are preferred. Examples of such libraries are <a class="reference external" href="https://www.openblas.net/">OpenBLAS</a>, MKL (TM), and ATLAS. Because those libraries are multithreaded and processor dependent, environmental variables and external packages such as <a class="reference external" href="https://github.com/joblib/threadpoolctl">threadpoolctl</a> may be needed to control the number of threads or specify the processor architecture.</p> <p>The SciPy library also contains a <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/reference/linalg.html#module-scipy.linalg" title="(in SciPy v1.7.1)"><code>linalg</code></a> submodule, and there is overlap in the functionality provided by the SciPy and NumPy submodules. SciPy contains functions not found in <a class="reference internal" href="#module-numpy.linalg" title="numpy.linalg"><code>numpy.linalg</code></a>, such as functions related to LU decomposition and the Schur decomposition, multiple ways of calculating the pseudoinverse, and matrix transcendentals such as the matrix logarithm. Some functions that exist in both have augmented functionality in <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/reference/linalg.html#module-scipy.linalg" title="(in SciPy v1.7.1)"><code>scipy.linalg</code></a>. For example, <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/reference/generated/scipy.linalg.eig.html#scipy.linalg.eig" title="(in SciPy v1.7.1)"><code>scipy.linalg.eig</code></a> can take a second matrix argument for solving generalized eigenvalue problems. Some functions in NumPy, however, have more flexible broadcasting options. For example, <a class="reference internal" href="generated/numpy.linalg.solve#numpy.linalg.solve" title="numpy.linalg.solve"><code>numpy.linalg.solve</code></a> can handle “stacked” arrays, while <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/reference/generated/scipy.linalg.solve.html#scipy.linalg.solve" title="(in SciPy v1.7.1)"><code>scipy.linalg.solve</code></a> accepts only a single square array as its first argument.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>The term <em>matrix</em> as it is used on this page indicates a 2d <a class="reference internal" href="generated/numpy.array#numpy.array" title="numpy.array"><code>numpy.array</code></a> object, and <em>not</em> a <a class="reference internal" href="generated/numpy.matrix#numpy.matrix" title="numpy.matrix"><code>numpy.matrix</code></a> object. The latter is no longer recommended, even for linear algebra. See <a class="reference internal" href="arrays.classes#matrix-objects"><span class="std std-ref">the matrix object documentation</span></a> for more information.</p> </div> <section id="the-operator"> <h2>The <code>@</code> operator</h2> <p>Introduced in NumPy 1.10.0, the <code>@</code> operator is preferable to other methods when computing the matrix product between 2d arrays. The <a class="reference internal" href="generated/numpy.matmul#numpy.matmul" title="numpy.matmul"><code>numpy.matmul</code></a> function implements the <code>@</code> operator.</p> </section> <section id="matrix-and-vector-products"> <h2>Matrix and vector products</h2> <table class="longtable table autosummary">   <tr>
<td><p><a class="reference internal" href="generated/numpy.dot#numpy.dot" title="numpy.dot"><code>dot</code></a>(a, b[, out])</p></td> <td><p>Dot product of two arrays.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.multi_dot#numpy.linalg.multi_dot" title="numpy.linalg.multi_dot"><code>linalg.multi_dot</code></a>(arrays, *[, out])</p></td> <td><p>Compute the dot product of two or more arrays in a single function call, while automatically selecting the fastest evaluation order.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.vdot#numpy.vdot" title="numpy.vdot"><code>vdot</code></a>(a, b, /)</p></td> <td><p>Return the dot product of two vectors.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.inner#numpy.inner" title="numpy.inner"><code>inner</code></a>(a, b, /)</p></td> <td><p>Inner product of two arrays.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.outer#numpy.outer" title="numpy.outer"><code>outer</code></a>(a, b[, out])</p></td> <td><p>Compute the outer product of two vectors.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.matmul#numpy.matmul" title="numpy.matmul"><code>matmul</code></a>(x1, x2, /[, out, casting, order, ...])</p></td> <td><p>Matrix product of two arrays.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.tensordot#numpy.tensordot" title="numpy.tensordot"><code>tensordot</code></a>(a, b[, axes])</p></td> <td><p>Compute tensor dot product along specified axes.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.einsum#numpy.einsum" title="numpy.einsum"><code>einsum</code></a>(subscripts, *operands[, out, dtype, ...])</p></td> <td><p>Evaluates the Einstein summation convention on the operands.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.einsum_path#numpy.einsum_path" title="numpy.einsum_path"><code>einsum_path</code></a>(subscripts, *operands[, optimize])</p></td> <td><p>Evaluates the lowest cost contraction order for an einsum expression by considering the creation of intermediate arrays.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.matrix_power#numpy.linalg.matrix_power" title="numpy.linalg.matrix_power"><code>linalg.matrix_power</code></a>(a, n)</p></td> <td><p>Raise a square matrix to the (integer) power <code>n</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.kron#numpy.kron" title="numpy.kron"><code>kron</code></a>(a, b)</p></td> <td><p>Kronecker product of two arrays.</p></td> </tr>  </table> </section> <section id="decompositions"> <h2>Decompositions</h2> <table class="longtable table autosummary">   <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.cholesky#numpy.linalg.cholesky" title="numpy.linalg.cholesky"><code>linalg.cholesky</code></a>(a)</p></td> <td><p>Cholesky decomposition.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.qr#numpy.linalg.qr" title="numpy.linalg.qr"><code>linalg.qr</code></a>(a[, mode])</p></td> <td><p>Compute the qr factorization of a matrix.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.svd#numpy.linalg.svd" title="numpy.linalg.svd"><code>linalg.svd</code></a>(a[, full_matrices, compute_uv, ...])</p></td> <td><p>Singular Value Decomposition.</p></td> </tr>  </table> </section> <section id="matrix-eigenvalues"> <h2>Matrix eigenvalues</h2> <table class="longtable table autosummary">   <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.eig#numpy.linalg.eig" title="numpy.linalg.eig"><code>linalg.eig</code></a>(a)</p></td> <td><p>Compute the eigenvalues and right eigenvectors of a square array.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.eigh#numpy.linalg.eigh" title="numpy.linalg.eigh"><code>linalg.eigh</code></a>(a[, UPLO])</p></td> <td><p>Return the eigenvalues and eigenvectors of a complex Hermitian (conjugate symmetric) or a real symmetric matrix.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.eigvals#numpy.linalg.eigvals" title="numpy.linalg.eigvals"><code>linalg.eigvals</code></a>(a)</p></td> <td><p>Compute the eigenvalues of a general matrix.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.eigvalsh#numpy.linalg.eigvalsh" title="numpy.linalg.eigvalsh"><code>linalg.eigvalsh</code></a>(a[, UPLO])</p></td> <td><p>Compute the eigenvalues of a complex Hermitian or real symmetric matrix.</p></td> </tr>  </table> </section> <section id="norms-and-other-numbers"> <h2>Norms and other numbers</h2> <table class="longtable table autosummary">   <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.norm#numpy.linalg.norm" title="numpy.linalg.norm"><code>linalg.norm</code></a>(x[, ord, axis, keepdims])</p></td> <td><p>Matrix or vector norm.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.cond#numpy.linalg.cond" title="numpy.linalg.cond"><code>linalg.cond</code></a>(x[, p])</p></td> <td><p>Compute the condition number of a matrix.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.det#numpy.linalg.det" title="numpy.linalg.det"><code>linalg.det</code></a>(a)</p></td> <td><p>Compute the determinant of an array.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.matrix_rank#numpy.linalg.matrix_rank" title="numpy.linalg.matrix_rank"><code>linalg.matrix_rank</code></a>(A[, tol, hermitian])</p></td> <td><p>Return matrix rank of array using SVD method</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.slogdet#numpy.linalg.slogdet" title="numpy.linalg.slogdet"><code>linalg.slogdet</code></a>(a)</p></td> <td><p>Compute the sign and (natural) logarithm of the determinant of an array.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.trace#numpy.trace" title="numpy.trace"><code>trace</code></a>(a[, offset, axis1, axis2, dtype, out])</p></td> <td><p>Return the sum along diagonals of the array.</p></td> </tr>  </table> </section> <section id="solving-equations-and-inverting-matrices"> <h2>Solving equations and inverting matrices</h2> <table class="longtable table autosummary">   <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.solve#numpy.linalg.solve" title="numpy.linalg.solve"><code>linalg.solve</code></a>(a, b)</p></td> <td><p>Solve a linear matrix equation, or system of linear scalar equations.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.tensorsolve#numpy.linalg.tensorsolve" title="numpy.linalg.tensorsolve"><code>linalg.tensorsolve</code></a>(a, b[, axes])</p></td> <td><p>Solve the tensor equation <code>a x = b</code> for x.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.lstsq#numpy.linalg.lstsq" title="numpy.linalg.lstsq"><code>linalg.lstsq</code></a>(a, b[, rcond])</p></td> <td><p>Return the least-squares solution to a linear matrix equation.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.inv#numpy.linalg.inv" title="numpy.linalg.inv"><code>linalg.inv</code></a>(a)</p></td> <td><p>Compute the (multiplicative) inverse of a matrix.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.pinv#numpy.linalg.pinv" title="numpy.linalg.pinv"><code>linalg.pinv</code></a>(a[, rcond, hermitian])</p></td> <td><p>Compute the (Moore-Penrose) pseudo-inverse of a matrix.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.tensorinv#numpy.linalg.tensorinv" title="numpy.linalg.tensorinv"><code>linalg.tensorinv</code></a>(a[, ind])</p></td> <td><p>Compute the 'inverse' of an N-dimensional array.</p></td> </tr>  </table> </section> <section id="exceptions"> <h2>Exceptions</h2> <table class="longtable table autosummary">   <tr>
<td><p><a class="reference internal" href="generated/numpy.linalg.linalgerror#numpy.linalg.LinAlgError" title="numpy.linalg.LinAlgError"><code>linalg.LinAlgError</code></a></p></td> <td><p>Generic Python-exception-derived object raised by linalg functions.</p></td> </tr>  </table> </section> <section id="linear-algebra-on-several-matrices-at-once"> <h2 id="routines-linalg-broadcasting">Linear algebra on several matrices at once</h2> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.8.0.</span></p> </div> <p>Several of the linear algebra routines listed above are able to compute results for several matrices at once, if they are stacked into the same array.</p> <p>This is indicated in the documentation via input parameter specifications such as <code>a : (..., M, M) array_like</code>. This means that if for instance given an input array <code>a.shape == (N, M, M)</code>, it is interpreted as a “stack” of N matrices, each of size M-by-M. Similar specification applies to return values, for instance the determinant has <code>det : (...)</code> and will in this case return an array of shape <code>det(a).shape == (N,)</code>. This generalizes to linear algebra operations on higher-dimensional arrays: the last 1 or 2 dimensions of a multidimensional array are interpreted as vectors or matrices, as appropriate for each operation.</p> </section><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2021 NumPy Developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://numpy.org/doc/1.22/reference/routines.linalg.html" class="_attribution-link">https://numpy.org/doc/1.22/reference/routines.linalg.html</a>
  </p>
</div>
