<h1>numpy.cov</h1> <dl class="py function"> <dt class="sig sig-object py" id="numpy.cov"> <span class="sig-prename descclassname">numpy.</span><span class="sig-name descname">cov</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">m</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">rowvar</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">bias</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">ddof</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">fweights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">aweights</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="o">*</span></em>, <em class="sig-param"><span class="n">dtype</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/numpy/numpy/blob/v1.22.0/numpy/lib/function_base.py#L2462-L2681"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate a covariance matrix, given data and weights.</p> <p>Covariance indicates the level to which two variables vary together. If we examine N-dimensional samples, <span class="math notranslate nohighlight">\(X = [x_1, x_2, ... x_N]^T\)</span>, then the covariance matrix element <span class="math notranslate nohighlight">\(C_{ij}\)</span> is the covariance of <span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(x_j\)</span>. The element <span class="math notranslate nohighlight">\(C_{ii}\)</span> is the variance of <span class="math notranslate nohighlight">\(x_i\)</span>.</p> <p>See the notes for an outline of the algorithm.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<strong>m</strong><span class="classifier">array_like</span>
</dt>
<dd>
<p>A 1-D or 2-D array containing multiple variables and observations. Each row of <code>m</code> represents a variable, and each column a single observation of all those variables. Also see <code>rowvar</code> below.</p> </dd> <dt>
<strong>y</strong><span class="classifier">array_like, optional</span>
</dt>
<dd>
<p>An additional set of variables and observations. <code>y</code> has the same form as that of <code>m</code>.</p> </dd> <dt>
<strong>rowvar</strong><span class="classifier">bool, optional</span>
</dt>
<dd>
<p>If <code>rowvar</code> is True (default), then each row represents a variable, with observations in the columns. Otherwise, the relationship is transposed: each column represents a variable, while the rows contain observations.</p> </dd> <dt>
<strong>bias</strong><span class="classifier">bool, optional</span>
</dt>
<dd>
<p>Default normalization (False) is by <code>(N - 1)</code>, where <code>N</code> is the number of observations given (unbiased estimate). If <code>bias</code> is True, then normalization is by <code>N</code>. These values can be overridden by using the keyword <code>ddof</code> in numpy versions &gt;= 1.5.</p> </dd> <dt>
<strong>ddof</strong><span class="classifier">int, optional</span>
</dt>
<dd>
<p>If not <code>None</code> the default value implied by <code>bias</code> is overridden. Note that <code>ddof=1</code> will return the unbiased estimate, even if both <code>fweights</code> and <code>aweights</code> are specified, and <code>ddof=0</code> will return the simple average. See the notes for the details. The default value is <code>None</code>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.5.</span></p> </div> </dd> <dt>
<strong>fweights</strong><span class="classifier">array_like, int, optional</span>
</dt>
<dd>
<p>1-D array of integer frequency weights; the number of times each observation vector should be repeated.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.10.</span></p> </div> </dd> <dt>
<strong>aweights</strong><span class="classifier">array_like, optional</span>
</dt>
<dd>
<p>1-D array of observation vector weights. These relative weights are typically large for observations considered “important” and smaller for observations considered less “important”. If <code>ddof=0</code> the array of weights can be used to assign probabilities to observation vectors.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.10.</span></p> </div> </dd> <dt>
<strong>dtype</strong><span class="classifier">data-type, optional</span>
</dt>
<dd>
<p>Data-type of the result. By default, the return data-type will have at least <a class="reference internal" href="../arrays.scalars#numpy.float64" title="numpy.float64"><code>numpy.float64</code></a> precision.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.20.</span></p> </div> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<strong>out</strong><span class="classifier">ndarray</span>
</dt>
<dd>
<p>The covariance matrix of the variables.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt><a class="reference internal" href="numpy.corrcoef#numpy.corrcoef" title="numpy.corrcoef"><code>corrcoef</code></a></dt>
<dd>
<p>Normalized covariance matrix</p> </dd> </dl> </div> <h4 class="rubric">Notes</h4> <p>Assume that the observations are in the columns of the observation array <code>m</code> and let <code>f = fweights</code> and <code>a = aweights</code> for brevity. The steps to compute the weighted covariance are as follows:</p> <pre data-language="python">&gt;&gt;&gt; m = np.arange(10, dtype=np.float64)
&gt;&gt;&gt; f = np.arange(10) * 2
&gt;&gt;&gt; a = np.arange(10) ** 2.
&gt;&gt;&gt; ddof = 1
&gt;&gt;&gt; w = f * a
&gt;&gt;&gt; v1 = np.sum(w)
&gt;&gt;&gt; v2 = np.sum(w * a)
&gt;&gt;&gt; m -= np.sum(m * w, axis=None, keepdims=True) / v1
&gt;&gt;&gt; cov = np.dot(m * w, m.T) * v1 / (v1**2 - ddof * v2)
</pre> <p>Note that when <code>a == 1</code>, the normalization factor <code>v1 / (v1**2 - ddof * v2)</code> goes over to <code>1 / (np.sum(f) - ddof)</code> as it should.</p> <h4 class="rubric">Examples</h4> <p>Consider two variables, <span class="math notranslate nohighlight">\(x_0\)</span> and <span class="math notranslate nohighlight">\(x_1\)</span>, which correlate perfectly, but in opposite directions:</p> <pre data-language="python">&gt;&gt;&gt; x = np.array([[0, 2], [1, 1], [2, 0]]).T
&gt;&gt;&gt; x
array([[0, 1, 2],
       [2, 1, 0]])
</pre> <p>Note how <span class="math notranslate nohighlight">\(x_0\)</span> increases while <span class="math notranslate nohighlight">\(x_1\)</span> decreases. The covariance matrix shows this clearly:</p> <pre data-language="python">&gt;&gt;&gt; np.cov(x)
array([[ 1., -1.],
       [-1.,  1.]])
</pre> <p>Note that element <span class="math notranslate nohighlight">\(C_{0,1}\)</span>, which shows the correlation between <span class="math notranslate nohighlight">\(x_0\)</span> and <span class="math notranslate nohighlight">\(x_1\)</span>, is negative.</p> <p>Further, note how <code>x</code> and <code>y</code> are combined:</p> <pre data-language="python">&gt;&gt;&gt; x = [-2.1, -1,  4.3]
&gt;&gt;&gt; y = [3,  1.1,  0.12]
&gt;&gt;&gt; X = np.stack((x, y), axis=0)
&gt;&gt;&gt; np.cov(X)
array([[11.71      , -4.286     ], # may vary
       [-4.286     ,  2.144133]])
&gt;&gt;&gt; np.cov(x, y)
array([[11.71      , -4.286     ], # may vary
       [-4.286     ,  2.144133]])
&gt;&gt;&gt; np.cov(x)
array(11.71)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2021 NumPy Developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://numpy.org/doc/1.22/reference/generated/numpy.cov.html" class="_attribution-link">https://numpy.org/doc/1.22/reference/generated/numpy.cov.html</a>
  </p>
</div>
