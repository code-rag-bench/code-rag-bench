<h1>numpy.testing.assert_allclose</h1> <dl class="py function"> <dt class="sig sig-object py" id="numpy.testing.assert_allclose"> <span class="sig-prename descclassname">testing.</span><span class="sig-name descname">assert_allclose</span><span class="sig-paren">(</span><em class="sig-param"><span class="n">actual</span></em>, <em class="sig-param"><span class="n">desired</span></em>, <em class="sig-param"><span class="n">rtol</span><span class="o">=</span><span class="default_value">1e-07</span></em>, <em class="sig-param"><span class="n">atol</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">equal_nan</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">err_msg</span><span class="o">=</span><span class="default_value">''</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/numpy/numpy/blob/v1.22.0/numpy/testing/_private/utils.py#L1476-L1531"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Raises an AssertionError if two objects are not equal up to desired tolerance.</p> <p>The test is equivalent to <code>allclose(actual, desired, rtol, atol)</code> (note that <code>allclose</code> has different default values). It compares the difference between <code>actual</code> and <code>desired</code> to <code>atol + rtol * abs(desired)</code>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 1.5.0.</span></p> </div> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<strong>actual</strong><span class="classifier">array_like</span>
</dt>
<dd>
<p>Array obtained.</p> </dd> <dt>
<strong>desired</strong><span class="classifier">array_like</span>
</dt>
<dd>
<p>Array desired.</p> </dd> <dt>
<strong>rtol</strong><span class="classifier">float, optional</span>
</dt>
<dd>
<p>Relative tolerance.</p> </dd> <dt>
<strong>atol</strong><span class="classifier">float, optional</span>
</dt>
<dd>
<p>Absolute tolerance.</p> </dd> <dt>
<strong>equal_nan</strong><span class="classifier">bool, optional.</span>
</dt>
<dd>
<p>If True, NaNs will compare equal.</p> </dd> <dt>
<strong>err_msg</strong><span class="classifier">str, optional</span>
</dt>
<dd>
<p>The error message to be printed in case of failure.</p> </dd> <dt>
<strong>verbose</strong><span class="classifier">bool, optional</span>
</dt>
<dd>
<p>If True, the conflicting values are appended to the error message.</p> </dd> </dl> </dd> <dt class="field-even">Raises</dt> <dd class="field-even">
<dl class="simple"> <dt>AssertionError</dt>
<dd>
<p>If actual and desired are not equal up to specified precision.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt>
<a class="reference internal" href="numpy.testing.assert_array_almost_equal_nulp#numpy.testing.assert_array_almost_equal_nulp" title="numpy.testing.assert_array_almost_equal_nulp"><code>assert_array_almost_equal_nulp</code></a>, <a class="reference internal" href="numpy.testing.assert_array_max_ulp#numpy.testing.assert_array_max_ulp" title="numpy.testing.assert_array_max_ulp"><code>assert_array_max_ulp</code></a>
</dt>
 </dl> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; x = [1e-5, 1e-3, 1e-1]
&gt;&gt;&gt; y = np.arccos(np.cos(x))
&gt;&gt;&gt; np.testing.assert_allclose(x, y, rtol=1e-5, atol=0)
</pre> </dd>
</dl><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2005&ndash;2021 NumPy Developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://numpy.org/doc/1.22/reference/generated/numpy.testing.assert_allclose.html" class="_attribution-link">https://numpy.org/doc/1.22/reference/generated/numpy.testing.assert_allclose.html</a>
  </p>
</div>
