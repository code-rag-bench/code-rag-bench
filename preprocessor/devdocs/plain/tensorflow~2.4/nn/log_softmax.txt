# tf.nn.log_softmax

View source on GitHub  Computes log softmax activations.

#### View aliases

Main aliases `tf.math.log_softmax`

    
    tf.nn.log_softmax(
        logits, axis=None, name=None
    )
    
For each batch `i` and class `j` we have

    
    logsoftmax = logits - log(reduce_sum(exp(logits), axis))
    
| Args  
---  
`logits` |  A non-empty `Tensor`. Must be one of the following types: `half`, `float32`, `float64`.   
`axis` |  The dimension softmax would be performed on. The default is -1 which indicates the last dimension.   
`name` |  A name for the operation (optional).   
Returns  
---  
A `Tensor`. Has the same type as `logits`. Same shape as `logits`.  
Raises  
---  
`InvalidArgumentError` |  if `logits` is empty or `axis` is beyond the last dimension of `logits`.   
Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/nn/log_softmax

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

